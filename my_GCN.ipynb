{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18628,
     "status": "ok",
     "timestamp": 1661918171612,
     "user": {
      "displayName": "Nasrin Kalanat",
      "userId": "09177474018032965645"
     },
     "user_tz": 240
    },
    "id": "jjX4gojjAbSM",
    "outputId": "dca0ddc5-2233-45c7-95b6-48632b8864a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Symbolic_image/SKG-Sym\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Symbolic_image/SKG-Sym')\n",
    "%cd '/content/drive/My Drive/Symbolic_image/SKG-Sym'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aj4JOu0Hocsk"
   },
   "outputs": [],
   "source": [
    "# x={\"unknown\":0, \"fashion\": 17, \"family\": 29, \"strength\": 21, \"fun\": 5, \"sex\": 2, \"natural\": 1, \"comfort\": 43, \"delicious\": 39, \"violence\": 6, \"health\": 9, \"speed\": 16, \"energy\": 19, \"love\": 12, \"entertainment\": 26, \"adventure\": 10, \"vacation\": 42, \"art\": 33, \"travel\": 24, \"beauty\": 7, \"danger\": 4, \"nature\": 3, \"power\": 11, \"sports\": 14, \"happy\": 51, \"freedom\": 41, \"variety\": 45, \"environment\": 15, \"technology\": 27, \"protection\": 38, \"sexy\": 13, \"happiness\": 36, \"party\": 49, \"youth\": 23, \"fitness\": 37, \"safety\": 22, \"death\": 8, \"clean\": 40, \"animal cruelty\": 52, \"relaxation\": 32, \"hot\": 25, \"excitement\": 30, \"healthy\": 31, \"class\": 53, \"christmas\": 34, \"alcohol\": 50, \"strong\": 47, \"injury\": 20, \"hunger\": 46, \"desire\": 44, \"food\": 18, \"humor\": 48, \"refreshing\": 35, \"smoking\": 28}\n",
    "# x=dict(sorted(x.items(), key=lambda item: item[1]))\n",
    "# print(x)\n",
    "# listl=[0]*len(x)\n",
    "# for l in x:\n",
    "#   listl[x[l]]=l\n",
    "# print(listl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H09q_MU1RV5O"
   },
   "outputs": [],
   "source": [
    "# !python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cnUeK3m41OG"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall torch -y\n",
    "# !pip uninstall torch -y\n",
    "# !pip uninstall torchvision -y\n",
    "# !pip uninstall torchvision -y\n",
    "# !pip uninstall torchtext -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84966,
     "status": "ok",
     "timestamp": 1661918256570,
     "user": {
      "displayName": "Nasrin Kalanat",
      "userId": "09177474018032965645"
     },
     "user_tz": 240
    },
    "id": "tyEbnOjYCw9y",
    "outputId": "405c4b63-9eb0-418a-c50d-33c548182a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.6.0+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (708.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 708.0 MB 9.6 kB/s \n",
      "\u001B[?25hCollecting torchvision==0.7.0+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (5.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 5.9 MB 68.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (1.21.6)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cu101) (7.1.2)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu113\n",
      "    Uninstalling torch-1.12.1+cu113:\n",
      "      Successfully uninstalled torch-1.12.1+cu113\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.1+cu113\n",
      "    Uninstalling torchvision-0.13.1+cu113:\n",
      "      Successfully uninstalled torchvision-0.13.1+cu113\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.6.0+cu101 which is incompatible.\n",
      "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.6.0+cu101 which is incompatible.\n",
      "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.6.0+cu101 which is incompatible.\n",
      "fastai 2.7.9 requires torchvision>=0.8.2, but you have torchvision 0.7.0+cu101 which is incompatible.\u001B[0m\n",
      "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26139,
     "status": "ok",
     "timestamp": 1661918282699,
     "user": {
      "displayName": "Nasrin Kalanat",
      "userId": "09177474018032965645"
     },
     "user_tz": 240
    },
    "id": "mOeoqUBxyE_9",
    "outputId": "9030adad-a816-4496-e9ca-5638ddc82663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0+cu101.html\n",
      "Collecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-1.6.0%2Bcu101/torch_scatter-2.0.6-cp37-cp37m-linux_x86_64.whl (2.8 MB)\n",
      "\u001B[K     |████████████████████████████████| 2.8 MB 586 kB/s \n",
      "\u001B[?25hInstalling collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.0.6\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0+cu101.html\n",
      "Collecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-1.6.0%2Bcu101/torch_sparse-0.6.9-cp37-cp37m-linux_x86_64.whl (1.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.6 MB 560 kB/s \n",
      "\u001B[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.9\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0+cu101.html\n",
      "Collecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-1.6.0%2Bcu101/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1 MB 626 kB/s \n",
      "\u001B[?25hInstalling collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.5.9\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0+cu101.html\n",
      "Collecting torch-spline-conv\n",
      "  Downloading https://data.pyg.org/whl/torch-1.6.0%2Bcu101/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (367 kB)\n",
      "\u001B[K     |████████████████████████████████| 367 kB 733 kB/s \n",
      "\u001B[?25hInstalling collected packages: torch-spline-conv\n",
      "Successfully installed torch-spline-conv-1.2.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torch-geometric==2.0.1\n",
      "  Downloading torch_geometric-2.0.1.tar.gz (308 kB)\n",
      "\u001B[K     |████████████████████████████████| 308 kB 5.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (1.21.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (4.64.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (1.7.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (2.6.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (1.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (2.23.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (1.3.5)\n",
      "Collecting rdflib\n",
      "  Downloading rdflib-6.2.0-py3-none-any.whl (500 kB)\n",
      "\u001B[K     |████████████████████████████████| 500 kB 67.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (2.11.3)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (3.0.9)\n",
      "Collecting yacs\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.0.1) (6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric==2.0.1) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==2.0.1) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==2.0.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric==2.0.1) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==2.0.1) (4.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==2.0.1) (57.4.0)\n",
      "Collecting isodate\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001B[K     |████████████████████████████████| 41 kB 707 kB/s \n",
      "\u001B[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric==2.0.1) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric==2.0.1) (4.1.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.1) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.1) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.0.1) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.0.1) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.0.1) (3.1.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-2.0.1-py3-none-any.whl size=513820 sha256=e230249d4572c8e7c69f23cd468a0725b0218588eb5091fad185d5ee6cffd54f\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/3d/42/20589db73c66b5109fb93a0c5743edfd6ab5ca820a52afacfc\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
      "Successfully installed isodate-0.6.1 rdflib-6.2.0 torch-geometric-2.0.1 yacs-0.1.8\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting torchtext==0.7.0\n",
      "  Downloading torchtext-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (4.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 4.5 MB 5.1 MB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (2.23.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.3 MB 79.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (1.21.6)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (1.6.0+cu101)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (4.64.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (3.0.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.7.0) (0.16.0)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.13.1\n",
      "    Uninstalling torchtext-0.13.1:\n",
      "      Successfully uninstalled torchtext-0.13.1\n",
      "Successfully installed sentencepiece-0.1.97 torchtext-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.6.0+cu101.html\n",
    "!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.6.0+cu101.html\n",
    "!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.6.0+cu101.html\n",
    "!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.6.0+cu101.html\n",
    "!pip install torch-geometric==2.0.1\n",
    "!pip install torchtext==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-I-iGIPBG3b"
   },
   "outputs": [],
   "source": [
    "# !pip install torch-scatter torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6pUeic5CAoT"
   },
   "outputs": [],
   "source": [
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ac3VJXm_EadE"
   },
   "outputs": [],
   "source": [
    "# !wget https://nlp.stanford.edu/data/gqa/sceneGraphs.zip\n",
    "# !unzip sceneGraphs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYF9GW6DExs-"
   },
   "outputs": [],
   "source": [
    "# %cd 'questions'\n",
    "# !wget https://nlp.stanford.edu/data/gqa/questions1.2.zip\n",
    "# !unzip questions1.2.zip\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYJqzGOhPwzx"
   },
   "outputs": [],
   "source": [
    "# %cd 'questions'\n",
    "# !mkdir 'original'\n",
    "# %cd 'original'\n",
    "# !wget https://nlp.stanford.edu/data/gqa/eval.zip\n",
    "# !unzip eval.zip\n",
    "# %cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1093,
     "status": "ok",
     "timestamp": 1661918283781,
     "user": {
      "displayName": "Nasrin Kalanat",
      "userId": "09177474018032965645"
     },
     "user_tz": 240
    },
    "id": "CTCp6P16XT5b",
    "outputId": "8f32f1bc-4ff2-47a2-f55e-9a56e8e22932"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPxzebKQUxWU"
   },
   "outputs": [],
   "source": [
    "# %run preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ganEIIOjgSAM"
   },
   "outputs": [],
   "source": [
    "# !pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14968,
     "status": "ok",
     "timestamp": 1661918298742,
     "user": {
      "displayName": "Nasrin Kalanat",
      "userId": "09177474018032965645"
     },
     "user_tz": 240
    },
    "id": "-Nc1RHMhAM2n",
    "outputId": "11d7c785-0a5b-4c07-cb17-a11d8544fe8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This file defines the whole pipeline model (all neural modules).\n",
    "TO DEBUG:\n",
    "python pipeline_model.py\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_scatter import scatter_mean, scatter_add\n",
    "import logging\n",
    "import torch_geometric\n",
    "from gqa_dataset_entry import GQATorchDataset\n",
    "\n",
    "from graph_utils import my_graph_layernorm\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Parameter, Linear\n",
    "\"\"\"\n",
    "Graph Meta Layer, Example funciton\n",
    "\"\"\"\n",
    "def __meta_layer():\n",
    "\n",
    "    class EdgeModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(EdgeModel, self).__init__()\n",
    "            self.edge_mlp = Seq(Lin(2 * 10 + 5 + 20, 5), ReLU(), Lin(5, 5))\n",
    "\n",
    "        def forward(self, src, dest, edge_attr, u, batch):\n",
    "            out = torch.cat([src, dest, edge_attr, u[batch]], 1)\n",
    "            return self.edge_mlp(out)\n",
    "\n",
    "    class NodeModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NodeModel, self).__init__()\n",
    "            self.node_mlp_1 = Seq(Lin(15, 10), ReLU(), Lin(10, 10))\n",
    "            self.node_mlp_2 = Seq(Lin(2 * 10 + 20, 10), ReLU(), Lin(10, 10))\n",
    "\n",
    "        def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "            row, col = edge_index\n",
    "            out = torch.cat([x[row], edge_attr], dim=1)\n",
    "            out = self.node_mlp_1(out)\n",
    "            out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n",
    "            out = torch.cat([x, out, u[batch]], dim=1)\n",
    "            return self.node_mlp_2(out)\n",
    "\n",
    "    class GlobalModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(GlobalModel, self).__init__()\n",
    "            self.global_mlp = Seq(Lin(20 + 10, 20), ReLU(), Lin(20, 20))\n",
    "\n",
    "        def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "            out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)\n",
    "            return self.global_mlp(out)\n",
    "\n",
    "    op = torch_geometric.nn.MetaLayer(EdgeModel(), NodeModel(), GlobalModel())\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zAPPjrxAHk9"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scene Graph Encoding Module For Ground Truth (Graph Neural Module)\n",
    "Functional definition of scene graph encoding layer\n",
    "Return: a callable operator, which is an initialized torch_geometric.nn graph neural layer\n",
    "\"\"\"\n",
    "def get_gt_scene_graph_encoding_layer(num_node_features, num_edge_features):\n",
    "\n",
    "    class EdgeModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(EdgeModel, self).__init__()\n",
    "            self.edge_mlp = Seq(\n",
    "                Lin(2 * num_node_features + num_edge_features, num_edge_features),\n",
    "                ReLU(),\n",
    "                Lin(num_edge_features, num_edge_features)\n",
    "                )\n",
    "\n",
    "        def forward(self, src, dest, edge_attr, u, batch):\n",
    "            out = torch.cat([src, dest, edge_attr], 1)\n",
    "            return self.edge_mlp(out)\n",
    "\n",
    "    class NodeModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NodeModel, self).__init__()\n",
    "            self.node_mlp_1 = Seq(\n",
    "                Lin(num_node_features + num_edge_features, num_node_features),\n",
    "                ReLU(),\n",
    "                Lin(num_node_features, num_node_features)\n",
    "                )\n",
    "            self.node_mlp_2 = Seq(\n",
    "                Lin(2 * num_node_features, num_node_features),\n",
    "                ReLU(),\n",
    "                Lin(num_node_features, num_node_features)\n",
    "                )\n",
    "\n",
    "        def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "            row, col = edge_index\n",
    "            out = torch.cat([x[row], edge_attr], dim=1)\n",
    "            out = self.node_mlp_1(out)\n",
    "            out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n",
    "            out = torch.cat([x, out], dim=1)\n",
    "            return self.node_mlp_2(out)\n",
    "\n",
    "    op = torch_geometric.nn.MetaLayer(EdgeModel(), NodeModel())\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6uIwiS-__1e"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Final Layer of Graph Execution Module\n",
    "\"\"\"\n",
    "\n",
    "class MyConditionalGlobalAttention(torch.nn.Module):\n",
    "    r\"\"\"Language-Conditioned Global soft attention layer\n",
    "    .. math::\n",
    "        \\mathbf{r}_i = \\sum_{n=1}^{N_i} \\mathrm{softmax} \\left(\n",
    "        h_{\\mathrm{gate}} ( u[batch] ) \\dot h_{\\mathbf{\\Theta}} ( \\mathbf{x}_n ) \\right)\n",
    "        \\odot\n",
    "        h_{\\mathbf{\\Theta}} ( \\mathbf{x}_n ),\n",
    "    where :math:`h_{\\mathrm{gate}} \\colon \\mathbb{R}^F \\to\n",
    "    \\mathbb{R}` and :math:`h_{\\mathbf{\\Theta}}` denote neural networks, *i.e.*\n",
    "    MLPS.\n",
    "    Args:\n",
    "        gate_nn (torch.nn.Module): A neural network :math:`h_{\\mathrm{gate}}`\n",
    "            that computes attention scores by mapping node features :obj:`x` of\n",
    "            shape :obj:`[-1, in_channels]` to shape :obj:`[-1, 1]`, *e.g.*,\n",
    "            defined by :class:`torch.nn.Sequential`.\n",
    "        nn (torch.nn.Module, optional): A neural network\n",
    "            :math:`h_{\\mathbf{\\Theta}}` that maps node features :obj:`x` of\n",
    "            shape :obj:`[-1, in_channels]` to shape :obj:`[-1, out_channels]`\n",
    "            before combining them with the attention scores, *e.g.*, defined by\n",
    "            :class:`torch.nn.Sequential`. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_node_features, num_out_features):\n",
    "        super(MyConditionalGlobalAttention, self).__init__()\n",
    "        channels = num_out_features\n",
    "        self.gate_nn = Seq(Lin(channels, channels), ReLU(), Lin(channels, 1))\n",
    "        self.node_nn = Seq(Lin(num_node_features, channels), ReLU(), Lin(channels, channels))\n",
    "        self.ques_nn = Seq(Lin(channels, channels), ReLU(), Lin(channels, channels))\n",
    "        # self.gate_nn = Lin(channels, 1)\n",
    "        # self.node_nn = Lin(channels, channels)\n",
    "        # self.nn = Lin(num_node_features, channels)\n",
    "        self.my_layer = Lin(num_node_features, channels)#\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch_geometric.nn.inits.reset(self.gate_nn)\n",
    "        torch_geometric.nn.inits.reset(self.node_nn)\n",
    "        torch_geometric.nn.inits.reset(self.ques_nn)\n",
    "\n",
    "    # def forward(self, x, u, batch, size=None):#\n",
    "    def forward(self, x, batch, size=None):\n",
    "        \"\"\"\"\"\"\n",
    "        x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        size = batch[-1].item() + 1 if size is None else size\n",
    "\n",
    "        # gate = self.gate_nn(x).view(-1, 1)\n",
    "\n",
    "        ##################################\n",
    "        # Batch\n",
    "        # shape: x - [ Num of Nodes, num_node_features] --> [ Num of Nodes, Feature Channels ]\n",
    "        # shape: u - [ Batch Size, Feature Channels]\n",
    "        # shape: u[batch] - [ Num of Nodes, Feature Channels]\n",
    "        ##################################\n",
    "        my_x=self.my_layer(x)#\n",
    "        x = self.node_nn(x) # if self.node_nn is not None else x\n",
    "\n",
    "        # print(\"x\", x.size(), \"u\", u.size(), \"u[batch]\", u[batch].size())\n",
    "\n",
    "        ##################################\n",
    "        # torch.bmm\n",
    "        # batch1 and batch2 must be 3D Tensors each containing the same number of matrices.\n",
    "        # If batch1 is a b x n x m Tensor, batch2 is a b x m x p Tensor, out will be a b x n x p Tensor.\n",
    "        ##################################\n",
    "\n",
    "\n",
    "        # gate = self.gate_nn(self.ques_nn(u)[batch] * x)#\n",
    "        gate = self.gate_nn(x)#\n",
    "        assert gate.dim() == x.dim() and gate.size(0) == x.size(0)\n",
    "\n",
    "        # gate = torch.bmm(x.unsqueeze(1) , self.ques_nn(u)[batch].unsqueeze(2)).squeeze(-1)\n",
    "        # assert gate.dim() == x.dim() and gate.size(0) == x.size(0)\n",
    "\n",
    "        gate = torch_geometric.utils.softmax(gate, batch, num_nodes=size)\n",
    "        out = scatter_add(gate * x, batch, dim=0, dim_size=size)\n",
    "        \n",
    "        my_out=scatter_add(my_x, batch, dim=0, dim_size=size)#\n",
    "\n",
    "        return my_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(gate_nn={}, node_nn={}, ques_nn={})'.format(self.__class__.__name__,\n",
    "                                              self.gate_nn, self.node_nn, self.ques_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dht3K2yE_4BI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class RecurrentExecutionEngine(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_node_features, num_instr_features, dropout=0.1):\n",
    "        super(RecurrentExecutionEngine, self).__init__()\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_instr_features = num_instr_features\n",
    "\n",
    "        self.engine_one_step_execution_cell = self.get_RecurrentExecutionEngine_layer()\n",
    "        self.graph_layer_norm = my_graph_layernorm.LayerNorm(self.num_node_features)\n",
    "        self.softmax_bitmap_predictor = self.get_softmax_bitmap_predictor()\n",
    "\n",
    "        self.history_vectors_mlp = Seq(\n",
    "                    Lin(num_node_features, num_instr_features),\n",
    "                    ReLU(),\n",
    "                    Lin(num_instr_features, num_instr_features) # output dim\n",
    "                    )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, instr_vectors, batch):\n",
    "        # instr_vectors: [ MaxNumSteps - Like LEN, Batch, Dim]\n",
    "        execution_bitmap = []\n",
    "        history_vector_list = []\n",
    "        batch_size = instr_vectors.size(1)\n",
    "        history_vector = torch.zeros(batch_size, self.num_node_features, device=instr_vectors.device) # init as zero paddings\n",
    "        for instr_idx in range(GQATorchDataset.MAX_EXECUTION_STEP):\n",
    "            u = instr_vectors[instr_idx] # fetch the i^th instruction vector\n",
    "            x_out = self.engine_one_step_execution_cell(x, edge_index, edge_attr, u, history_vector, batch)\n",
    "            x_out = self.graph_layer_norm(x_out, batch)\n",
    "            bitmap_one_step, history_vector = self.softmax_bitmap_predictor(x_out, edge_index, edge_attr, u, history_vector, batch)\n",
    "            execution_bitmap.append(bitmap_one_step)\n",
    "            history_vector_list.append(history_vector)\n",
    "\n",
    "        execution_bitmap = torch.cat(execution_bitmap, dim=1) # [ Num Nodes, Num Steps ]\n",
    "        history_vectors = torch.stack(history_vector_list, dim=0) # [ MaxNumSteps - Like LEN, Batch, Dim]\n",
    "        history_vectors = self.history_vectors_mlp(history_vectors)\n",
    "\n",
    "        return x, execution_bitmap, history_vectors\n",
    "\n",
    "    def get_RecurrentExecutionEngine_layer(self):\n",
    "\n",
    "        num_node_features = self.num_node_features\n",
    "        num_instr_features = self.num_instr_features\n",
    "\n",
    "        class NodeModel(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super(NodeModel, self).__init__()\n",
    "                self.node_mlp_1 = Seq(\n",
    "                    Lin(num_node_features + num_node_features, num_node_features),\n",
    "                    ReLU(),\n",
    "                    Lin(num_node_features, num_node_features)\n",
    "                    )\n",
    "                self.node_mlp_2 = Seq(\n",
    "                    Lin(2 * num_node_features + num_instr_features, num_node_features),\n",
    "                    ReLU(),\n",
    "                    Lin(num_node_features, num_node_features)\n",
    "                    )\n",
    "\n",
    "            def forward(self, x, edge_index, edge_attr, u, history_vector, batch):\n",
    "                row, col = edge_index\n",
    "                # out = x[row]\n",
    "                # u[batch[row]]\n",
    "                out = torch.cat([x[row], history_vector[batch[row]] ], dim=1) # Add edge attribute in future\n",
    "                # out = torch.cat([x[row], edge_attr], dim=1) # Add edge attribute in future\n",
    "                out = self.node_mlp_1(out)\n",
    "                out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n",
    "                out = torch.cat([x, out, u[batch]], dim=1)\n",
    "                return self.node_mlp_2(out) + x # residual connection\n",
    "\n",
    "        return NodeModel()\n",
    "\n",
    "\n",
    "\n",
    "    def get_softmax_bitmap_predictor(self):\n",
    "\n",
    "        num_node_features = self.num_node_features\n",
    "        num_instr_features = self.num_instr_features\n",
    "\n",
    "        class GlobalModel(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                super(GlobalModel, self).__init__()\n",
    "                self.node_mlp_1 = Seq(\n",
    "                    Lin(num_node_features, num_node_features),\n",
    "                    ReLU(),\n",
    "                    Lin(num_node_features, 1)\n",
    "                    )\n",
    "\n",
    "            def forward(self, x, edge_index, edge_attr, u, history_vector, batch):\n",
    "                gate = self.node_mlp_1(x)\n",
    "                assert gate.dim() == x.dim() and gate.size(0) == x.size(0)\n",
    "                # gate = torch.bmm(x.unsqueeze(1) , self.ques_nn(u)[batch].unsqueeze(2)).squeeze(-1)\n",
    "                # assert gate.dim() == x.dim() and gate.size(0) == x.size(0)\n",
    "                gate = torch_geometric.utils.softmax(gate, batch, num_nodes=None)\n",
    "                new_history_vector = scatter_add(gate * x, batch, dim=0, dim_size=None)\n",
    "                return gate, new_history_vector\n",
    "\n",
    "        return GlobalModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12pVdTGk_NS3"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Transformer for text\n",
    "\"\"\"\n",
    "# helper class for the transformer decoder\n",
    "import math\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "\n",
    "class TransformerProgramDecoder(torch.nn.Module):\n",
    "    # should also be hierarchical\n",
    "\n",
    "    def __init__(self, text_vocab_embedding, vocab_size, text_emb_dim, ninp, nhead, nhid, nlayers, dropout=0.1):\n",
    "        super(TransformerProgramDecoder, self).__init__()\n",
    "        self.text_vocab_embedding = text_vocab_embedding\n",
    "        self.model_type = 'Transformer'\n",
    "        self.emb_proj = torch.nn.Linear(text_emb_dim, ninp)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "\n",
    "        ##################################\n",
    "        # For Hierarchical Deocding\n",
    "        ##################################\n",
    "        TEXT = GQATorchDataset.TEXT\n",
    "        self.num_queries = GQATorchDataset.MAX_EXECUTION_STEP\n",
    "        self.query_embed = torch.nn.Embedding(self.num_queries, ninp)\n",
    "\n",
    "        decoder_layers = torch.nn.TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.coarse_decoder = torch.nn.TransformerDecoder(decoder_layers, nlayers, norm=torch.nn.LayerNorm(ninp))\n",
    "\n",
    "        ##################################\n",
    "        # Decoding\n",
    "        ##################################\n",
    "        decoder_layers = torch.nn.TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(decoder_layers, nlayers, norm=torch.nn.LayerNorm(ninp))\n",
    "        self.ninp = ninp\n",
    "\n",
    "        self.vocab_decoder = torch.nn.Linear(ninp, vocab_size)\n",
    "\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "            https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer.generate_square_subsequent_mask\n",
    "        \"\"\"\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, memory, tgt):\n",
    "\n",
    "        ##################################\n",
    "        # Hierarchical Deocding, first get M instruction vectors\n",
    "        # in a non-autoregressvie manner\n",
    "        # Batch_1_Step_1, Batch_1_Step_N, Batch_2_Step_1, Batch_1_Step_N\n",
    "        # Remember to also update sampling\n",
    "        ##################################\n",
    "        true_batch_size = memory.size(1)\n",
    "        instr_queries = self.query_embed.weight.unsqueeze(1).repeat(1, true_batch_size, 1) # [Len, Batch, Dim]\n",
    "        instr_vectors = self.coarse_decoder(tgt=instr_queries, memory=memory, tgt_mask=None) # [ MaxNumSteps, Batch, Dim]\n",
    "        instr_vectors_reshape = instr_vectors.permute(1, 0, 2)\n",
    "        instr_vectors_reshape = instr_vectors_reshape.reshape( true_batch_size * self.num_queries, -1).unsqueeze(0) # [Len=1, RepeatBatch, Dim]\n",
    "        memory_repeat = memory.repeat_interleave(self.num_queries, dim=1) # [Len, RepeatBatch, Dim]\n",
    "\n",
    "        ##################################\n",
    "        # prepare target mask\n",
    "        ##################################\n",
    "        n_len_seq = tgt.shape[0] # seq len\n",
    "        tgt_mask = self.generate_square_subsequent_mask(\n",
    "                n_len_seq).to(memory.device)\n",
    "\n",
    "        ##################################\n",
    "        # forward model, expect [Len, Batch, Dim]\n",
    "        ##################################\n",
    "        tgt   = self.text_vocab_embedding(tgt)\n",
    "        tgt = self.emb_proj(tgt) * math.sqrt(self.ninp)\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "\n",
    "        ##################################\n",
    "        # Replace the init token feature with instruciton feature\n",
    "        ##################################\n",
    "\n",
    "        tgt = tgt[1:] # [Len, Batch, Dim] discard the start of sentence token\n",
    "        tgt = torch.cat((instr_vectors_reshape, tgt), dim=0) # replace with our init values\n",
    "\n",
    "        output = self.transformer_decoder(tgt=tgt, memory=memory_repeat, tgt_mask=tgt_mask)\n",
    "        output = self.vocab_decoder(output)\n",
    "\n",
    "        # output both prediction and instruction vectors\n",
    "        return output, instr_vectors\n",
    "\n",
    "    def sample(self, memory, tgt):\n",
    "\n",
    "        ##################################\n",
    "        # Hierarchical Deocding, first get M instruction vectors\n",
    "        # in a non-autoregressvie manner\n",
    "        # Batch_1_Step_1, Batch_1_Step_N, Batch_2_Step_1, Batch_1_Step_N\n",
    "        # Remember to also update sampling\n",
    "        ##################################\n",
    "        true_batch_size = memory.size(1)\n",
    "        instr_queries = self.query_embed.weight.unsqueeze(1).repeat(1, true_batch_size, 1) # [Len, Batch, Dim]\n",
    "        instr_vectors = self.coarse_decoder(tgt=instr_queries, memory=memory, tgt_mask=None) # [ MaxNumSteps, Batch, Dim]\n",
    "        instr_vectors_reshape = instr_vectors.permute(1, 0, 2)\n",
    "        instr_vectors_reshape = instr_vectors_reshape.reshape( true_batch_size * self.num_queries, -1).unsqueeze(0) # [Len=1, RepeatBatch, Dim]\n",
    "        memory_repeat = memory.repeat_interleave(self.num_queries, dim=1) # [Len, RepeatBatch, Dim]\n",
    "\n",
    "\n",
    "        tgt = None # discard\n",
    "\n",
    "        max_output_len = 16 # 80 # program concat 80, full answer max 15, instr max 10\n",
    "        batch_size = memory.size(1) * self.num_queries\n",
    "\n",
    "        TEXT = GQATorchDataset.TEXT\n",
    "        output = torch.ones(max_output_len, batch_size).long().to(memory.device) * TEXT.vocab.stoi[TEXT.init_token]\n",
    "\n",
    "\n",
    "        for t in range(1, max_output_len):\n",
    "            tgt = self.text_vocab_embedding(output[:t,:]) # from 0 to t-1\n",
    "            tgt = self.emb_proj(tgt) * math.sqrt(self.ninp)\n",
    "            tgt = self.pos_encoder(tgt) # contains dropout\n",
    "\n",
    "            ##################################\n",
    "            # Replace the init token feature with instruciton feature\n",
    "            ##################################\n",
    "            tgt = tgt[1:] # [Len, Batch, Dim] discard the start of sentence token\n",
    "            tgt = torch.cat((instr_vectors_reshape, tgt), dim=0) # replace with our init values\n",
    "\n",
    "            n_len_seq = t # seq len\n",
    "            tgt_mask = self.generate_square_subsequent_mask(\n",
    "                    n_len_seq).to(memory.device)\n",
    "            # 2D mask (query L, key S)(L,S) where L is the target sequence length, S is the source sequence length.\n",
    "            out = self.transformer_decoder(tgt, memory_repeat, tgt_mask=tgt_mask)\n",
    "            # output: (T, N, E): target len, batch size, embedding size\n",
    "            out = self.vocab_decoder(out)\n",
    "            # target len, batch size, vocab size\n",
    "            output_t = out[-1, :, :].data.topk(1)[1].squeeze()\n",
    "            output[t,:] = output_t\n",
    "\n",
    "        return output, instr_vectors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TransformerFullAnswerDecoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, text_vocab_embedding, vocab_size, text_emb_dim, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerFullAnswerDecoder, self).__init__()\n",
    "        self.text_vocab_embedding = text_vocab_embedding\n",
    "        self.model_type = 'Transformer'\n",
    "        self.emb_proj = torch.nn.Linear(text_emb_dim, ninp)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        decoder_layers = torch.nn.TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(decoder_layers, nlayers, norm=torch.nn.LayerNorm(ninp))\n",
    "        self.ninp = ninp\n",
    "\n",
    "        self.vocab_decoder = torch.nn.Linear(ninp, vocab_size)\n",
    "\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "            https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer.generate_square_subsequent_mask\n",
    "        \"\"\"\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, memory, tgt):\n",
    "        ##################################\n",
    "        # prepare target mask\n",
    "        ##################################\n",
    "        n_len_seq = tgt.shape[0] # seq len\n",
    "        tgt_mask = self.generate_square_subsequent_mask(\n",
    "                n_len_seq).to(memory.device)\n",
    "\n",
    "        ##################################\n",
    "        # forward model, expect [Len, Batch, Dim]\n",
    "        ##################################\n",
    "        # print(\"tgt\", tgt.size(),tgt)\n",
    "        \n",
    "        tgt   = self.text_vocab_embedding(tgt)\n",
    "        # print(\"tgt\", tgt.size())\n",
    "        tgt = self.emb_proj(tgt) * math.sqrt(self.ninp)\n",
    "        # print(\"tgt\", tgt.size())\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        # print(\"tgt\", tgt.size())\n",
    "        output = self.transformer_decoder(tgt=tgt, memory=memory, tgt_mask=tgt_mask)\n",
    "        output = self.vocab_decoder(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def sample(self, memory, tgt):\n",
    "\n",
    "        tgt = None # discard\n",
    "\n",
    "        max_output_len = 20 # 80 # program concat 80, full answer max 15, instr max 10\n",
    "        batch_size = memory.size(1)\n",
    "\n",
    "        TEXT = GQATorchDataset.TEXT\n",
    "        output = torch.ones(max_output_len, batch_size).long().to(memory.device) * TEXT.vocab.stoi[TEXT.init_token]\n",
    "\n",
    "\n",
    "        for t in range(1, max_output_len):\n",
    "            tgt   = self.text_vocab_embedding(output[:t,:]) # from 0 to t-1\n",
    "            tgt = self.emb_proj(tgt) * math.sqrt(self.ninp)\n",
    "            tgt = self.pos_encoder(tgt) # contains dropout\n",
    "\n",
    "            n_len_seq = t # seq len\n",
    "            tgt_mask = self.generate_square_subsequent_mask(\n",
    "                    n_len_seq).to(memory.device)\n",
    "            # 2D mask (query L, key S)(L,S) where L is the target sequence length, S is the source sequence length.\n",
    "            out = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask)\n",
    "            # output: (T, N, E): target len, batch size, embedding size\n",
    "            out = self.vocab_decoder(out)\n",
    "            # target len, batch size, vocab size\n",
    "            output_t = out[-1, :, :].data.topk(1)[1].squeeze()\n",
    "            output[t,:] = output_t\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class TransformerQuestionEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, text_vocab_embedding, text_emb_dim, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerQuestionEncoder, self).__init__()\n",
    "        self.text_vocab_embedding = text_vocab_embedding\n",
    "        self.model_type = 'Transformer'\n",
    "        self.emb_proj = torch.nn.Linear(text_emb_dim, ninp)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers, norm=torch.nn.LayerNorm(ninp) )\n",
    "        self.ninp = ninp\n",
    "\n",
    "    def forward(self, src):\n",
    "\n",
    "        ##################################\n",
    "        # forward model, expect [Len, Batch, Dim]\n",
    "        ##################################\n",
    "        src   = self.text_vocab_embedding(src)\n",
    "        src = self.emb_proj(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GroundTruth_SceneGraph_Encoder(torch.nn.Module):\n",
    "    def __init__(self, graph_type='sg'):\n",
    "        super(GroundTruth_SceneGraph_Encoder, self).__init__()\n",
    "        if graph_type=='sg':\n",
    "          from gqa_dataset_entry import GQA_gt_sg_feature_lookup\n",
    "          sg_TEXT = GQA_gt_sg_feature_lookup.SG_ENCODING_TEXT\n",
    "          sg_vocab = GQA_gt_sg_feature_lookup.SG_ENCODING_TEXT.vocab\n",
    "        else:\n",
    "          from gqa_dataset_entry import GQA_gt_sg_feature_lookup_concept\n",
    "          sg_TEXT = GQA_gt_sg_feature_lookup_concept.SG_ENCODING_TEXT\n",
    "          sg_vocab = GQA_gt_sg_feature_lookup_concept.SG_ENCODING_TEXT.vocab\n",
    "\n",
    "        self.sg_emb_dim = 300 # 300d glove\n",
    "        sg_pad_idx = sg_vocab.stoi[sg_TEXT.pad_token]\n",
    "        self.sg_vocab_embedding = torch.nn.Embedding(len(sg_vocab), self.sg_emb_dim, padding_idx=sg_pad_idx)\n",
    "        # print(f'vocab size#####################################################################:{len(sg_vocab)}')\n",
    "       \n",
    "        # self.sg_vocab_embedding.weight.data.copy_(sg_vocab.vectors)\n",
    "        del sg_TEXT, sg_vocab, sg_pad_idx\n",
    "\n",
    "        ##################################\n",
    "        # build scene graph encoding layer\n",
    "        ##################################\n",
    "        self.scene_graph_encoding_layer = get_gt_scene_graph_encoding_layer(\n",
    "            num_node_features=self.sg_emb_dim,\n",
    "            num_edge_features=self.sg_emb_dim)\n",
    "\n",
    "        self.graph_layer_norm = my_graph_layernorm.LayerNorm(self.sg_emb_dim)\n",
    "\n",
    "    def forward(self,\n",
    "                gt_scene_graphs, phase=None\n",
    "                ):\n",
    "\n",
    "        ##################################\n",
    "        # Use glove embedding to embed ground truth scene graph\n",
    "        ##################################\n",
    "        # [ num_nodes, MAX_OBJ_TOKEN_LEN] -> [ num_nodes, MAX_OBJ_TOKEN_LEN, sg_emb_dim]\n",
    "\n",
    "        x_embed     = self.sg_vocab_embedding(gt_scene_graphs.x)\n",
    "        # if torch.any(torch.isnan(x_embed)) or torch.any(torch.isinf(x_embed)):\n",
    "        #   print(f'x_embed:{x_embed}\\n')\n",
    "        # torch.nn.LayerNorm(3*hid_dim, eps=1e-12)\n",
    "        # print(f'gt_scene_graphs.edge_attr;{gt_scene_graphs.edge_attr}')\n",
    "        # print(f'gt_scene_graphs={gt_scene_graphs}')\n",
    "        # print(f'sg_vocab_embedding={self.sg_vocab_embedding}')\n",
    "        # print(f'sg_vocab_embedding_shape={self.sg_vocab_embedding}')\n",
    "        # print(f'weight={self.sg_vocab_embedding.weight}')\n",
    "        # print(f'weight_shape={self.sg_vocab_embedding.weight.shape}')\n",
    "        # print(f'gt_scene_graphs.x;{gt_scene_graphs.x}\\n')\n",
    "        # print(f'gt_scene_graphs.x_shape;{gt_scene_graphs.x.shape}\\n')\n",
    "        # print(f'x_embed={x_embed}')\n",
    "        # print(f'x_embed_shape={x_embed.shape}')\n",
    "        # print(f'x_embedweight={self.sg_vocab_embedding(gt_scene_graphs.x).weight@ W.t()}')\n",
    "        # print(f'x_embedweight_shape={self.sg_vocab_embedding(gt_scene_graphs.x).weight@ W.t()}')\n",
    "          \n",
    "\n",
    "        # [ num_nodes, MAX_OBJ_TOKEN_LEN, sg_emb_dim] -> [ num_nodes, sg_emb_dim]\n",
    "        x_embed_sum = torch.sum(input=x_embed, dim=-2, keepdim=False)\n",
    "        # if torch.any(torch.isnan(x_embed_sum)) or torch.any(torch.isinf(x_embed_sum)):\n",
    "        #   print(f'x_embed_sum:{x_embed_sum}\\n')\n",
    "\n",
    "        # [ num_edges, MAX_EDGE_TOKEN_LEN] -> [ num_edges, MAX_EDGE_TOKEN_LEN, sg_emb_dim]\n",
    "        edge_attr_embed = self.sg_vocab_embedding(gt_scene_graphs.edge_attr)\n",
    "        # print(f'weight={self.sg_vocab_embedding.weight}')\n",
    "        # print(f'weight_shape={self.sg_vocab_embedding.weight.shape}')\n",
    "        # print(f'gt_scene_graphs.edge_attr;{gt_scene_graphs.edge_attr}')\n",
    "        # print(f'gt_scene_graphs.edge_attr_shape;{gt_scene_graphs.edge_attr.shape}')\n",
    "        # print(f'edge_attr_embed={edge_attr_embed}')\n",
    "        # print(f'edge_attr_embed_shape={edge_attr_embed.shape}')\n",
    "        \n",
    "        # if torch.any(torch.isnan(edge_attr_embed)) or torch.any(torch.isinf(edge_attr_embed)):\n",
    "          # print(f'gt_scene_graphs.edge_attr;{gt_scene_graphs.edge_attr}\\n')\n",
    "          # print(f'edge_attr_embed:{edge_attr_embed}\\n')\n",
    "        # yanhao: for the manually added symmetric edges, reverse the sign of emb to denote reverse relationship:\n",
    "        edge_attr_embed[gt_scene_graphs.added_sym_edge, :, :] *= -1\n",
    "\n",
    "\n",
    "        # [ num_edges, MAX_EDGE_TOKEN_LEN, sg_emb_dim] -> [ num_edges, sg_emb_dim]\n",
    "        edge_attr_embed_sum   = torch.sum(input=edge_attr_embed, dim=-2, keepdim=False)\n",
    "        # if torch.any(torch.isnan(edge_attr_embed_sum)) or torch.any(torch.isinf(edge_attr_embed_sum)):\n",
    "        #   print(f'edge_attr_embed_sum:{edge_attr_embed_sum}\\n')\n",
    "        del x_embed, edge_attr_embed\n",
    "\n",
    "        ##################################\n",
    "        # Call scene graph encoding layer\n",
    "        ##################################\n",
    "\n",
    "        x_encoded, edge_attr_encoded, _ = self.scene_graph_encoding_layer(\n",
    "            x=x_embed_sum,\n",
    "            edge_index=gt_scene_graphs.edge_index,\n",
    "            edge_attr=edge_attr_embed_sum,\n",
    "            u=None,\n",
    "            batch=gt_scene_graphs.batch\n",
    "            )\n",
    "        # if torch.any(torch.isnan(x_encoded)) or torch.any(torch.isinf(x_encoded)):\n",
    "        #   print(f'x_encoded:{x_encoded}\\n')\n",
    "        x_encoded = self.graph_layer_norm(x_encoded, gt_scene_graphs.batch)\n",
    "\n",
    "        return x_encoded, edge_attr_encoded, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FM0iJCvpoHDF"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch_geometric.nn import Sequential, GCNConv, JumpingKnowledge\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "\n",
    "# my_short_answer_logits=Sequential('x, edge_index, batch', [\n",
    "#     (Dropout(p=0.5), 'x -> x'),\n",
    "#     (GCNConv(self.scene_graph_encoder.sg_emb_dim, 64), 'x, edge_index -> x1'),\n",
    "#     ReLU(inplace=True),\n",
    "#     (GCNConv(64, 64), 'x1, edge_index -> x2'),\n",
    "#     ReLU(inplace=True),\n",
    "#     (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n",
    "#     (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n",
    "#     (global_mean_pool, 'x, batch -> x'),\n",
    "#     Linear(2 * 64, 54),\n",
    "# ])\n",
    "\n",
    "class my_gcn_sg(torch.nn.Module):\n",
    "    # def __init__(self, in_channels, out_channels, ins_dim, dropout=0.0):#\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):#\n",
    "\n",
    "        super(my_gcn_sg, self).__init__()\n",
    "        # self.edge_weight = torch.nn.Parameter(torch.ones(edge_index.shape[1]))\n",
    "        \n",
    "        self.layers=2\n",
    "        self.conv1=GCNConv(in_channels, out_channels)\n",
    "        self.conv2=GCNConv(out_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "        # self.jumpknow=JumpingKnowledge(mode=\"cat\")#, channels=64, num_layers=2\n",
    "        self.layernorm=nn.LayerNorm(out_channels)\n",
    "        self.linlayer=Lin(out_channels*self.layers, out_channels)\n",
    "        self.simplelayer=Lin(in_channels, out_channels)\n",
    "        self.graph_global_attention = Attention(\n",
    "            dim=out_channels) \n",
    "\n",
    "        # self.edge_weight=None\n",
    "        # self.flag=True\n",
    "        # self.register_parameter('edge_weight',None)\n",
    "\n",
    "    # def reset_parameters(self,edge_index_t):\n",
    "    #   self.edge_weight = nn.Parameter(torch.ones((edge_index_t.size(1),),dtype=None, device=edge_index_t.device, requires_grad=True).cuda())\n",
    "    #   print('###############################')\n",
    "\n",
    "    def forward(self, x, edge_index, batch):#\n",
    "\n",
    "        # if self.edge_weight is None:\n",
    "\t      #   self.reset_parameters(edge_index)\n",
    "        # x = F.relu(x)\n",
    "        x=F.dropout(x, p=self.dropout)\n",
    "        x0=self.simplelayer(x)\n",
    "        # x0=self.layernorm(x0)\n",
    "        x0 = F.relu(x0)\n",
    "        x1=self.conv1(x, edge_index)\n",
    "        # print(\"conv1 weight:\", self.conv1.lin.weight.shape)\n",
    "        # print(\"weight_shap\",self.conv1.edge_weight)\n",
    "        # x1=self.layernorm(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        # x1=F.dropout(x1, p=self.dropout)\n",
    "        x2=self.conv2(x1, edge_index)\n",
    "        # x2=self.layernorm(x2)\n",
    "        # x2=torch.add(x0,x2)\n",
    "        x2 = F.relu(x2)\n",
    "        # x2=F.dropout(x2, p=self.dropout)\n",
    "        x3=self.conv2(x2, edge_index)\n",
    "        # x3=self.layernorm(x3)\n",
    "        x3 = F.relu(x3)\n",
    "        # x3=F.dropout(x3, p=self.dropout)\n",
    "        x4=self.conv2(x3, edge_index)\n",
    "        # x4=self.layernorm(x4)\n",
    "        # # x4=torch.add(x2,x4)\n",
    "        x4 = F.relu(x4)\n",
    "        # out=self.simplelayer(x4)\n",
    "        # x4=F.dropout(x4, p=self.dropout)\n",
    "        # x5=self.conv2(x4, edge_index=edge_index)\n",
    "        # x5 = F.relu(x5)\n",
    "        # xs=[]\n",
    "        # xo=x0\n",
    "        # xo=torch.cat( (x0, x1), dim=-1)\n",
    "        # xo=torch.cat( (xo, x2), dim=-1)\n",
    "        # xo=torch.cat( (xo, x3), dim=-1)\n",
    "        # xo=torch.cat( (xo, x4), dim=-1)\n",
    "  \n",
    "        x0=self.layernorm(x0)\n",
    "        x1=self.layernorm(x1)\n",
    "        x2=self.layernorm(x2)\n",
    "        x3=self.layernorm(x3)\n",
    "        x4=self.layernorm(x4)\n",
    "        qkv=torch.stack([x0, x1, x2, x3, x4],dim=1)\n",
    "        # qkv=self.dropout(self.normalize(qkv))\n",
    "        \n",
    "        # qkv=torch.cat( (gcn_sg, gcn_concept), dim=1 )\n",
    "        # graph_final_feature = self.graph_global_attention(q = qkv, k = qkv, v=qkv, batch=gt_scene_graphs.batch)\n",
    "        graph_final_feature, attent_weight = self.graph_global_attention(qkv,qkv)\n",
    "        \n",
    "        # graph_final_feature = self.graph_global_attention(qkv, qkv, qkv)\n",
    "        # graph_final_feature, attent_weight = self.multihead_attn(qkv, qkv, qkv)\n",
    "        # print(graph_final_feature.shape)\n",
    "        # x = torch.cat( (gcn_sg, gcn_concept, gcn_sg*gcn_concept), dim=-1 )\n",
    "        \n",
    "        # graph_final_feature = self.dropout(graph_final_feature)\n",
    "        # graph_final_feature=self.normalize(graph_final_feature)\n",
    "        # print(qkv.shape)\n",
    "        # print(graph_final_feature.shape)\n",
    "        xo=graph_final_feature.contiguous().view(graph_final_feature.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "        # xo=torch.cat( (xo, x5), dim=-1)\n",
    "        # xs=lambda x1, x2: [x1, x2]\n",
    "        # xs.append(x1)\n",
    "        # xs.append(x2)\n",
    "        # xs.append(x3)\n",
    "        # xs.append(x4)\n",
    "        # xo=torch.as_tensor(xs)\n",
    "        # xs.append(x5)\n",
    "        # xo=self.jumpknow(xs)\n",
    "\n",
    "        out=global_add_pool(xo,batch)\n",
    "        # out=self.linlayer(xs)\n",
    "        # out=F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOEpgXHgxUho"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    r\"\"\"\n",
    "    Applies an attention mechanism on the output features from the decoder.\n",
    "    .. math::\n",
    "            \\begin{array}{ll}\n",
    "            x = context*output \\\\\n",
    "            attn = exp(x_i) / sum_j exp(x_j) \\\\\n",
    "            output = \\tanh(w * (attn * context) + b * output)\n",
    "            \\end{array}\n",
    "    Args:\n",
    "        dim(int): The number of expected features in the output\n",
    "    Inputs: output, context\n",
    "        - **output** (batch, output_len, dimensions): tensor containing the output features from the decoder.\n",
    "        - **context** (batch, input_len, dimensions): tensor containing features of the encoded input sequence.\n",
    "    Outputs: output, attn\n",
    "        - **output** (batch, output_len, dimensions): tensor containing the attended output features from the decoder.\n",
    "        - **attn** (batch, output_len, input_len): tensor containing attention weights.\n",
    "    Attributes:\n",
    "        linear_out (torch.nn.Linear): applies a linear transformation to the incoming data: :math:`y = Ax + b`.\n",
    "        mask (torch.Tensor, optional): applies a :math:`-inf` to the indices specified in the `Tensor`.\n",
    "    Examples::\n",
    "         >>> attention = seq2seq.models.Attention(256)\n",
    "         >>> context = Variable(torch.randn(5, 3, 256))\n",
    "         >>> output = Variable(torch.randn(5, 5, 256))\n",
    "         >>> output, attn = attention(output, context)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.linear_out = nn.Linear(dim*2, dim)\n",
    "        self.mask = None\n",
    "\n",
    "    def set_mask(self, mask):\n",
    "        \"\"\"\n",
    "        Sets indices to be masked\n",
    "        Args:\n",
    "            mask (torch.Tensor): tensor containing indices to be masked\n",
    "        \"\"\"\n",
    "        self.mask = mask\n",
    "    def forward(self, output, context):\n",
    "        \n",
    "        batch_size = output.size(0)\n",
    "        hidden_size = output.size(2)\n",
    "        input_size = context.size(1)\n",
    "        \n",
    "        # (batch, out_len, dim) * (batch, in_len, dim) -> (batch, out_len, in_len)\n",
    "        attn = torch.bmm(output, context.transpose(1, 2))\n",
    "        # print(output.shape, context.shape)\n",
    "        # print(attn.shape)\n",
    "        if self.mask is not None:\n",
    "            attn.data.masked_fill_(self.mask, -float('inf'))\n",
    "        attn = F.softmax(attn.view(-1, input_size), dim=1).view(batch_size, -1, input_size)\n",
    "        \n",
    "\n",
    "        # (batch, out_len, in_len) * (batch, in_len, dim) -> (batch, out_len, dim)\n",
    "        mix = torch.bmm(attn, context)\n",
    "        # print(attn.shape)\n",
    "\n",
    "        # concat -> (batch, out_len, 2*dim)\n",
    "        combined = torch.cat((mix, output), dim=2)\n",
    "        # output=combined\n",
    "        # output -> (batch, out_len, dim)\n",
    "        output = F.relu(self.linear_out(combined.view(-1, 2 * hidden_size))).view(batch_size, -1, hidden_size)\n",
    "        # print(output.shape)\n",
    "\n",
    "        return output, attn\n",
    "    # def forward(self, output, context):\n",
    "    #     print(output.shape)\n",
    "    #     print(output.size(0))\n",
    "    #     print(output.size(-2))\n",
    "    #     print(context.size(1))\n",
    "    #     batch_size = output.size(0)   \n",
    "    #     hidden_size = output.size(-2)\n",
    "    #     input_size = context.size(-1)\n",
    "    #     # (batch, out_len, dim) * (batch, in_len, dim) -> (batch, out_len, in_len)\n",
    "    #     print(output.shape, context.shape, context.transpose(-1, -2).shape)\n",
    "    #     attn = torch.bmm(output, context.transpose(-1, -2))\n",
    "    #     if self.mask is not None:\n",
    "    #         attn.data.masked_fill_(self.mask, -float('inf'))\n",
    "    #     attn = F.softmax(attn.view(-1, input_size), dim=-1).view(batch_size, -1, input_size)\n",
    "\n",
    "    #     # (batch, out_len, in_len) * (batch, in_len, dim) -> (batch, out_len, dim)\n",
    "    #     mix = torch.bmm(attn, context)\n",
    "\n",
    "    #     # concat -> (batch, out_len, 2*dim)\n",
    "    #     combined = torch.cat((mix, output), dim=-2)\n",
    "    #     # output -> (batch, out_len, dim)\n",
    "    #     output = F.tanh(self.linear_out(combined.view(-1, 2 * hidden_size))).view(batch_size, -1, hidden_size)\n",
    "\n",
    "    #     return output, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cG2vvxUyc9em"
   },
   "outputs": [],
   "source": [
    "class MyAttention(torch.nn.Module):\n",
    "    r\"\"\"Language-Conditioned Global soft attention layer\n",
    "    .. math::\n",
    "        \\mathbf{r}_i = \\sum_{n=1}^{N_i} \\mathrm{softmax} \\left(\n",
    "        h_{\\mathrm{gate}} ( u[batch] ) \\dot h_{\\mathbf{\\Theta}} ( \\mathbf{x}_n ) \\right)\n",
    "        \\odot\n",
    "        h_{\\mathbf{\\Theta}} ( \\mathbf{x}_n ),\n",
    "    where :math:`h_{\\mathrm{gate}} \\colon \\mathbb{R}^F \\to\n",
    "    \\mathbb{R}` and :math:`h_{\\mathbf{\\Theta}}` denote neural networks, *i.e.*\n",
    "    MLPS.\n",
    "    Args:\n",
    "        gate_nn (torch.nn.Module): A neural network :math:`h_{\\mathrm{gate}}`\n",
    "            that computes attention scores by mapping node features :obj:`x` of\n",
    "            shape :obj:`[-1, in_channels]` to shape :obj:`[-1, 1]`, *e.g.*,\n",
    "            defined by :class:`torch.nn.Sequential`.\n",
    "        nn (torch.nn.Module, optional): A neural network\n",
    "            :math:`h_{\\mathbf{\\Theta}}` that maps node features :obj:`x` of\n",
    "            shape :obj:`[-1, in_channels]` to shape :obj:`[-1, out_channels]`\n",
    "            before combining them with the attention scores, *e.g.*, defined by\n",
    "            :class:`torch.nn.Sequential`. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_node_features, num_out_features):\n",
    "        super(MyAttention, self).__init__()\n",
    "        channels = num_out_features\n",
    "        self.gate_nn = Seq(Lin(channels, channels), ReLU(), Lin(channels, 1))\n",
    "        self.node_nn = Seq(Lin(num_node_features, channels), ReLU(), Lin(channels, channels))\n",
    "        self.ques_nn = Seq(Lin(channels, channels), ReLU(), Lin(channels, channels))\n",
    "        # self.gate_nn = Lin(channels, 1)\n",
    "        # self.node_nn = Lin(channels, channels)\n",
    "        # self.nn = Lin(num_node_features, channels)\n",
    "        self.my_layer = Lin(2*num_node_features, channels)#\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch_geometric.nn.inits.reset(self.gate_nn)\n",
    "        torch_geometric.nn.inits.reset(self.node_nn)\n",
    "        torch_geometric.nn.inits.reset(self.ques_nn)\n",
    "\n",
    "    def forward(self, x, u, batch, size=None):#\n",
    "    # def forward(self, x, batch, size=None):\n",
    "        \"\"\"\"\"\"\n",
    "        ques=torch.cat( ( x, u), dim=-1 )\n",
    "        # x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        # u = u.unsqueeze(-1) if u.dim() == 1 else u\n",
    "        size = batch[-1].item() + 1 if size is None else size\n",
    "\n",
    "        # gate = self.gate_nn(x).view(-1, 1)\n",
    "\n",
    "        ##################################\n",
    "        # Batch\n",
    "        # shape: x - [ Num of Nodes, num_node_features] --> [ Num of Nodes, Feature Channels ]\n",
    "        # shape: u - [ Batch Size, Feature Channels]\n",
    "        # shape: u[batch] - [ Num of Nodes, Feature Channels]\n",
    "        ##################################\n",
    "        # my_x=self.my_layer(x)#\n",
    "        x = self.node_nn(x) # if self.node_nn is not None else x\n",
    "        u=self.node_nn(u)\n",
    "        ques=self.my_layer(ques)\n",
    "\n",
    "        # print(\"x\", x.size(), \"u\", u.size(), \"u[batch]\", u[batch].size())\n",
    "\n",
    "        ##################################\n",
    "        # torch.bmm\n",
    "        # batch1 and batch2 must be 3D Tensors each containing the same number of matrices.\n",
    "        # If batch1 is a b x n x m Tensor, batch2 is a b x m x p Tensor, out will be a b x n x p Tensor.\n",
    "        ##################################\n",
    "\n",
    "\n",
    "        # gate = self.gate_nn(self.ques_nn(u)[batch] * x)#\n",
    "        gate = self.gate_nn(self.ques_nn(ques)[batch] * x)\n",
    "        # gate = self.gate_nn(x)#\n",
    "        assert gate.dim() == x.dim() and gate.size(0) == x.size(0)\n",
    "\n",
    "        # gate = torch.bmm(x.unsqueeze(1) , self.ques_nn(u)[batch].unsqueeze(2)).squeeze(-1)\n",
    "        # assert gate.dim() == x.dim() and gate.size(0) == x.size(0)\n",
    "\n",
    "        gate = torch_geometric.utils.softmax(gate, batch, num_nodes=size)\n",
    "        out = scatter_add(gate * x, batch, dim=0, dim_size=size)\n",
    "        \n",
    "        # my_out=scatter_add(my_x, batch, dim=0, dim_size=size)#\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvFB35mL-45E"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sequence of 5 GCN layers, takes in node features only and ouput the last layer's hidden states\n",
    "\"\"\"\n",
    "\n",
    "class gcn_seq(torch.nn.Module):\n",
    "    # def __init__(self, in_channels, out_channels, ins_dim, dropout=0.0):#\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):#\n",
    "\n",
    "        super(gcn_seq, self).__init__()\n",
    "\n",
    "        # 5 layers of conv with  BN, ReLU, and Dropout in between\n",
    "        # self.convs = torch.nn.ModuleList([GCNConv(in_channels+ins_dim, out_channels) for _ in range(5)])#\n",
    "        # self.convs = torch.nn.ModuleList([GCNConv(in_channels, out_channels)])\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(in_channels, out_channels) for _ in range(5)])#\n",
    "\n",
    "        # for the last output, no batch norm\n",
    "        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(out_channels) for _ in range(5-1)]) \n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # def forward(self, x, edge_index, instr_vectors, batch):#\n",
    "    def forward(self, x, edge_index, batch):#\n",
    "\n",
    "        num_conv_layers = len(self.convs)\n",
    "\n",
    "        h = x\n",
    "        for i in range(num_conv_layers):\n",
    "\n",
    "            # concat the inputs:\n",
    "            # ins = instr_vectors[i] # shape: batch_size X instruction_dim#\n",
    "\n",
    "            # repeated_ins_node = ins[batch] # pick correct batched instruction for each node#\n",
    "            # x_cat = torch.cat((h, repeated_ins_node), dim=-1) # concat the previous layer node hidden rep with the instruction vector#\n",
    "\n",
    "\n",
    "            # feed into the conv:\n",
    "\n",
    "            x_cat=h\n",
    "            conv_res = self.convs[i](x=x_cat, edge_index=edge_index)#\n",
    "            # conv_res = self.convs[i](x, edge_index=edge_index)#\n",
    "\n",
    "            # do BN, ReLU, Droupout in-between all conv layers\n",
    "            if i != num_conv_layers-1:\n",
    "                h = self.bns[i](h)\n",
    "                h = F.relu(h)\n",
    "                h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "\n",
    "        return h # return the last layer's hidden rep.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sboiKHfqGQSZ"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pathlib\n",
    "import util.misc as utils\n",
    "\n",
    "from gqa_dataset_entry import GQATorchDataset, GQATorchDataset_collate_fn\n",
    "# from pipeline_model_gcn import PipelineModel # use naive GCN model\n",
    "import json\n",
    "# GPU settings\n",
    "# assert torch.cuda.is_available()\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = config.GPU\n",
    "# device = torch.device(\"cuda\")\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# cudnn.benchmark = True\n",
    "cuda = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    # Default CUDA device\n",
    "cuda=\"cpu\"\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Explainable GQA Parser', add_help=False)\n",
    "    parser.add_argument('--data', metavar='PATH', default='./',\n",
    "                        help='path to dataset')\n",
    "    parser.add_argument('--save-dir', metavar='PATH', default='./',\n",
    "                        help='path to dataset')\n",
    "    # parser.add_argument('--log-name', default='tmp.log', type=str, metavar='PATH',\n",
    "    # parser.add_argument('--log-name', default='detrDEBUG.log', type=str, metavar='PATH',\n",
    "    # parser.add_argument('--log-name', default='detr.log', type=str, metavar='PATH',\n",
    "    # parser.add_argument('--log-name', default='detrDEV.log', type=str, metavar='PATH',\n",
    "    parser.add_argument('--log-name', default='gtsg.log', type=str, metavar='PATH',\n",
    "                        help='path to the log file (default: output.log)')\n",
    "    # parser.add_argument('-j', '--workers', default=2, type=int, metavar='N',\n",
    "    parser.add_argument('-j', '--workers', default=32, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4, 32)')\n",
    "    parser.add_argument('--epochs', default=300, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                        help='manual epoch number (useful on restarts)')\n",
    "    # parser.add_argument('-b', '--batch-size', default=1024, type=int,\n",
    "    # parser.add_argument('-b', '--batch-size', default=512, type=int,\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int,\n",
    "                        metavar='N',\n",
    "                        help='mini-batch size (default: 256), this is the total '\n",
    "                             'batch size of all GPUs on the current node when '\n",
    "                             'using Data Parallel or Distributed Data Parallel')\n",
    "    # parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float,\n",
    "    parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float,\n",
    "                        metavar='LR', help='initial learning rate', dest='lr')\n",
    "    parser.add_argument('--lr_drop', default=30, type=int)\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                        help='momentum')\n",
    "    parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)',\n",
    "                        dest='weight_decay')\n",
    "    # parser.add_argument('-p', '--print-freq', default=1, type=int,\n",
    "    parser.add_argument('-p', '--print-freq', default=50, type=int,\n",
    "                        metavar='N', help='print frequency (default: 10)')\n",
    "    parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                        help='path to latest checkpoint (default: none)')\n",
    "    parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                        help='evaluate model on validation set')\n",
    "    parser.add_argument('--evaluate_sets', default=['val_unbiased'], nargs='+',\n",
    "                        help='Data sets/splits to perform evaluation, e.g. '\n",
    "                             'val_unbiased, testdev etc. Multiple sets/splits '\n",
    "                             'are supported and need to be separated by space')\n",
    "    # parser.add_argument('--seed', default=1234, type=int,\n",
    "    parser.add_argument('--seed', default=1234, type=int,\n",
    "                        help='seed for initializing training. ')\n",
    "    # parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
    "    #                     help='Use multi-processing distributed training to launch '\n",
    "    #                         'N processes per node, which has N GPUs. This is the '\n",
    "    #                         'fastest way to use PyTorch for either single node or '\n",
    "    #                         'multi node data parallel training')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='./outputdir',\n",
    "                        help='path where to save, empty for no saving')\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')\n",
    "\n",
    "    return parser\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "        ##################################\n",
    "        # Save to logging\n",
    "        ##################################\n",
    "        if utils.is_main_process():\n",
    "            logging.info('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def accuracy_topk(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "      \n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        # print(f'res{res}')  \n",
    "        return res\n",
    "\n",
    "class Metrics(object):\n",
    "    \"\"\"\n",
    "    metric is an abstract class.\n",
    "    Args:\n",
    "        average (bool): a way to output one single value for metrics\n",
    "                        that are calculated in several trials.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, average=True, **kwargs):\n",
    "        self._average = average\n",
    "        self.eps = 1e-20\n",
    "        self.reset()\n",
    "        self.result = torch.FloatTensor()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the private values of the class.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update(self, output=None, target=None):\n",
    "        \"\"\"\n",
    "        Main calculation of the metric which updated the private values respectively.\n",
    "        Args:\n",
    "            output (tensor): predictions of model\n",
    "            target (tensor): labels\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def calculate_result(self):\n",
    "        \"\"\"calculate the final values when the epoch/batch loop\n",
    "        is finished.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        warnings.warn('`avg` is deprecated, please use `value`.', DeprecationWarning)\n",
    "        return self.value\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        \"\"\"output the metric results (array shape) or averaging\n",
    "        out over the results to output one single float number.\n",
    "        Returns:\n",
    "            result (np.array / float): final metric result\n",
    "        \"\"\"\n",
    "        self.result = torch.FloatTensor(self.calculate_result())\n",
    "        if self._average and self.result.numel() == self.result.size(0):\n",
    "            return self.result.mean(0).cpu().numpy().item()\n",
    "        elif self._average:\n",
    "            return self.result.mean(0).cpu().numpy()\n",
    "        else:\n",
    "            return self.result.cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def standard_dev(self):\n",
    "        \"\"\"Return the standard deviation of the metric.\"\"\"\n",
    "        result = torch.FloatTensor(self.calculate_result())\n",
    "        if result.numel() == result.size(0):\n",
    "            return result.std(0).cpu().numpy().item()\n",
    "        else:\n",
    "            return result.std(0).cpu().numpy()\n",
    "\n",
    "    def __str__(self):\n",
    "        val = self.value\n",
    "        std = self.standard_dev\n",
    "        if isinstance(val, np.ndarray):\n",
    "            return \", \".join(f\"{v:.3f}±{s:.3f}\" for v, s in zip(val, std))\n",
    "        else:\n",
    "            return f\"{val:.3f}±{std:.3f}\"\n",
    "\n",
    "class Precision_class(Metrics):\n",
    "    \"\"\"computes the precision for each class over epochs.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        average (bool): a way to output one single value for metrics\n",
    "                        that are calculated in several trials.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, average=True, **kwargs):\n",
    "        self.n_class = num_classes\n",
    "        super().__init__(average=average)\n",
    "        self._true_positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self._true_positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._false_positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "\n",
    "    def update(self, output=None, target=None):\n",
    "        \"\"\"\n",
    "        Update tp, fp and support acoording to output and target.\n",
    "        Args:\n",
    "            output (tensor): predictions of model\n",
    "            target (tensor): labels\n",
    "        \"\"\"\n",
    "        # (batch, 1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        # (batch, nclass)\n",
    "        indices = torch.argmax(output, dim=1).view(-1)\n",
    "\n",
    "        output = indices.type_as(target)\n",
    "        correct = output.eq(target.expand_as(output))\n",
    "        # print(f'output{output}')\n",
    "        # print(f'target{target}')\n",
    "\n",
    "        # Convert from int cuda/cpu to double cpu\n",
    "        for class_index in target:\n",
    "            self._positives[class_index] += 1\n",
    "        for class_index in indices[(correct == 1).nonzero()]:\n",
    "            self._true_positives[class_index] += 1\n",
    "        for class_index in indices[(correct == 0).nonzero()]:\n",
    "            self._false_positives[class_index] += 1\n",
    "\n",
    "    def calculate_result(self):\n",
    "        # print(f'true_pos={self._true_positives}')\n",
    "        # print(f'false_pos={self._false_positives}')\n",
    "        result = self._true_positives / self._positives\n",
    "        # precision_div=self._true_positives+self._false_positives\n",
    "        # result = self._true_positives / precision_div if precision_div != 0 else 0\n",
    "\n",
    "        # where the class never was shown in targets\n",
    "        result[result != result] = 0\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __str__(self):\n",
    "      return f'Precision: {torch.mean(self.calculate_result())}'\n",
    "\n",
    "class Recall_class(Metrics):\n",
    "    \"\"\"computes the precision for each class over epochs.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        average (bool): a way to output one single value for metrics\n",
    "                        that are calculated in several trials.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, average=True, **kwargs):\n",
    "        self.n_class = num_classes\n",
    "        super().__init__(average=average)\n",
    "        self._true_positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._label_imageid=[[] for i in range(self.n_class)]\n",
    "\n",
    "    def reset(self):\n",
    "        self._true_positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._false_negatives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._label_imageid=[{} for i in range(self.n_class)]\n",
    "\n",
    "    def update(self, image_id, output=None, target=None):\n",
    "        \"\"\"\n",
    "        Update tp, fp and support acoording to output and target.\n",
    "        Args:\n",
    "            output (tensor): predictions of model\n",
    "            target (tensor): labels\n",
    "        \"\"\"\n",
    "        # (batch, 1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        # (batch, nclass)\n",
    "        indices = torch.argmax(output, dim=1).view(-1)\n",
    "\n",
    "        output = indices.type_as(target)\n",
    "        correct = output.eq(target.expand_as(output))\n",
    "        # print(f'output{output}')\n",
    "        # print(f'target{target}')\n",
    "\n",
    "        # Convert from int cuda/cpu to double cpu\n",
    "        # for class_index in target:\n",
    "        for class_index in output:\n",
    "            self._positives[class_index] += 1\n",
    "        for idx, class_index in enumerate(indices[(correct == 1).nonzero()]):\n",
    "            self._true_positives[class_index] += 1\n",
    "            # self._label_imageid[class_index[1]].append(image_id[class_index[0]])\n",
    "            # self._label_imageid[idx].append(image_id[idx])\n",
    "        for class_index in target[(correct == 0).nonzero()]:\n",
    "            # false_negatives[class_index] += 1\n",
    "            self._false_negatives += 1\n",
    "          \n",
    "\n",
    "    def calculate_result(self):\n",
    "        # print(f'true_pos={self._true_positives}')\n",
    "        # print(f'false_pos={self._false_positives}')\n",
    "        \n",
    "        result = self._true_positives / self._positives\n",
    "        total=self._positives.float().sum().item()\n",
    "        # print(total)\n",
    "        distb=self._true_positives/total\n",
    "        # recall_div=self._true_positives+self._false_negatives\n",
    "        # result = self._true_positives / recall_div if recall_div != 0 else 0\n",
    "\n",
    "        # where the class never was shown in targets\n",
    "        result[result != result] = 0\n",
    "\n",
    "        return result, distb\n",
    "\n",
    "    def __str__(self):\n",
    "      result, distb=self.calculate_result()\n",
    "      # print(distb)\n",
    "      # print(self._label_imageid)\n",
    "      return f'Recall: {torch.mean(result)}'\n",
    "\n",
    "class bitmap_precision_recall_class(Metrics):\n",
    "    \"\"\"computes the precision for each class over epochs.\n",
    "    Args:\n",
    "        num_classes (int): number of classes.\n",
    "        average (bool): a way to output one single value for metrics\n",
    "                        that are calculated in several trials.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, average=True, **kwargs):\n",
    "        self.n_class = num_classes\n",
    "        super().__init__(average=average)\n",
    "        self._label_imageid=[[] for i in range(self.n_class)]\n",
    "        self._positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._tp=0\n",
    "        self._tn=0\n",
    "        self._fp=0\n",
    "        self._fn=0\n",
    "        self._micro_fscore=[0 for i in range(self.n_class)]\n",
    "        self._micro_tp=[0 for i in range(self.n_class)]\n",
    "        self._micro_fp=[0 for i in range(self.n_class)]\n",
    "        self._micro_tn=[0 for i in range(self.n_class)]\n",
    "        self._micro_fn=[0 for i in range(self.n_class)]\n",
    "        self._label_num=[0 for i in range(self.n_class)]\n",
    "\n",
    "    def reset(self):\n",
    "        self._label_imageid=[[] for i in range(self.n_class)]\n",
    "        self._positives = torch.zeros([self.n_class], dtype=torch.float32)\n",
    "        self._micro_fscore=[0 for i in range(self.n_class)]\n",
    "        self._micro_tp=[0 for i in range(self.n_class)]\n",
    "        self._micro_fp=[0 for i in range(self.n_class)]\n",
    "        self._micro_tn=[0 for i in range(self.n_class)]\n",
    "        self._micro_fn=[0 for i in range(self.n_class)]\n",
    "        self._label_num=[0 for i in range(self.n_class)]\n",
    "\n",
    "    def update(self, image_id, output=None, target=None, threshold=0.5):\n",
    "      with torch.no_grad():\n",
    "\n",
    "        for t in (target == 1).nonzero():\n",
    "          self._label_num[t[1]]+=1\n",
    "\n",
    "        target_one = (target == 1)\n",
    "        # target_one_total = torch.sum(target_one).item()\n",
    "\n",
    "        output_pred_binary = (output > threshold)\n",
    "        # print(output_pred_binary)\n",
    "\n",
    "        true_positive = (output_pred_binary & target_one)\n",
    "        false_negative = (torch.logical_not(output_pred_binary) & target_one)\n",
    "        false_positive = (output_pred_binary & torch.logical_not(target_one))\n",
    "        true_negative = ( torch.logical_not(output_pred_binary) & torch.logical_not(target_one))\n",
    "\n",
    "        for class_index in (output_pred_binary == 1).nonzero():\n",
    "            # print(class_index)\n",
    "            # print(class_index[1])\n",
    "            self._positives[class_index[1]] += 1\n",
    "        for class_index in (true_positive == 1).nonzero():\n",
    "          self._label_imageid[class_index[1]].append(image_id[class_index[0]])\n",
    "        \n",
    "        self._tp += true_positive.float().sum().item()\n",
    "        self._fn += false_negative.float().sum().item()\n",
    "        self._fp += false_positive.float().sum().item()\n",
    "        self._tn += true_negative.float().sum().item()\n",
    "\n",
    "        for class_index in (true_positive==1).nonzero() :\n",
    "            # print(class_index)\n",
    "            # print(class_index[1])\n",
    "            self._micro_tp[class_index[1]] += 1\n",
    "        for class_index in (false_negative==1).nonzero() :\n",
    "            # print(class_index)\n",
    "            # print(class_index[1])\n",
    "            self._micro_fn[class_index[1]] += 1\n",
    "        for class_index in (false_positive==1).nonzero() :\n",
    "            # print(class_index)\n",
    "            # print(class_index[1])\n",
    "            self._micro_fp[class_index[1]] += 1\n",
    "        for class_index in (true_negative==1).nonzero():\n",
    "            # print(class_index)\n",
    "            # print(class_index[1])\n",
    "            self._micro_tn[class_index[1]] += 1\n",
    "    @property\n",
    "    def calculate_result(self):\n",
    "        # print(f'true_pos={self._true_positives}')\n",
    "        # print(f'false_pos={self._false_positives}')\n",
    "        \n",
    "        total=self._positives.float().sum().item()\n",
    "        distb=self._positives/total\n",
    "\n",
    "        accuracy_div=(self._tp+self._fp+self._tn+self._fn)\n",
    "       # distb=torch.div(true_positive,tp+fn)\n",
    "        accuracy=(self._tp+self._tn) / accuracy_div * 100. if accuracy_div != 0 else 0.        \n",
    "        precision_div = (self._tp + self._fp)\n",
    "        precision = self._tp / precision_div * 100. if precision_div != 0 else 0.\n",
    "        # prevent div 0\n",
    "        precision_div = 1e-6 if precision_div == 0 else precision_div\n",
    "\n",
    "        recall_div = (self._tp + self._fn)\n",
    "        recall = self._tp / recall_div * 100. if recall_div != 0 else 0.\n",
    "        # prevent div 0\n",
    "        recall_div = 1e-6 if recall_div == 0 else recall_div\n",
    "        # p_r_div=precision+recall\n",
    "        # F_score= 2*precision*recall/(precision+recall) if p_r_div != 0 else 0\n",
    "        p_r_div=self._tp+((self._fp+self._fn)/2)\n",
    "        F_score= self._tp/p_r_div * 100. if p_r_div != 0 else 0\n",
    "        \n",
    "        for l in range(len(self._micro_tp)):\n",
    "          micro_fscore_div=self._micro_tp[l]+((self._micro_fp[l]+self._micro_fn[l])/2)\n",
    "          # micro_fscore_div=1e-6 if micro_fscore_div==0 else micro_fscore_div\n",
    "          self._micro_fscore[l]=self._micro_tp[l]/micro_fscore_div * 100. if micro_fscore_div != 0 else 0\n",
    "\n",
    "        return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'F_score': F_score, 'distb': distb}\n",
    "\n",
    "    def __str__(self):\n",
    "      print(f'micro_fsoce={self._micro_fscore}')\n",
    "      print(f'label_num={self._label_num}')\n",
    "      out_dict=self.calculate_result\n",
    "      # out='accuracy: '+out_dict[accuracy]+ 'precision: '+out_dict[precision]+ 'recall: 'out_dict[recall]\n",
    "      # print(f'label_imageid={self._label_imageid}')\n",
    "      # print(f'label_distribution={out_dict[\"distb\"]}')\n",
    "      out_dict.pop('distb')\n",
    "      \n",
    "      out='accuracy: {accuracy}, precision: {precision}, recall: {recall}, F_score: {F_score}'\n",
    "      return out.format(**out_dict)\n",
    "\n",
    "\n",
    "def bitmap_precision_recall(output, target, threshold=0.5):\n",
    "    \"\"\" Computes the precision recall over execution bitmap given a interpretation threshold \"\"\"\n",
    "    with torch.no_grad():\n",
    "\n",
    "        target_one = (target == 1)\n",
    "        # target_one_total = torch.sum(target_one).item()\n",
    "\n",
    "        output_pred_binary = (output > threshold)\n",
    "\n",
    "        true_positive = (output_pred_binary & target_one)\n",
    "        false_negative = (torch.logical_not(output_pred_binary) & target_one)\n",
    "        false_positive = (output_pred_binary & torch.logical_not(target_one))\n",
    "        true_negative = ( torch.logical_not(output_pred_binary) & torch.logical_not(target_one))\n",
    "        \n",
    "        tp = true_positive.float().sum().item()\n",
    "        fn = false_negative.float().sum().item()\n",
    "        fp = false_positive.float().sum().item()\n",
    "        tn = true_negative.float().sum().item()\n",
    "\n",
    "        accuracy_div=(tp+fp+tn+fn)\n",
    "       # distb=torch.div(true_positive,tp+fn)\n",
    "        accuracy=(tp+tn) / accuracy_div * 100. if accuracy_div != 0 else 0.        \n",
    "        precision_div = (tp + fp)\n",
    "        precision = tp / precision_div * 100. if precision_div != 0 else 0.\n",
    "        # prevent div 0\n",
    "        precision_div = 1e-6 if precision_div == 0 else precision_div\n",
    "\n",
    "        recall_div = (tp + fn)\n",
    "        recall = tp / recall_div * 100. if recall_div != 0 else 0.\n",
    "        # prevent div 0\n",
    "        recall_div = 1e-6 if recall_div == 0 else recall_div\n",
    "\n",
    "        return accuracy, accuracy_div, precision, precision_div, recall, recall_div\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCO3hyLMvKSH"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.metrics import f1_score, accuracy_score, jaccard_score\n",
    "from sklearn.metrics import confusion_matrix, auc\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "sys.argv=[]\n",
    "parser = argparse.ArgumentParser('Explainable GQA training and evaluation script',\n",
    "                                  parents=[get_args_parser()])\n",
    "args = parser.parse_args()\n",
    "\n",
    "##################################\n",
    "# Initialize saving directory\n",
    "##################################\n",
    "if args.output_dir:\n",
    "    pathlib.Path(args.output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PLZ8SjYtohq"
   },
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163255,
     "status": "ok",
     "timestamp": 1661920519880,
     "user": {
      "displayName": "Nasrin Kalanat",
      "userId": "09177474018032965645"
     },
     "user_tz": 240
    },
    "id": "wr3ZYnZjd-FG",
    "outputId": "a6fa3205-1ae0-4d0f-ca64-3c340c83eb2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.field.Field object at 0x7f07d0aca250>\n",
      "finished loading the data, totally 7542 instances\n",
      "<torchtext.data.field.Field object at 0x7f07d0aca250>\n",
      "finished loading the data, totally 2664 instances\n"
     ]
    }
   ],
   "source": [
    "train_dataset = GQATorchDataset(\n",
    "    split='train_unbiased',\n",
    "    build_vocab_flag=False,\n",
    "    load_vocab_flag=False\n",
    ")\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     collate_fn=GQATorchDataset_collate_fn,\n",
    "#     num_workers=args.workers\n",
    "# )\n",
    "\n",
    "    # Old version\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    collate_fn=GQATorchDataset_collate_fn,\n",
    "    num_workers=args.workers)\n",
    "\n",
    "val_dataset_list = []\n",
    "for eval_split in args.evaluate_sets:\n",
    "    val_dataset_list.append(GQATorchDataset(\n",
    "        split=eval_split,\n",
    "        build_vocab_flag=False,\n",
    "        load_vocab_flag=args.evaluate\n",
    "    ))\n",
    "val_dataset = torch.utils.data.ConcatDataset(val_dataset_list)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    drop_last=False,\n",
    "    collate_fn=GQATorchDataset_collate_fn,\n",
    "    num_workers=args.workers\n",
    ")\n",
    "dataloader={'train':train_loader,'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0FtQ8spmvyq"
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# The whole Pipeline. put everything here\n",
    "# \"\"\"\n",
    "# class PipelineModel(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(PipelineModel, self).__init__()\n",
    "\n",
    "#         ##################################\n",
    "#         # build scene graph encoder\n",
    "#         ##################################\n",
    "#         self.scene_graph_encoder = GroundTruth_SceneGraph_Encoder()\n",
    "#         self.scene_graph_encoder_concept = GroundTruth_SceneGraph_Encoder(graph_type='concept')\n",
    "\n",
    "\n",
    "#         ##################################\n",
    "#         # build text embedding\n",
    "#         ##################################\n",
    "#         # TEXT = GQATorchDataset.TEXT\n",
    "#         # text_vocab = GQATorchDataset.TEXT.vocab\n",
    "#         # text_emb_dim = 300 # 300d glove\n",
    "#         # text_pad_idx = text_vocab.stoi[TEXT.pad_token]\n",
    "#         # text_vocab_size = len(text_vocab)\n",
    "#         # self.text_vocab_embedding = torch.nn.Embedding(text_vocab_size, text_emb_dim, padding_idx=text_pad_idx)\n",
    "#         # self.text_vocab_embedding.weight.data.copy_(text_vocab.vectors)\n",
    "#         # del TEXT, text_vocab, text_pad_idx\n",
    "\n",
    "#         # ##################################\n",
    "#         # # Build Question Encoder\n",
    "#         # ##################################\n",
    "#         self.question_hidden_dim = 512 # 256, 79% slower # 128 - 82% on short # 512, batch size#\n",
    "#         # self.question_encoder = TransformerQuestionEncoder(\n",
    "#         #     text_vocab_embedding=self.text_vocab_embedding,\n",
    "#         #     text_emb_dim=text_emb_dim, # embedding dimension\n",
    "#         #     ninp=self.question_hidden_dim, # transformer encoder layer input dim\n",
    "#         #     nhead=8, # the number of heads in the multiheadattention models\n",
    "#         #     nhid=4*self.question_hidden_dim, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "#         #     nlayers=3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "#         #     dropout=0.1, # the dropout value\n",
    "#         #     )\n",
    "\n",
    "#         # ##################################\n",
    "#         # # Build Program Decoder\n",
    "#         # ##################################\n",
    "#         # self.program_decoder = TransformerProgramDecoder(\n",
    "#         #     text_vocab_embedding=self.text_vocab_embedding,\n",
    "#         #     vocab_size=text_vocab_size,\n",
    "#         #     text_emb_dim=text_emb_dim, # embedding dimension\n",
    "#         #     ninp=self.question_hidden_dim, # transformer encoder layer input dim\n",
    "#         #     nhead=8, # the number of heads in the multiheadattention models\n",
    "#         #     nhid=4*self.question_hidden_dim, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "#         #     nlayers=3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "#         #     dropout=0.1, # the dropout value\n",
    "#         #     )\n",
    "\n",
    "#         ##################################\n",
    "#         # Build Neural Execution Module Pooling Layer\n",
    "#         ##################################\n",
    "#         # self.recurrent_execution_engine = RecurrentExecutionEngine(\n",
    "#         #     num_node_features=self.scene_graph_encoder.sg_emb_dim,\n",
    "#         #     num_instr_features=self.question_hidden_dim,\n",
    "#         #     )\n",
    "\n",
    "\n",
    "#         # input to the gat_seq would be: \n",
    "#         # 1. concat(h_prev, x_orig), where h_prev is the previous GAT layer's output and x_orig is the original encoded node features\n",
    "#         # 2. concat(edge_attr, ins_i), concat of edge_attr and i_th step instruction vector\n",
    "#         # self.gat_seq = gat(in_channels=self.scene_graph_encoder.sg_emb_dim*2,\n",
    "#         #          out_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "#         #          edge_in_channels=self.scene_graph_encoder.sg_emb_dim+self.question_hidden_dim, \n",
    "#         #          heads= 4, concat=False, negative_slope= 0.2, dropout= 0.0, bias= True)\n",
    "#         hid_dim=512\n",
    "#         # self.gat_seq = my_gat(in_channels=self.scene_graph_encoder.sg_emb_dim,\n",
    "#         #   out_channels=hid_dim, \n",
    "#         #   edge_attr_dim=self.scene_graph_encoder.sg_emb_dim, \n",
    "#         #   dropout=0.1, gat_heads=4, gat_negative_slope=0.2, gat_bias=True)\n",
    "\n",
    "\n",
    "#         # # graph excution\n",
    "#         # self.gcn_seq = gcn_seq(in_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "#         #         out_channels=self.scene_graph_encoder.sg_emb_dim, ins_dim=self.question_hidden_dim,\n",
    "#         #         dropout=0.1)\n",
    "\n",
    "#         # self.gcn_seq = gcn_seq(in_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "#         #         out_channels=self.scene_graph_encoder.sg_emb_dim\n",
    "#         #         dropout=0.1)#\n",
    "\n",
    "        \n",
    "#         self.my_gcn_sg = my_gcn_sg(in_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "#                 out_channels=hid_dim,\n",
    "#                 dropout=0.1)#0.5. 0.1\n",
    "\n",
    "#         # self.my_gcn_concept = my_gcn_concept(in_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "#         #         out_channels=hid_dim,\n",
    "#         #         dropout=0.1)#0.5. 0.1\n",
    "#         # print(f'embed={self.scene_graph_encoder.sg_emb_dim}')\n",
    "#         # print(f'question={self.question_hidden_dim}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         ##################################\n",
    "#         # Build Neural Execution Module Pooling Layer\n",
    "#         ##################################\n",
    "#         # self.graph_global_attention_pooling = MyConditionalGlobalAttention(\n",
    "#         #     num_node_features=self.scene_graph_encoder_concept.sg_emb_dim,\n",
    "#         #     num_out_features=self.question_hidden_dim)\n",
    "\n",
    "#         # ##################################\n",
    "#         # # Build Neural Execution Module Pooling Layer\n",
    "#         # ##################################\n",
    "#         self.graph_global_attention_pooling = MyConditionalGlobalAttention(\n",
    "#             num_node_features=hid_dim,\n",
    "#             num_out_features=hid_dim)\n",
    "\n",
    "#         ##################################\n",
    "#         # Build Natural Language Generation Module\n",
    "#         ##################################\n",
    "#         # self.full_answer_decoder = TransformerFullAnswerDecoder(\n",
    "#         #     text_vocab_embedding=self.text_vocab_embedding,\n",
    "#         #     vocab_size=text_vocab_size,\n",
    "#         #     text_emb_dim=text_emb_dim, # embedding dimension\n",
    "#         #     ninp=self.question_hidden_dim, # transformer encoder layer input dim\n",
    "#         #     nhead=8, # the number of heads in the multiheadattention models\n",
    "#         #     nhid=4*self.question_hidden_dim, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "#         #     nlayers=3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "#         #     dropout=0.1, # the dropout value\n",
    "#         #     )\n",
    "\n",
    "#         ##################################\n",
    "#         # Build Short Answer Classification Module, Only for debug.\n",
    "#         ##################################\n",
    "#         # num_short_answer_choices = 7488 # hard coding#\n",
    "#         num_short_answers = 54 # hard coding#\n",
    "#         # hid_dim = self.question_hidden_dim  * 3 # due to concat#\n",
    "#         # hid_dim = num_short_answer_choices  * 3 # due to concat#\n",
    "#         # hid_dim = self.question_hidden_dim  # due to concat#\n",
    "#         # self.logit_fc = torch.nn.Linear(hid_dim, num_short_answer_choices)\n",
    "#         # out_classifier_dim = 512\n",
    "#         # self.logit_fc = torch.nn.Sequential(\n",
    "#         #     torch.nn.Dropout(p=0.2),\n",
    "#         #     torch.nn.Linear(hid_dim, out_classifier_dim),\n",
    "#         #     torch.nn.ELU(),\n",
    "#         #     torch.nn.Dropout(p=0.2),\n",
    "#         #     torch.nn.Linear(out_classifier_dim, num_short_answer_choices)\n",
    "#         # )\n",
    "#         # del out_classifier_dim\n",
    "\n",
    "\n",
    "\n",
    "#         # self.pretrain_model = models.vgg16(pretrained=True)\n",
    "#         # num_ftr = self.pretrain_model.classifier[6].in_features\n",
    "#         # self.pretrain_model.classifier[6] = torch.nn.Linear(num_ftr, 5*hid_dim)\n",
    "\n",
    "\n",
    "\n",
    "#         # self.my_logit_fc=torch.nn.Linear(3*2*hid_dim  , num_short_answers)\n",
    "#         self.my_logit_fc=torch.nn.Sequential(\n",
    "#             # torch.nn.Dropout(p=0.1),\n",
    "#             # torch.nn.LayerNorm(3*4*hid_dim, eps=1e-12),\n",
    "#             # torch.nn.Dropout(p=0.5),\n",
    "#             torch.nn.Linear(5*1*hid_dim, 3*hid_dim),\n",
    "#             torch.nn.LayerNorm(3*hid_dim, eps=1e-12),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             # torch.nn.Dropout(p=0.5),\n",
    "#             # torch.nn.LayerNorm(3*hid_dim, eps=1e-12),\n",
    "#             torch.nn.Linear(3*hid_dim, num_short_answers),\n",
    "#             # torch.nn.ReLU(inplace=True),\n",
    "#             # torch.nn.Dropout(p=0.5),\n",
    "#             # torch.nn.LayerNorm(hid_dim, eps=1e-12),\n",
    "#             # torch.nn.Linear(hid_dim, int(hid_dim/2)),\n",
    "#             # torch.nn.ReLU(),\n",
    "#             # torch.nn.Linear(int(hid_dim/2), int(hid_dim/4)),\n",
    "#             # torch.nn.ReLU(),\n",
    "#             # torch.nn.LayerNorm(int(hid_dim/4), eps=1e-12),\n",
    "#             # torch.nn.Linear(hid_dim, num_short_answers)\n",
    "#         )\n",
    "\n",
    "#         # self.my_logit_fc=torch.nn.Sequential(\n",
    "#         #     torch.nn.Linear(hid_dim, hid_dim * 2),\n",
    "#         #     torch.nn.ReLU(),\n",
    "#         #     torch.nn.LayerNorm(hid_dim * 2, eps=1e-12),\n",
    "#         #     torch.nn.Linear(hid_dim * 2, num_short_answers)\n",
    "#         # )\n",
    "\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def forward(self,\n",
    "#                 questions,\n",
    "#                 gt_scene_graphs,\n",
    "#                 gt_scene_graphs_concept,\n",
    "#                 programs_input,\n",
    "#                 full_answers_input,\n",
    "#                 img_inputs,\n",
    "#                 image_id,\n",
    "#                 SAMPLE_FLAG=False\n",
    "#                 ):\n",
    "\n",
    "#         x_encoded, edge_attr_encoded, _ = self.scene_graph_encoder(gt_scene_graphs)\n",
    "        \n",
    "#         if torch.any(torch.isinf(x_encoded)):\n",
    "          \n",
    "#           print(\"xinf\")\n",
    "#         if torch.any(torch.isnan(x_encoded)):\n",
    "#           print(\"xnan\")\n",
    "#         if torch.any(torch.isinf(edge_attr_encoded)):\n",
    "\n",
    "#           print(\"attinf\")\n",
    "#         if torch.any(torch.isnan(edge_attr_encoded)):\n",
    "\n",
    "#           print(\"attnan\")\n",
    "\n",
    "#         x_encoded_concept, edge_attr_encoded_concept, _ = self.scene_graph_encoder_concept(gt_scene_graphs_concept)\n",
    "#         if torch.any(torch.isinf(x_encoded_concept)):\n",
    "#           print(\"*****x_cinf\")\n",
    "#         if torch.any(torch.isinf(edge_attr_encoded_concept)):\n",
    "\n",
    "#           print(\"*****att_cinf\") \n",
    "#         if torch.any(torch.isnan(x_encoded_concept)):\n",
    "#           print(\"*****x_cnan\")\n",
    "#         if torch.any(torch.isnan(edge_attr_encoded_concept)):\n",
    "\n",
    "#           print(\"******att_cnan\")          \n",
    "\n",
    "#         # ##################################\n",
    "#         # # Encode questions\n",
    "#         # ##################################\n",
    "#         # # [ Len, Batch ] -> [ Len, Batch, self.question_hidden_dim ]\n",
    "#         # questions_encoded = self.question_encoder(questions)\n",
    "\n",
    "#         # ##################################\n",
    "#         # # Decode programs\n",
    "#         # ##################################\n",
    "#         # # [ Len, Batch ] -> [ Len, Batch, self.question_hidden_dim ]\n",
    "#         # if not SAMPLE_FLAG:\n",
    "#         #     programs_output, instr_vectors = self.program_decoder(memory=questions_encoded, tgt=programs_input)\n",
    "#         # else:\n",
    "#         #     programs_output, instr_vectors = self.program_decoder.sample(memory=questions_encoded, tgt=programs_input)\n",
    "\n",
    "#         ##################################\n",
    "#         # Call Recurrent Neural Execution Module\n",
    "#         ##################################\n",
    "#         # # x_executed, execution_bitmap, history_vectors = self.recurrent_execution_engine(\n",
    "#         # #     x=x_encoded,\n",
    "#         # #     edge_index=gt_scene_graphs.edge_index,\n",
    "#         # #     edge_attr=None,\n",
    "#         # #     instr_vectors=instr_vectors,\n",
    "#         # #     batch=gt_scene_graphs.batch,\n",
    "#         # # )\n",
    "\n",
    "#         # # print(\"inst: shape\", instr_vectors.shape)\n",
    "#         # # ins = instr_vectors[0] # shape: batch_size X instruction_dim\n",
    "#         # # edge_batch = gt_scene_graphs.batch[gt_scene_graphs.edge_index[0]] # find out which batch the edge belongs to\n",
    "#         # # repeated_ins = torch.zeros((gt_scene_graphs.edge_index.shape[1], ins.shape[-1])) # shape: num_edges x instruction_dim\n",
    "#         # # repeated_ins = ins[edge_batch] # pick correct batched instruction for each edge\n",
    "\n",
    "\n",
    "#         # # edge_cat = torch.cat( (edge_attr_encoded, repeated_ins.to(edge_attr_encoded.device)), dim=-1) # shape: num_edges X  encode_dim+instruction_dim\n",
    "#         # # x_cat = torch.cat( (x_encoded, x_encoded), dim=-1)\n",
    "\n",
    "#         # # x_executed = self.gat_seq(x=x_cat, edge_index=gt_scene_graphs.edge_index, edge_attr=edge_cat)\n",
    "\n",
    "#         # # excute the 5 layers of GCN using node features\n",
    "#         # # x_executed = self.gcn_seq(x=x_encoded, edge_index=gt_scene_graphs.edge_index, instr_vectors=instr_vectors, batch=gt_scene_graphs.batch)#\n",
    "#         # x_executed = self.gcn_seq(x=x_encoded, edge_index=gt_scene_graphs.edge_index, batch=gt_scene_graphs.batch)#\n",
    "#         # x_executed_concept = self.gcn_seq(x=x_encoded_concept, edge_index=gt_scene_graphs_concept.edge_index, batch=gt_scene_graphs_concept.batch)#\n",
    "#         # # print(f'x_executed={x_executed.shape}')\n",
    "#         # # print(f'x_executed_conc={x_executed_concept.shape}') \n",
    "\n",
    "\n",
    "#         # ##################################\n",
    "#         # # Final Layer of the Neural Execution Module, global pooling\n",
    "#         # # (batch_size, channels)\n",
    "#         # ##################################\n",
    "#         # #global_language_feature = questions_encoded[0] # should be changed when completing NEM#\n",
    "#         # graph_final_feature = self.graph_global_attention_pooling(\n",
    "#         #     x = x_executed, # x=x_encoded,\n",
    "#         #     #u = global_language_feature,#\n",
    "#         #     batch = gt_scene_graphs.batch,\n",
    "#         #     # no need for edge features since it is global node pooling\n",
    "#         #     size = None)\n",
    "#         # # print(f'graph_final_feature={graph_final_feature.shape}')\n",
    "\n",
    "\n",
    "#         # graph_final_feature_concept = self.graph_global_attention_pooling(\n",
    "#         #     x = x_executed_concept, # x=x_encoded,\n",
    "#         #     #u = global_language_feature,#\n",
    "#         #     batch = gt_scene_graphs_concept.batch,\n",
    "#         #     # no need for edge features since it is global node pooling\n",
    "#         #     size = None)\n",
    "#         # # print(f'graph_final_feature_conc={graph_final_feature_concept.shape}')\n",
    "\n",
    "#         # ##################################\n",
    "#         # # Call Short Answer Classification Module Only for Debug\n",
    "#         # ##################################\n",
    "#         # # short_answer_feature = questions_encoded[0]\n",
    "        \n",
    "#         # # short_answer_feature = torch.cat( ( graph_final_feature, graph_final_feature_concept, graph_final_feature * graph_final_feature_concept ), dim=-1 )#\n",
    "#         # short_answer_feature=graph_final_feature#\n",
    "#         # # short_answer_feature=x_executed\n",
    "\n",
    "#         # short_answer_logits = self.logit_fc(short_answer_feature)\n",
    "\n",
    "#         gcn_sg=self.my_gcn_sg(x=x_encoded, edge_index=gt_scene_graphs.edge_index, batch=gt_scene_graphs.batch)#*********************\n",
    "#         # print(gt_scene_graphs.edge_index)\n",
    "#         # print(\"edge_shap\",gt_scene_graphs.edge_index.shape)\n",
    "#         # print(\"node_shap\",x_encoded.shape)\n",
    "#         # print('gcn_shap', self.my_gcn_seq.lin.weight.shape)\n",
    "#         # print()\n",
    "#         gcn_concept=self.my_gcn_sg(x=x_encoded_concept, edge_index=gt_scene_graphs_concept.edge_index, batch=gt_scene_graphs_concept.batch)#*********************\n",
    "#         # if img_id==2/165122.jpg or img_id==7/21427.jpg or img_id==10/175425.png or img_id==3/46313.jpg or img_id==3/101383.jpg img_id==or 0/155290.jpg or img_id==7/54467.jpg or img_id==3/107983.jpg:\n",
    "#         #   print(gt_scene_graphs.edge_index)\n",
    "#         #   print(gt_scene_graphs_concept.edge_index)\n",
    "\n",
    "#         # gcn_sg = self.gat_seq(x=x_encoded, edge_index=gt_scene_graphs.edge_index, edge_attr=edge_attr_encoded, batch=gt_scene_graphs.batch)\n",
    "#         # gcn_concept = self.gat_seq(x=x_encoded_concept, edge_index=gt_scene_graphs_concept.edge_index, edge_attr=edge_attr_encoded_concept, batch=gt_scene_graphs_concept.batch)\n",
    "\n",
    "\n",
    "#         ##################################\n",
    "#         # Final Layer of the Neural Execution Module, global pooling\n",
    "#         # (batch_size, channels)\n",
    "#         ##################################\n",
    "#         # global_language_feature = gcn_concept # should be changed when completing NEM\n",
    "#         # graph_final_feature = self.graph_global_attention_pooling(\n",
    "#         #     x = gcn_sg, # x=x_encoded,\n",
    "#         #     u = global_language_feature,\n",
    "#         #     batch = gt_scene_graphs.batch,\n",
    "#         #     # no need for edge features since it is global node pooling\n",
    "#         #     size = None)\n",
    "\n",
    "#         # img_outputs=self.pretrain_model(img_inputs)\n",
    "\n",
    "\n",
    "\n",
    "#         # graph_final_feature = self.graph_global_attention_pooling(\n",
    "#         #     x = gcn_sg, # x=x_encoded,\n",
    "#         #     #u = global_language_feature,#\n",
    "#         #     batch = gt_scene_graphs.batch,\n",
    "#         #     # no need for edge features since it is global node pooling\n",
    "#         #     size = None)\n",
    "#         # # # print(f'graph_final_feature={graph_final_feature.shape}')\n",
    "\n",
    "#         # graph_final_feature_concept = self.graph_global_attention_pooling(\n",
    "#         #     x = gcn_concept, # x=x_encoded,\n",
    "#         #     #u = global_language_feature,#\n",
    "#         #     batch = gt_scene_graphs_concept.batch,\n",
    "#         #     # no need for edge features since it is global node pooling\n",
    "#         #     size = None)\n",
    "#         # print(f'graph_final_feature_conc={graph_final_feature_concept.shape}')\n",
    "\n",
    "\n",
    "#         # short_ans_feat=torch.cat( (graph_final_feature, graph_final_feature_concept, graph_final_feature*graph_final_feature_concept), dim=-1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         # short_ans_feat = torch.cat( (gcn_sg, gcn_concept, gcn_sg*gcn_concept), dim=-1 )#\n",
    "\n",
    "\n",
    "#         # short_ans_feat = torch.cat( ( graph_final_feature, gcn_concept, graph_final_feature*gcn_concept), dim=-1 )#\n",
    "#         short_ans_feat=gcn_concept\n",
    "#         my_short_answer_logits = self.my_logit_fc(short_ans_feat)\n",
    "\n",
    "       \n",
    "#         # x=x_encoded_concept\n",
    "#         # edge_index=gt_scene_graphs_concept.edge_index\n",
    "#         # batch=gt_scene_graphs_concept.batch\n",
    "#         # my_short_answer_logits=Sequential('x, edge_index, batch', [\n",
    "#         #     (Dropout(p=0.5), 'x -> x'),\n",
    "#         #     (GCNConv(self.scene_graph_encoder.sg_emb_dim, 64), 'x, edge_index -> x1'),\n",
    "#         #     ReLU(inplace=True),\n",
    "#         #     (GCNConv(64, 64), 'x1, edge_index -> x2'),\n",
    "#         #     ReLU(inplace=True),\n",
    "#         #     (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n",
    "#         #     (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n",
    "#         #     (global_mean_pool, 'x, batch -> x'),\n",
    "#         #     Linear(2 * 64, 54),\n",
    "#         # ])\n",
    "\n",
    "\n",
    "\n",
    "#         # return programs_output, short_answer_logits#\n",
    "#         return my_short_answer_logits#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OySRrpg-MZpf"
   },
   "outputs": [],
   "source": [
    "# attention on cocatenation of sg and concept\n",
    "\"\"\"\n",
    "The whole Pipeline. put everything here\n",
    "\"\"\"\n",
    "class PipelineModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PipelineModel, self).__init__()\n",
    "\n",
    "        ##################################\n",
    "        # build scene graph encoder\n",
    "        ##################################\n",
    "        self.scene_graph_encoder = GroundTruth_SceneGraph_Encoder()\n",
    "        self.scene_graph_encoder_concept = GroundTruth_SceneGraph_Encoder(graph_type='concept')\n",
    "\n",
    "\n",
    "        ##################################\n",
    "        # build text embedding\n",
    "        ##################################\n",
    "        # TEXT = GQATorchDataset.TEXT\n",
    "        # text_vocab = GQATorchDataset.TEXT.vocab\n",
    "        # text_emb_dim = 300 # 300d glove\n",
    "        # text_pad_idx = text_vocab.stoi[TEXT.pad_token]\n",
    "        # text_vocab_size = len(text_vocab)\n",
    "        # self.text_vocab_embedding = torch.nn.Embedding(text_vocab_size, text_emb_dim, padding_idx=text_pad_idx)\n",
    "        # self.text_vocab_embedding.weight.data.copy_(text_vocab.vectors)\n",
    "        # del TEXT, text_vocab, text_pad_idx\n",
    "\n",
    "        # ##################################\n",
    "        # # Build Question Encoder\n",
    "        # ##################################\n",
    "        self.question_hidden_dim = 512 # 256, 79% slower # 128 - 82% on short # 512, batch size#\n",
    "        # self.question_encoder = TransformerQuestionEncoder(\n",
    "        #     text_vocab_embedding=self.text_vocab_embedding,\n",
    "        #     text_emb_dim=text_emb_dim, # embedding dimension\n",
    "        #     ninp=self.question_hidden_dim, # transformer encoder layer input dim\n",
    "        #     nhead=8, # the number of heads in the multiheadattention models\n",
    "        #     nhid=4*self.question_hidden_dim, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "        #     nlayers=3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        #     dropout=0.1, # the dropout value\n",
    "        #     )\n",
    "\n",
    "        # ##################################\n",
    "        # # Build Program Decoder\n",
    "        # ##################################\n",
    "        # self.program_decoder = TransformerProgramDecoder(\n",
    "        #     text_vocab_embedding=self.text_vocab_embedding,\n",
    "        #     vocab_size=text_vocab_size,\n",
    "        #     text_emb_dim=text_emb_dim, # embedding dimension\n",
    "        #     ninp=self.question_hidden_dim, # transformer encoder layer input dim\n",
    "        #     nhead=8, # the number of heads in the multiheadattention models\n",
    "        #     nhid=4*self.question_hidden_dim, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "        #     nlayers=3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        #     dropout=0.1, # the dropout value\n",
    "        #     )\n",
    "\n",
    "        ##################################\n",
    "        # Build Neural Execution Module Pooling Layer\n",
    "        ##################################\n",
    "        # self.recurrent_execution_engine = RecurrentExecutionEngine(\n",
    "        #     num_node_features=self.scene_graph_encoder.sg_emb_dim,\n",
    "        #     num_instr_features=self.question_hidden_dim,\n",
    "        #     )\n",
    "\n",
    "\n",
    "        # input to the gat_seq would be: \n",
    "        # 1. concat(h_prev, x_orig), where h_prev is the previous GAT layer's output and x_orig is the original encoded node features\n",
    "        # 2. concat(edge_attr, ins_i), concat of edge_attr and i_th step instruction vector\n",
    "        # self.gat_seq = gat(in_channels=self.scene_graph_encoder.sg_emb_dim*2,\n",
    "        #          out_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "        #          edge_in_channels=self.scene_graph_encoder.sg_emb_dim+self.question_hidden_dim, \n",
    "        #          heads= 4, concat=False, negative_slope= 0.2, dropout= 0.0, bias= True)\n",
    "        hid_dim=512\n",
    "        # self.gat_seq = my_gat(in_channels=self.scene_graph_encoder.sg_emb_dim,\n",
    "        #   out_channels=hid_dim, \n",
    "        #   edge_attr_dim=self.scene_graph_encoder.sg_emb_dim, \n",
    "        #   dropout=0.1, gat_heads=4, gat_negative_slope=0.2, gat_bias=True)\n",
    "\n",
    "\n",
    "        # # graph excution\n",
    "        # self.gcn_seq = gcn_seq(in_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "        #         out_channels=self.scene_graph_encoder.sg_emb_dim, ins_dim=self.question_hidden_dim,\n",
    "        #         dropout=0.1)\n",
    "\n",
    "        # self.gcn_seq = gcn_seq(in_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "        #         out_channels=self.scene_graph_encoder.sg_emb_dim\n",
    "        #         dropout=0.1)#\n",
    "\n",
    "        \n",
    "        self.my_gcn_sg = my_gcn_sg(in_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "                out_channels=hid_dim,\n",
    "                dropout=0.1)#0.5. 0.1\n",
    "\n",
    "        # self.my_gcn_concept = my_gcn_concept(in_channels=self.scene_graph_encoder.sg_emb_dim, \n",
    "        #         out_channels=hid_dim,\n",
    "        #         dropout=0.0)#0.5. 0.1\n",
    "        # # print(f'embed={self.scene_graph_encoder.sg_emb_dim}')\n",
    "        # # print(f'question={self.question_hidden_dim}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##################################\n",
    "        # Build Neural Execution Module Pooling Layer\n",
    "        ##################################\n",
    "        # self.graph_global_attention_pooling = MyConditionalGlobalAttention(\n",
    "        #     num_node_features=self.scene_graph_encoder_concept.sg_emb_dim,\n",
    "        #     num_out_features=self.question_hidden_dim)\n",
    "\n",
    "        # ##################################\n",
    "        # # Build Neural Execution Module Pooling Layer\n",
    "        # ##################################\n",
    "        # self.graph_global_attention_pooling = MyAttention(\n",
    "        #     num_node_features=3*hid_dim,\n",
    "        #     num_out_features=hid_dim)\n",
    "        # self.graph_global_attention = MultiHeadAttention(\n",
    "        #     num_hiddens=5*hid_dim,\n",
    "        #     num_heads=32, dropout=0.1)\n",
    "        self.graph_global_attention = Attention(\n",
    "            dim=5*hid_dim)  \n",
    "        self.multihead_attn = nn.MultiheadAttention(5*hid_dim, 1) \n",
    "        self.normalize=nn.LayerNorm(5*hid_dim)    \n",
    "\n",
    "        ##################################\n",
    "        # Build Natural Language Generation Module\n",
    "        ##################################\n",
    "        # self.full_answer_decoder = TransformerFullAnswerDecoder(\n",
    "        #     text_vocab_embedding=self.text_vocab_embedding,\n",
    "        #     vocab_size=text_vocab_size,\n",
    "        #     text_emb_dim=text_emb_dim, # embedding dimension\n",
    "        #     ninp=self.question_hidden_dim, # transformer encoder layer input dim\n",
    "        #     nhead=8, # the number of heads in the multiheadattention models\n",
    "        #     nhid=4*self.question_hidden_dim, # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "        #     nlayers=3, # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        #     dropout=0.1, # the dropout value\n",
    "        #     )\n",
    "\n",
    "        ##################################\n",
    "        # Build Short Answer Classification Module, Only for debug.\n",
    "        ##################################\n",
    "        # num_short_answer_choices = 7488 # hard coding#\n",
    "        num_short_answers = 54 # hard coding#\n",
    "        # hid_dim = self.question_hidden_dim  * 3 # due to concat#\n",
    "        # hid_dim = num_short_answer_choices  * 3 # due to concat#\n",
    "        # hid_dim = self.question_hidden_dim  # due to concat#\n",
    "        # self.logit_fc = torch.nn.Linear(hid_dim, num_short_answer_choices)\n",
    "        # out_classifier_dim = 512\n",
    "        # self.logit_fc = torch.nn.Sequential(\n",
    "        #     torch.nn.Dropout(p=0.2),\n",
    "        #     torch.nn.Linear(hid_dim, out_classifier_dim),\n",
    "        #     torch.nn.ELU(),\n",
    "        #     torch.nn.Dropout(p=0.2),\n",
    "        #     torch.nn.Linear(out_classifier_dim, num_short_answer_choices)\n",
    "        # )\n",
    "        # del out_classifier_dim\n",
    "\n",
    "\n",
    "\n",
    "        # self.pretrain_model = models.vgg16(pretrained=True)\n",
    "        # num_ftr = self.pretrain_model.classifier[6].in_features\n",
    "        # self.pretrain_model.classifier[6] = torch.nn.Linear(num_ftr, 5*hid_dim)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # self.my_logit_fc=torch.nn.Linear(3*2*hid_dim  , num_short_answers)\n",
    "        self.my_logit_fc=torch.nn.Sequential(\n",
    "            # torch.nn.Dropout(p=0.1),\n",
    "            # torch.nn.LayerNorm(3*4*hid_dim, eps=1e-12),\n",
    "            # torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(3*5*hid_dim, 3*hid_dim),\n",
    "            torch.nn.LayerNorm(3*hid_dim, eps=1e-12),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            # torch.nn.Dropout(p=0.5),\n",
    "            # torch.nn.LayerNorm(3*hid_dim, eps=1e-12),\n",
    "            torch.nn.Linear(3*hid_dim, num_short_answers),\n",
    "            # torch.nn.ReLU(inplace=True),\n",
    "            # torch.nn.Dropout(p=0.5),\n",
    "            # torch.nn.LayerNorm(hid_dim, eps=1e-12),\n",
    "            # torch.nn.Linear(hid_dim, int(hid_dim/2)),\n",
    "            # torch.nn.ReLU(),\n",
    "            # torch.nn.Linear(int(hid_dim/2), int(hid_dim/4)),\n",
    "            # torch.nn.ReLU(),\n",
    "            # torch.nn.LayerNorm(int(hid_dim/4), eps=1e-12),\n",
    "            # torch.nn.Linear(hid_dim, num_short_answers)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.Rl=torch.nn.ReLU(inplace=True)\n",
    "        self.my_linear=torch.nn.Linear(3*5*hid_dim, num_short_answers)\n",
    "\n",
    "        # self.my_logit_fc=torch.nn.Sequential(\n",
    "        #     torch.nn.Linear(hid_dim, hid_dim * 2),\n",
    "        #     torch.nn.ReLU(),\n",
    "        #     torch.nn.LayerNorm(hid_dim * 2, eps=1e-12),\n",
    "        #     torch.nn.Linear(hid_dim * 2, num_short_answers)\n",
    "        # )\n",
    "\n",
    "\n",
    "        return\n",
    "\n",
    "    def forward(self,\n",
    "                questions,\n",
    "                gt_scene_graphs,\n",
    "                gt_scene_graphs_concept,\n",
    "                programs_input,\n",
    "                full_answers_input,\n",
    "                img_inputs,\n",
    "                image_id,\n",
    "                SAMPLE_FLAG=False\n",
    "                ):\n",
    "\n",
    "        x_encoded, edge_attr_encoded, _ = self.scene_graph_encoder(gt_scene_graphs)\n",
    "        \n",
    "        if torch.any(torch.isinf(x_encoded)):\n",
    "          \n",
    "          print(\"xinf\")\n",
    "        if torch.any(torch.isnan(x_encoded)):\n",
    "          print(\"xnan\")\n",
    "        if torch.any(torch.isinf(edge_attr_encoded)):\n",
    "\n",
    "          print(\"attinf\")\n",
    "        if torch.any(torch.isnan(edge_attr_encoded)):\n",
    "\n",
    "          print(\"attnan\")\n",
    "\n",
    "        x_encoded_concept, edge_attr_encoded_concept, _ = self.scene_graph_encoder_concept(gt_scene_graphs_concept)\n",
    "        if torch.any(torch.isinf(x_encoded_concept)):\n",
    "          print(\"*****x_cinf\")\n",
    "        if torch.any(torch.isinf(edge_attr_encoded_concept)):\n",
    "\n",
    "          print(\"*****att_cinf\") \n",
    "        if torch.any(torch.isnan(x_encoded_concept)):\n",
    "          print(\"*****x_cnan\")\n",
    "        if torch.any(torch.isnan(edge_attr_encoded_concept)):\n",
    "\n",
    "          print(\"******att_cnan\")          \n",
    "\n",
    "        # ##################################\n",
    "        # # Encode questions\n",
    "        # ##################################\n",
    "        # # [ Len, Batch ] -> [ Len, Batch, self.question_hidden_dim ]\n",
    "        # questions_encoded = self.question_encoder(questions)\n",
    "\n",
    "        # ##################################\n",
    "        # # Decode programs\n",
    "        # ##################################\n",
    "        # # [ Len, Batch ] -> [ Len, Batch, self.question_hidden_dim ]\n",
    "        # if not SAMPLE_FLAG:\n",
    "        #     programs_output, instr_vectors = self.program_decoder(memory=questions_encoded, tgt=programs_input)\n",
    "        # else:\n",
    "        #     programs_output, instr_vectors = self.program_decoder.sample(memory=questions_encoded, tgt=programs_input)\n",
    "\n",
    "        ##################################\n",
    "        # Call Recurrent Neural Execution Module\n",
    "        ##################################\n",
    "        # # x_executed, execution_bitmap, history_vectors = self.recurrent_execution_engine(\n",
    "        # #     x=x_encoded,\n",
    "        # #     edge_index=gt_scene_graphs.edge_index,\n",
    "        # #     edge_attr=None,\n",
    "        # #     instr_vectors=instr_vectors,\n",
    "        # #     batch=gt_scene_graphs.batch,\n",
    "        # # )\n",
    "\n",
    "        # # print(\"inst: shape\", instr_vectors.shape)\n",
    "        # # ins = instr_vectors[0] # shape: batch_size X instruction_dim\n",
    "        # # edge_batch = gt_scene_graphs.batch[gt_scene_graphs.edge_index[0]] # find out which batch the edge belongs to\n",
    "        # # repeated_ins = torch.zeros((gt_scene_graphs.edge_index.shape[1], ins.shape[-1])) # shape: num_edges x instruction_dim\n",
    "        # # repeated_ins = ins[edge_batch] # pick correct batched instruction for each edge\n",
    "\n",
    "\n",
    "        # # edge_cat = torch.cat( (edge_attr_encoded, repeated_ins.to(edge_attr_encoded.device)), dim=-1) # shape: num_edges X  encode_dim+instruction_dim\n",
    "        # # x_cat = torch.cat( (x_encoded, x_encoded), dim=-1)\n",
    "\n",
    "        # # x_executed = self.gat_seq(x=x_cat, edge_index=gt_scene_graphs.edge_index, edge_attr=edge_cat)\n",
    "\n",
    "        # # excute the 5 layers of GCN using node features\n",
    "        # # x_executed = self.gcn_seq(x=x_encoded, edge_index=gt_scene_graphs.edge_index, instr_vectors=instr_vectors, batch=gt_scene_graphs.batch)#\n",
    "        # x_executed = self.gcn_seq(x=x_encoded, edge_index=gt_scene_graphs.edge_index, batch=gt_scene_graphs.batch)#\n",
    "        # x_executed_concept = self.gcn_seq(x=x_encoded_concept, edge_index=gt_scene_graphs_concept.edge_index, batch=gt_scene_graphs_concept.batch)#\n",
    "        # # print(f'x_executed={x_executed.shape}')\n",
    "        # # print(f'x_executed_conc={x_executed_concept.shape}') \n",
    "\n",
    "\n",
    "        # ##################################\n",
    "        # # Final Layer of the Neural Execution Module, global pooling\n",
    "        # # (batch_size, channels)\n",
    "        # ##################################\n",
    "        # #global_language_feature = questions_encoded[0] # should be changed when completing NEM#\n",
    "        # graph_final_feature = self.graph_global_attention_pooling(\n",
    "        #     x = x_executed, # x=x_encoded,\n",
    "        #     #u = global_language_feature,#\n",
    "        #     batch = gt_scene_graphs.batch,\n",
    "        #     # no need for edge features since it is global node pooling\n",
    "        #     size = None)\n",
    "        # # print(f'graph_final_feature={graph_final_feature.shape}')\n",
    "\n",
    "\n",
    "        # graph_final_feature_concept = self.graph_global_attention_pooling(\n",
    "        #     x = x_executed_concept, # x=x_encoded,\n",
    "        #     #u = global_language_feature,#\n",
    "        #     batch = gt_scene_graphs_concept.batch,\n",
    "        #     # no need for edge features since it is global node pooling\n",
    "        #     size = None)\n",
    "        # # print(f'graph_final_feature_conc={graph_final_feature_concept.shape}')\n",
    "\n",
    "        # ##################################\n",
    "        # # Call Short Answer Classification Module Only for Debug\n",
    "        # ##################################\n",
    "        # # short_answer_feature = questions_encoded[0]\n",
    "        \n",
    "        # # short_answer_feature = torch.cat( ( graph_final_feature, graph_final_feature_concept, graph_final_feature * graph_final_feature_concept ), dim=-1 )#\n",
    "        # short_answer_feature=graph_final_feature#\n",
    "        # # short_answer_feature=x_executed\n",
    "\n",
    "        # short_answer_logits = self.logit_fc(short_answer_feature)\n",
    "\n",
    "        gcn_sg=self.my_gcn_sg(x=x_encoded, edge_index=gt_scene_graphs.edge_index, batch=gt_scene_graphs.batch)#*********************\n",
    "        # print(gt_scene_graphs.edge_index)\n",
    "        # print(\"edge_shap\",gt_scene_graphs.edge_index.shape)\n",
    "        # print(\"node_shap\",x_encoded.shape)\n",
    "        # print('gcn_shap', self.my_gcn_seq.lin.weight.shape)\n",
    "        # print()\n",
    "        gcn_concept=self.my_gcn_sg(x=x_encoded_concept, edge_index=gt_scene_graphs_concept.edge_index, batch=gt_scene_graphs_concept.batch)#*********************\n",
    "        # if img_id==2/165122.jpg or img_id==7/21427.jpg or img_id==10/175425.png or img_id==3/46313.jpg or img_id==3/101383.jpg img_id==or 0/155290.jpg or img_id==7/54467.jpg or img_id==3/107983.jpg:\n",
    "        #   print(gt_scene_graphs.edge_index)\n",
    "        #   print(gt_scene_graphs_concept.edge_index)\n",
    "\n",
    "        # gcn_sg = self.gat_seq(x=x_encoded, edge_index=gt_scene_graphs.edge_index, edge_attr=edge_attr_encoded, batch=gt_scene_graphs.batch)\n",
    "        # gcn_concept = self.gat_seq(x=x_encoded_concept, edge_index=gt_scene_graphs_concept.edge_index, edge_attr=edge_attr_encoded_concept, batch=gt_scene_graphs_concept.batch)\n",
    "\n",
    "\n",
    "        ##################################\n",
    "        # Final Layer of the Neural Execution Module, global pooling\n",
    "        # (batch_size, channels)\n",
    "        ##################################\n",
    "        # global_language_feature = gcn_concept # should be changed when completing NEM\n",
    "        # graph_final_feature = self.graph_global_attention_pooling(\n",
    "        #     x = gcn_sg, # x=x_encoded,\n",
    "        #     u = gcn_concept,\n",
    "        #     batch = gt_scene_graphs.batch,\n",
    "        #     # no need for edge features since it is global node pooling\n",
    "        #     size = None)\n",
    "        gcn_sg=self.normalize(gcn_sg)\n",
    "        gcn_concept=self.normalize(gcn_concept)       \n",
    "        qkv=torch.stack([gcn_sg, gcn_concept, gcn_sg*gcn_concept],dim=1)\n",
    "        # qkv=self.dropout(self.normalize(qkv))\n",
    "        # qkv=self.normalize(self.dropout(qkv))\n",
    "        \n",
    "        # qkv=torch.cat( (gcn_sg, gcn_concept), dim=1 )\n",
    "        # graph_final_feature = self.graph_global_attention(q = qkv, k = qkv, v=qkv, batch=gt_scene_graphs.batch)\n",
    "        graph_final_feature, attent_weight = self.graph_global_attention(qkv,qkv)\n",
    "        \n",
    "        # graph_final_feature = self.graph_global_attention(qkv, qkv, qkv)\n",
    "        # graph_final_feature, attent_weight = self.multihead_attn(qkv, qkv, qkv)\n",
    "        # print(graph_final_feature.shape)\n",
    "        # x = torch.cat( (gcn_sg, gcn_concept, gcn_sg*gcn_concept), dim=-1 )\n",
    "        \n",
    "        # graph_final_feature = self.dropout(graph_final_feature)\n",
    "        # graph_final_feature=self.normalize(graph_final_feature)\n",
    "        # print(qkv.shape)\n",
    "        # print(graph_final_feature.shape)\n",
    "        graph_final_feature=graph_final_feature.contiguous().view(graph_final_feature.shape[0],-1)\n",
    "        # x = torch.cat( (gcn_sg, gcn_concept, gcn_sg*gcn_concept), dim=-1 )\n",
    "        # graph_final_feature = torch.cat( (x, graph_final_feature), dim=-1)\n",
    "        # graph_final_feature=graph_final_feature.view(graph_final_feature.shape[0], graph_final_feature.shape[1]*graph_final_feature.shape[2])\n",
    "        # print(graph_final_feature.shape)\n",
    "        # graph_final_feature=torch.sum(graph_final_feature)\n",
    "        # print(graph_final_feature.shape)\n",
    "\n",
    "\n",
    "        # img_outputs=self.pretrain_model(img_inputs)\n",
    "\n",
    "        # short_ans_feat = torch.cat( (gcn_sg, gcn_concept, gcn_sg*gcn_concept), dim=-1 )#\n",
    "        # short_ans_feat = torch.cat( ( graph_final_feature, gcn_concept, graph_final_feature*gcn_concept), dim=-1 )#\n",
    "        short_ans_feat=graph_final_feature\n",
    "        my_short_answer_logits = self.my_logit_fc(short_ans_feat)\n",
    "        # my_short_answer_logits = self.my_linear(short_ans_feat)\n",
    "\n",
    "       \n",
    "        # x=x_encoded_concept\n",
    "        # edge_index=gt_scene_graphs_concept.edge_index\n",
    "        # batch=gt_scene_graphs_concept.batch\n",
    "        # my_short_answer_logits=Sequential('x, edge_index, batch', [\n",
    "        #     (Dropout(p=0.5), 'x -> x'),\n",
    "        #     (GCNConv(self.scene_graph_encoder.sg_emb_dim, 64), 'x, edge_index -> x1'),\n",
    "        #     ReLU(inplace=True),\n",
    "        #     (GCNConv(64, 64), 'x1, edge_index -> x2'),\n",
    "        #     ReLU(inplace=True),\n",
    "        #     (lambda x1, x2: [x1, x2], 'x1, x2 -> xs'),\n",
    "        #     (JumpingKnowledge(\"cat\", 64, num_layers=2), 'xs -> x'),\n",
    "        #     (global_mean_pool, 'x, batch -> x'),\n",
    "        #     Linear(2 * 64, 54),\n",
    "        # ])\n",
    "\n",
    "\n",
    "\n",
    "        # return programs_output, short_answer_logits#\n",
    "        return my_short_answer_logits#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGsIuBPERdX9",
    "outputId": "55857e9d-5127-4942-d7b4-4ef65bc64541"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:398: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5194805194805194, 0.0, 0.5681818181818182, 2.6200873362445414, 0.0, 0.0, 0.0, 4.145077720207254, 0.0, 0.0, 0.6514657980456027, 0.0, 2.2222222222222223, 2.2058823529411766, 0.0, 0.6172839506172839, 0.7692307692307693, 3.508771929824561, 2.8169014084507045, 0.7407407407407408, 0.0, 1.1173184357541899, 0.0, 0.0, 0.0, 0.0, 0.8368200836820083, 0.0, 2.586206896551724, 0.0, 0.0, 1.0204081632653061, 0.0, 4.986149584487535, 3.1372549019607843, 0.8620689655172413, 0.9803921568627451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [0][  22/7542]\tLoss 9.97e-01 (9.26e-01)\tAccuracy@Bitmap 95.37 (96.29)\tPrecision@Bitmap 0.00 (4.70)\tRecall@Bitmap 0.00 (0.38)\taccuracy: 96.29334983352486, precision: 4.70383275261324, recall: 0.38417757541263514, F_score: 0.7103393843725335\n",
      "[0.7103393843725335]\n",
      "epoch_loss=29.580404114925255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 0.0, 0.0, 0.7575757575757576, 0.0, 0.0, 0.0, 15.447154471544716, 0.0, 0.0, 0.0, 1.9417475728155338, 0.0, 8.19672131147541, 0.0, 0.0, 0.0, 0.0, 12.121212121212121, 0.0, 0.0, 0.0, 0.0, 0.0, 12.578616352201259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.306799336650083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.442176870748299, 0.0, 0.0, 3.4722222222222223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [0][   8/7542]\tLoss 9.16e-01 (9.56e-01)\tAccuracy@Bitmap 95.83 (95.30)\tPrecision@Bitmap 0.00 (4.18)\tRecall@Bitmap 0.00 (1.63)\taccuracy: 95.30433210988767, precision: 4.181724315952503, recall: 1.6265060240963853, F_score: 2.3420558045395405\n",
      "[2.3420558045395405]\n",
      "epoch_loss=30.328838723046438\n",
      "micro_fsoce=[0, 10.115606936416185, 9.03954802259887, 13.259668508287293, 0.0, 0.0, 0.0, 31.293881644934807, 0.0, 0.0, 18.104667609618105, 8.32, 0.0, 22.629969418960243, 11.180124223602485, 2.510460251046025, 14.285714285714285, 15.128593040847202, 20.101522842639593, 1.146131805157593, 0.0, 7.174887892376682, 0.8064516129032258, 16.483516483516482, 11.446740858505565, 0.0, 0.6329113924050633, 7.709750566893423, 0.0, 7.913669064748201, 6.827309236947792, 13.225371120107962, 2.941176470588235, 6.395348837209303, 0.0, 7.346938775510205, 7.100591715976331, 8.812260536398467, 0.0, 11.645569620253164, 5.734767025089606, 5.0, 7.06713780918728, 2.5210084033613445, 11.11111111111111, 10.46831955922865, 11.857707509881422, 6.205250596658711, 1.146131805157593, 5.5813953488372094, 10.9375, 6.089743589743589, 0.0, 2.857142857142857]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [1][  22/7542]\tLoss 6.68e-01 (8.65e-01)\tAccuracy@Bitmap 94.87 (94.65)\tPrecision@Bitmap 13.16 (12.05)\tRecall@Bitmap 15.15 (8.76)\taccuracy: 94.6457860671597, precision: 12.054445750097925, recall: 8.757825839499146, F_score: 10.14504697544091\n",
      "[0.7103393843725335, 10.14504697544091]\n",
      "epoch_loss=27.64154427485951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 18.009478672985782, 10.576923076923077, 19.879518072289155, 0.0, 0.0, 0.0, 20.618556701030926, 0.0, 0.0, 17.99307958477509, 0.0, 0.0, 16.539050535987748, 15.11627906976744, 11.76470588235294, 17.02127659574468, 13.068181818181818, 26.56826568265683, 0.0, 0.0, 0.0, 1.9417475728155338, 10.702341137123746, 16.39344262295082, 0.0, 9.090909090909092, 3.6363636363636362, 0.0, 0.0, 0.0, 10.76923076923077, 0.0, 0.0, 0.0, 0.0, 7.6190476190476195, 8.571428571428571, 0.0, 17.449664429530202, 0.0, 0.0, 0.0, 0.0, 6.051437216338881, 4.294478527607362, 15.384615384615385, 4.878048780487805, 0.0, 4.545454545454546, 0.0, 0.0, 0.0, 4.878048780487805]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [1][   8/7542]\tLoss 9.45e-01 (9.16e-01)\tAccuracy@Bitmap 93.98 (93.81)\tPrecision@Bitmap 7.14 (9.30)\tRecall@Bitmap 7.14 (9.02)\taccuracy: 93.80630630630631, precision: 9.299917149958576, recall: 9.016064257028113, F_score: 9.1557911908646\n",
      "[2.3420558045395405, 9.1557911908646]\n",
      "epoch_loss=29.0508903889429\n",
      "micro_fsoce=[0, 24.249422632794456, 22.10184182015168, 27.925270403146506, 0.0, 1.335113484646195, 0.0, 43.53448275862069, 0.0, 0.43859649122807015, 28.010247651579846, 14.045801526717558, 0.0, 26.21359223300971, 24.145785876993166, 16.103896103896105, 25.291181364392678, 21.792260692464357, 20.454545454545457, 1.662049861495845, 0.0, 12.703101920236337, 8.174386920980927, 21.316033364226136, 16.738197424892704, 0.0, 6.490872210953347, 16.012558869701728, 0.0, 14.325068870523417, 8.56610800744879, 16.258064516129032, 11.7359413202934, 6.79886685552408, 0.0, 17.12962962962963, 9.722222222222223, 15.649867374005305, 0.0, 16.260162601626014, 11.363636363636363, 9.174311926605505, 17.252396166134183, 6.1465721040189125, 11.05318039624609, 15.712383488681759, 15.429403202328967, 7.2992700729927, 5.263157894736842, 8.754208754208754, 15.32258064516129, 6.299212598425196, 0.0, 7.100591715976331]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [2][  22/7542]\tLoss 8.33e-01 (8.26e-01)\tAccuracy@Bitmap 93.35 (93.59)\tPrecision@Bitmap 16.07 (14.74)\tRecall@Bitmap 21.95 (17.94)\taccuracy: 93.58604162369741, precision: 14.735796118774841, recall: 17.93540125213432, F_score: 16.178924399948656\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656]\n",
      "epoch_loss=26.404494416915764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 26.24113475177305, 19.93127147766323, 30.493273542600896, 0.0, 8.121827411167512, 0.0, 24.644549763033176, 0.0, 3.125, 23.045267489711936, 5.172413793103448, 0.0, 17.77777777777778, 19.047619047619047, 29.003021148036257, 21.164021164021165, 14.035087719298245, 25.10460251046025, 3.389830508474576, 0.0, 9.15032679738562, 1.9607843137254901, 13.10344827586207, 12.957746478873238, 0.0, 8.031088082901555, 11.278195488721805, 0.0, 10.38961038961039, 6.6350710900473935, 14.634146341463413, 6.514657980456026, 3.508771929824561, 0.0, 16.27906976744186, 5.691056910569105, 9.75609756097561, 0.0, 10.526315789473683, 5.47945205479452, 5.208333333333334, 12.087912087912088, 0.0, 6.698564593301436, 7.476635514018691, 17.02127659574468, 5.263157894736842, 6.369426751592357, 7.536231884057972, 15.0, 2.557544757033248, 0.0, 0.0]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [2][   8/7542]\tLoss 7.44e-01 (9.15e-01)\tAccuracy@Bitmap 92.13 (92.48)\tPrecision@Bitmap 18.75 (9.04)\tRecall@Bitmap 42.86 (12.95)\taccuracy: 92.47580914247581, precision: 9.04121110176619, recall: 12.951807228915662, F_score: 10.648836057454185\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185]\n",
      "epoch_loss=29.02065902664548\n",
      "micro_fsoce=[0, 28.202368137782564, 29.560336763330213, 33.47713546160483, 0.0, 5.012531328320802, 0.0, 46.86840253342716, 0.0, 5.914972273567468, 29.359430604982208, 17.00507614213198, 0.0, 29.44582299421009, 27.00507614213198, 17.429193899782135, 25.56179775280899, 22.838847385272146, 23.425022182786158, 7.06401766004415, 1.3793103448275863, 15.852047556142669, 8.287292817679557, 19.652173913043477, 18.81881881881882, 4.694835680751173, 11.363636363636363, 21.650879566982407, 0.0, 19.298245614035086, 13.654618473895583, 18.64406779661017, 15.308641975308642, 9.956709956709958, 3.79746835443038, 20.94240837696335, 11.228070175438596, 15.70926143024619, 0.0, 16.34980988593156, 12.135922330097088, 12.925170068027212, 20.47930283224401, 8.237986270022883, 12.327311370882041, 15.006150061500614, 16.7741935483871, 10.29940119760479, 4.958677685950414, 11.881188118811881, 18.181818181818183, 5.943152454780361, 0.0, 8.6687306501548]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [3][  22/7542]\tLoss 7.95e-01 (7.95e-01)\tAccuracy@Bitmap 91.25 (93.01)\tPrecision@Bitmap 9.88 (15.30)\tRecall@Bitmap 20.51 (22.60)\taccuracy: 93.01099030613749, precision: 15.298651252408476, recall: 22.59533295389869, F_score: 18.244485294117645\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645]\n",
      "epoch_loss=25.415719020669744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 27.81456953642384, 23.376623376623375, 34.66666666666667, 0.0, 5.714285714285714, 0.0, 25.405405405405407, 0.0, 0.0, 25.0, 1.8181818181818181, 0.0, 19.801980198019802, 19.858156028368796, 32.32876712328767, 20.754716981132077, 13.40782122905028, 24.354243542435423, 5.263157894736842, 0.0, 7.526881720430108, 12.060301507537687, 13.615023474178404, 13.377926421404682, 7.017543859649122, 7.38255033557047, 16.901408450704224, 0.0, 9.330628803245435, 3.9215686274509802, 14.285714285714285, 8.51063829787234, 8.695652173913043, 4.878048780487805, 19.78021978021978, 4.102564102564102, 7.2727272727272725, 0.0, 12.605042016806722, 6.4, 4.2105263157894735, 11.155378486055776, 0.0, 7.792207792207792, 6.25, 9.1324200913242, 4.615384615384616, 4.761904761904762, 9.090909090909092, 18.285714285714285, 3.4482758620689653, 2.898550724637681, 4.449648711943794]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [3][   8/7542]\tLoss 7.43e-01 (8.66e-01)\tAccuracy@Bitmap 92.59 (92.11)\tPrecision@Bitmap 12.50 (9.31)\tRecall@Bitmap 21.43 (14.62)\taccuracy: 92.11364141919698, precision: 9.30827259941184, recall: 14.61847389558233, F_score: 11.374111397547066\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066]\n",
      "epoch_loss=27.46664103439876\n",
      "micro_fsoce=[0, 30.816326530612244, 31.13456464379947, 34.527687296416936, 0.0, 10.586881472957423, 0.0, 46.49499284692418, 0.0, 7.6923076923076925, 31.879194630872483, 15.163398692810457, 1.1976047904191618, 29.75206611570248, 28.436911487758948, 17.842323651452283, 29.301075268817208, 26.08695652173913, 24.02088772845953, 10.839160839160838, 4.819277108433735, 17.874396135265698, 9.663865546218489, 22.30347349177331, 18.250950570342205, 7.729468599033816, 11.414982164090368, 21.830209481808158, 0.0, 24.144144144144146, 14.97005988023952, 20.275344180225282, 17.715617715617714, 11.031175059952037, 5.2356020942408374, 19.742489270386265, 13.056379821958458, 17.026378896882495, 3.4934497816593884, 16.84981684981685, 12.5, 13.47305389221557, 22.403258655804482, 7.5892857142857135, 14.301929625425652, 17.11606096131301, 18.75, 12.871287128712872, 7.345575959933222, 12.393162393162394, 23.008849557522122, 8.47457627118644, 10.526315789473683, 9.817671809256662]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [4][  22/7542]\tLoss 7.56e-01 (7.68e-01)\tAccuracy@Bitmap 93.10 (92.83)\tPrecision@Bitmap 13.56 (16.04)\tRecall@Bitmap 20.51 (25.43)\taccuracy: 92.8324837699009, precision: 16.03913297132343, recall: 25.426863972680707, F_score: 19.670326646302872\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872]\n",
      "epoch_loss=24.551773881508133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.555555555555557, 28.921568627450984, 34.20074349442379, 0.0, 2.380952380952381, 0.0, 24.46808510638298, 0.0, 6.167400881057269, 22.988505747126435, 6.0606060606060606, 0.0, 22.065727699530516, 20.437956204379564, 26.537216828478964, 22.36024844720497, 17.00404858299595, 22.5, 6.844106463878327, 0.0, 9.25925925925926, 10.256410256410255, 6.106870229007633, 19.047619047619047, 0.0, 6.896551724137931, 12.903225806451612, 0.0, 14.173228346456693, 0.0, 10.660980810234541, 11.03448275862069, 4.761904761904762, 5.88235294117647, 25.49019607843137, 3.571428571428571, 7.6923076923076925, 6.626506024096386, 9.94475138121547, 7.0588235294117645, 5.9620596205962055, 17.24137931034483, 5.263157894736842, 7.492795389048991, 10.0, 12.222222222222221, 7.567567567567568, 4.964539007092199, 10.638297872340425, 18.487394957983195, 4.142011834319527, 5.517241379310345, 4.524886877828054]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [4][   8/7542]\tLoss 7.24e-01 (8.48e-01)\tAccuracy@Bitmap 92.82 (92.28)\tPrecision@Bitmap 16.00 (9.91)\tRecall@Bitmap 28.57 (15.22)\taccuracy: 92.27560894227561, precision: 9.911087866108787, recall: 15.220883534136545, F_score: 12.005068102629078\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078]\n",
      "epoch_loss=26.902494203476678\n",
      "micro_fsoce=[0, 33.33333333333333, 35.914332784184516, 37.568199532346064, 0.4016064257028112, 15.102481121898597, 0.0, 47.918188458729, 0.0, 9.171075837742503, 34.77508650519031, 20.10723860589812, 0.0, 31.338582677165356, 31.431431431431434, 20.323325635103924, 31.292517006802722, 27.77777777777778, 26.408125577100645, 16.37239165329053, 5.095541401273886, 20.30075187969925, 15.659955257270694, 25.17766497461929, 21.76991150442478, 12.093023255813954, 16.666666666666664, 29.427792915531338, 0.0, 27.609427609427613, 17.870722433460077, 21.17202268431002, 21.782178217821784, 18.223234624145785, 13.636363636363635, 25.55205047318612, 15.779092702169626, 21.142162818955043, 10.0418410041841, 18.660287081339714, 16.766467065868262, 17.52988047808765, 24.860853432282003, 16.666666666666664, 16.987542468856173, 20.96069868995633, 21.855146124523507, 14.863387978142075, 16.99604743083004, 18.859649122807017, 26.02495543672014, 11.678832116788321, 22.22222222222222, 18.76046901172529]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [5][  22/7542]\tLoss 7.15e-01 (7.16e-01)\tAccuracy@Bitmap 93.01 (93.23)\tPrecision@Bitmap 25.76 (19.11)\tRecall@Bitmap 33.33 (29.71)\taccuracy: 93.23246609112428, precision: 19.105133132034037, recall: 29.709732498577118, F_score: 23.25555493679345\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345]\n",
      "epoch_loss=22.892421801716594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 27.516778523489933, 29.64705882352941, 37.89868667917448, 0.0, 11.206896551724139, 0.0, 27.27272727272727, 0.0, 2.2346368715083798, 20.37037037037037, 9.7165991902834, 0.0, 21.978021978021978, 18.51851851851852, 32.87671232876712, 20.76923076923077, 13.003095975232199, 25.27075812274368, 3.7037037037037033, 0.0, 7.971014492753622, 13.253012048192772, 14.043583535108958, 18.128654970760234, 0.0, 12.413793103448276, 10.75268817204301, 0.0, 14.563106796116504, 8.391608391608392, 13.397129186602871, 8.791208791208792, 6.557377049180328, 3.571428571428571, 21.951219512195124, 5.769230769230769, 9.615384615384617, 4.761904761904762, 16.600790513833992, 8.695652173913043, 7.07070707070707, 15.037593984962406, 5.9405940594059405, 6.315789473684211, 8.16326530612245, 11.11111111111111, 7.55813953488372, 3.361344537815126, 12.030075187969924, 16.99346405228758, 2.2900763358778624, 9.210526315789473, 4.739336492890995]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [5][   8/7542]\tLoss 7.10e-01 (8.42e-01)\tAccuracy@Bitmap 92.82 (92.50)\tPrecision@Bitmap 16.00 (11.43)\tRecall@Bitmap 28.57 (17.29)\taccuracy: 92.49805360916471, precision: 11.42819219538094, recall: 17.289156626506024, F_score: 13.760588141281765\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765]\n",
      "epoch_loss=26.706740924290248\n",
      "micro_fsoce=[0, 35.49618320610687, 36.48424543946932, 38.095238095238095, 0.0, 16.43835616438356, 0.0, 48.87599709934735, 0.0, 8.214285714285714, 35.25480367585631, 21.47165259348613, 0.6134969325153374, 32.16896831844029, 31.411530815109344, 20.0, 31.8562874251497, 29.804727646454264, 27.223230490018146, 17.311233885819522, 3.79746835443038, 20.689655172413794, 14.742014742014742, 26.247689463955638, 23.79654859218892, 13.397129186602871, 16.691505216095383, 28.07017543859649, 0.0, 26.580226904376016, 20.554649265905383, 22.55125284738041, 22.033898305084744, 21.36279926335175, 17.733990147783253, 25.245441795231415, 16.964285714285715, 22.25130890052356, 4.545454545454546, 20.90997095837367, 19.012797074954296, 19.871794871794872, 26.923076923076923, 17.902813299232736, 16.13588110403397, 21.994884910485936, 21.90132370637786, 17.46031746031746, 18.103448275862068, 20.043572984749456, 27.82608695652174, 14.432989690721648, 22.857142857142858, 21.52777777777778]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [6][  22/7542]\tLoss 5.76e-01 (7.03e-01)\tAccuracy@Bitmap 93.69 (93.32)\tPrecision@Bitmap 19.18 (19.99)\tRecall@Bitmap 46.67 (31.13)\taccuracy: 93.32429751416757, precision: 19.99360204734485, recall: 31.125498007968126, F_score: 24.347487339306582\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582]\n",
      "epoch_loss=22.470208367048684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.936305732484076, 29.698375870069604, 37.59398496240601, 0.0, 9.44206008583691, 0.0, 28.290766208251473, 0.0, 3.4682080924855487, 23.157894736842106, 5.813953488372093, 0.0, 23.11320754716981, 15.209125475285171, 33.97260273972603, 20.388349514563107, 14.61794019933555, 25.36231884057971, 8.974358974358974, 0.0, 9.053497942386832, 9.580838323353294, 15.469613259668508, 16.938110749185668, 0.0, 10.062893081761008, 12.5, 0.0, 14.689265536723164, 8.80503144654088, 13.88888888888889, 9.75609756097561, 8.88888888888889, 3.4482758620689653, 21.428571428571427, 4.081632653061225, 8.695652173913043, 2.2222222222222223, 16.546762589928058, 8.695652173913043, 8.13953488372093, 13.496932515337424, 6.504065040650407, 7.092198581560284, 9.30232558139535, 10.0418410041841, 7.807807807807808, 3.8834951456310676, 10.062893081761008, 16.99346405228758, 2.181818181818182, 9.333333333333334, 5.263157894736842]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [6][   8/7542]\tLoss 7.24e-01 (8.42e-01)\tAccuracy@Bitmap 92.59 (92.72)\tPrecision@Bitmap 15.38 (11.87)\tRecall@Bitmap 28.57 (17.17)\taccuracy: 92.72119341563786, precision: 11.87335092348285, recall: 17.16867469879518, F_score: 14.038256300796323\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323]\n",
      "epoch_loss=26.689101065908158\n",
      "micro_fsoce=[0, 35.78947368421053, 36.15062761506277, 38.058551617873654, 0.0, 18.276220145379025, 0.0, 50.03573981415297, 0.0, 9.242144177449168, 36.08888888888889, 19.319727891156464, 1.8018018018018018, 32.56578947368421, 32.44274809160305, 19.875776397515526, 30.94059405940594, 29.273285568065504, 27.051397655545532, 18.33910034602076, 5.0, 21.508034610630407, 14.746543778801843, 26.41509433962264, 24.904942965779465, 11.483253588516746, 20.029027576197386, 30.339805825242717, 0.0, 26.981450252951095, 20.62937062937063, 23.373493975903614, 23.89937106918239, 19.646365422396855, 15.384615384615385, 25.0, 17.636684303350968, 21.35678391959799, 6.557377049180328, 21.10358180058083, 19.2090395480226, 21.223021582733814, 28.256880733944957, 18.181818181818183, 17.574257425742573, 21.380243572395127, 22.991347342398022, 18.53546910755149, 18.725099601593627, 23.059866962305986, 28.17391304347826, 15.655577299412915, 30.303030303030305, 21.908127208480565]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [7][  22/7542]\tLoss 7.62e-01 (6.95e-01)\tAccuracy@Bitmap 92.93 (93.48)\tPrecision@Bitmap 18.75 (20.66)\tRecall@Bitmap 27.27 (31.32)\taccuracy: 93.47849573253976, precision: 20.661661191928673, recall: 31.324701195219124, F_score: 24.899621105016116\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116]\n",
      "epoch_loss=22.218634958994592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 28.671328671328673, 29.767441860465116, 36.74242424242424, 0.0, 9.401709401709402, 0.0, 27.037773359840955, 0.0, 2.2857142857142856, 19.321148825065272, 6.965174129353234, 0.0, 22.065727699530516, 15.384615384615385, 32.09169054441261, 18.90547263681592, 18.11023622047244, 25.64102564102564, 4.958677685950414, 3.125, 7.468879668049793, 10.112359550561797, 12.851405622489958, 19.710144927536234, 0.0, 8.737864077669903, 12.738853503184714, 0.0, 14.814814814814813, 8.0, 14.358974358974358, 6.629834254143646, 7.6923076923076925, 3.8461538461538463, 22.727272727272727, 6.451612903225806, 8.547008547008547, 2.197802197802198, 18.01801801801802, 8.771929824561402, 8.333333333333332, 13.19796954314721, 7.792207792207792, 7.671232876712329, 8.187134502923977, 11.594202898550725, 7.633587786259542, 4.329004329004329, 10.126582278481013, 15.950920245398773, 3.1914893617021276, 9.271523178807946, 4.195804195804196]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [7][   8/7542]\tLoss 7.21e-01 (8.41e-01)\tAccuracy@Bitmap 92.59 (92.45)\tPrecision@Bitmap 17.86 (11.26)\tRecall@Bitmap 35.71 (17.15)\taccuracy: 92.45356467578691, precision: 11.26054852320675, recall: 17.14859437751004, F_score: 13.594396688952562\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562]\n",
      "epoch_loss=26.68699887252989\n",
      "micro_fsoce=[0, 36.416747809152874, 37.933954276037255, 37.88819875776397, 0.0, 16.59751037344398, 0.0, 48.82697947214076, 0.0, 11.130434782608695, 35.87140439932318, 21.483375959079286, 2.43161094224924, 32.69069572506287, 32.007759456838016, 20.51282051282051, 33.80281690140845, 28.789531079607418, 28.09756097560976, 18.76046901172529, 11.428571428571429, 21.777221526908637, 16.818181818181817, 26.359447004608295, 23.992133726647, 13.82488479262673, 18.784530386740332, 29.554140127388536, 0.0, 28.62129144851658, 21.221864951768488, 24.634146341463413, 24.116424116424117, 21.47117296222664, 17.346938775510203, 26.27118644067797, 18.74039938556068, 20.636942675159236, 2.2598870056497176, 22.243902439024392, 18.71345029239766, 21.314387211367674, 26.56826568265683, 17.61904761904762, 19.37046004842615, 23.398328690807798, 23.31288343558282, 19.058553386911594, 18.560606060606062, 23.21083172147002, 27.586206896551722, 16.791044776119403, 27.027027027027028, 19.62962962962963]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [8][  22/7542]\tLoss 6.09e-01 (6.90e-01)\tAccuracy@Bitmap 94.44 (93.48)\tPrecision@Bitmap 21.82 (20.81)\tRecall@Bitmap 34.29 (31.66)\taccuracy: 93.4831609652612, precision: 20.808978255786766, recall: 31.65907797381901, F_score: 25.11215823481279\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279]\n",
      "epoch_loss=22.04125992524422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.042904290429046, 30.165289256198346, 37.6865671641791, 0.0, 9.777777777777779, 0.0, 27.964601769911507, 0.0, 2.4539877300613497, 21.641791044776117, 8.583690987124463, 0.0, 20.72936660268714, 16.39344262295082, 32.34501347708895, 19.801980198019802, 15.081967213114755, 22.71062271062271, 4.166666666666666, 2.185792349726776, 7.194244604316546, 9.580838323353294, 16.853932584269664, 19.310344827586206, 0.0, 8.860759493670885, 12.643678160919542, 0.0, 14.857142857142858, 6.666666666666667, 14.432989690721648, 8.88888888888889, 5.797101449275362, 3.8461538461538463, 23.03030303030303, 6.557377049180328, 8.333333333333332, 1.9607843137254901, 17.52988047808765, 10.0, 9.230769230769232, 14.76510067114094, 4.0, 6.451612903225806, 8.75, 12.435233160621761, 8.59375, 5.780346820809249, 13.461538461538462, 15.053763440860216, 1.9047619047619049, 9.210526315789473, 5.769230769230769]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [8][   8/7542]\tLoss 7.13e-01 (8.37e-01)\tAccuracy@Bitmap 92.82 (92.72)\tPrecision@Bitmap 18.52 (12.02)\tRecall@Bitmap 35.71 (17.43)\taccuracy: 92.72397397397397, precision: 12.017167381974248, recall: 17.429718875502008, F_score: 14.226009997541588\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588]\n",
      "epoch_loss=26.53490138053894\n",
      "micro_fsoce=[0, 36.4333652924257, 37.09949409780776, 37.88476716653512, 1.2024048096192386, 17.148760330578515, 0.0, 49.14040114613181, 0.0, 10.714285714285714, 35.65754633715799, 21.372031662269126, 2.380952380952381, 33.33333333333333, 33.011583011583014, 21.008403361344538, 33.125778331257784, 29.652996845425868, 28.705440900562852, 19.642857142857142, 9.03954802259887, 21.313506815365553, 17.48878923766816, 27.442827442827443, 25.265188042430086, 15.929203539823009, 19.943019943019944, 30.788804071246815, 0.0, 29.38053097345133, 21.020092735703248, 25.679012345679013, 23.599999999999998, 21.03250478011472, 20.85308056872038, 27.393225331369663, 17.488076311605724, 22.36503856041131, 8.791208791208792, 22.46740220661986, 20.074349442379184, 21.5929203539823, 29.65779467680608, 20.551378446115287, 18.90547263681592, 24.78134110787172, 24.099378881987576, 19.471153846153847, 17.463617463617464, 18.526315789473685, 29.757785467128027, 15.555555555555555, 30.303030303030305, 22.756410256410255]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [9][  22/7542]\tLoss 6.64e-01 (6.84e-01)\tAccuracy@Bitmap 94.19 (93.58)\tPrecision@Bitmap 27.69 (21.35)\tRecall@Bitmap 45.00 (32.10)\taccuracy: 93.57622008112594, precision: 21.353525792711782, recall: 32.100170745589075, F_score: 25.646563974307963\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963]\n",
      "epoch_loss=21.8630507452003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 26.573426573426573, 29.75929978118162, 37.476099426386234, 0.0, 7.111111111111111, 0.0, 27.037037037037038, 0.0, 4.807692307692308, 21.01694915254237, 6.521739130434782, 0.0, 21.721311475409834, 19.791666666666664, 32.27665706051873, 20.87912087912088, 15.09433962264151, 25.833333333333336, 1.6528925619834711, 0.0, 7.30593607305936, 4.615384615384616, 14.678899082568808, 20.717131474103585, 0.0, 8.24742268041237, 11.398963730569948, 0.0, 17.48633879781421, 10.285714285714285, 15.384615384615385, 9.70873786407767, 4.651162790697675, 4.0, 20.8955223880597, 6.629834254143646, 10.416666666666668, 0.0, 17.424242424242426, 8.47457627118644, 6.024096385542169, 15.277777777777779, 7.246376811594203, 6.8807339449541285, 7.894736842105263, 11.235955056179774, 9.243697478991598, 4.166666666666666, 9.63855421686747, 17.543859649122805, 2.711864406779661, 8.0, 5.769230769230769]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [9][   8/7542]\tLoss 7.48e-01 (8.42e-01)\tAccuracy@Bitmap 93.75 (92.68)\tPrecision@Bitmap 15.79 (11.56)\tRecall@Bitmap 21.43 (16.77)\taccuracy: 92.67600934267601, precision: 11.555494049266537, recall: 16.76706827309237, F_score: 13.681795838112404\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404]\n",
      "epoch_loss=26.69063946178981\n",
      "micro_fsoce=[0, 35.467980295566505, 38.18930041152264, 37.46031746031746, 0.8016032064128256, 17.51054852320675, 0.0, 48.756218905472636, 0.0, 15.384615384615385, 37.050043898156275, 21.199442119944212, 1.2084592145015105, 32.950819672131146, 33.939393939393945, 20.982142857142858, 31.565329883570502, 30.982905982905983, 28.486646884272997, 19.72318339100346, 9.30232558139535, 21.76541717049577, 17.2972972972973, 26.590693257359927, 26.406926406926406, 11.76470588235294, 20.535714285714285, 30.419161676646706, 0.0, 29.441624365482234, 21.794871794871796, 26.5, 25.05592841163311, 20.965058236272878, 23.83419689119171, 28.306878306878307, 19.58041958041958, 23.667100130039014, 11.224489795918368, 22.4609375, 21.57676348547718, 22.150882825040128, 29.844961240310074, 18.592964824120603, 20.385050962627407, 24.057971014492754, 24.043715846994534, 18.88745148771022, 23.636363636363637, 24.814814814814813, 29.772329246935204, 17.956656346749224, 26.666666666666668, 23.026315789473685]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [10][  22/7542]\tLoss 6.83e-01 (6.76e-01)\tAccuracy@Bitmap 94.44 (93.63)\tPrecision@Bitmap 23.91 (21.76)\tRecall@Bitmap 26.19 (32.62)\taccuracy: 93.62704656393333, precision: 21.761830177037353, recall: 32.6195219123506, F_score: 26.1067615658363\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363]\n",
      "epoch_loss=21.591063315585508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.53020134228188, 31.319910514541387, 37.105751391465674, 0.0, 9.174311926605505, 0.0, 27.74566473988439, 0.0, 5.4945054945054945, 21.052631578947366, 7.07070707070707, 0.0, 21.030042918454935, 16.589861751152075, 32.13296398891966, 18.81188118811881, 16.600790513833992, 23.754789272030653, 1.639344262295082, 2.1621621621621623, 6.926406926406926, 6.944444444444445, 15.18987341772152, 20.833333333333336, 0.0, 11.1731843575419, 13.114754098360656, 0.0, 17.045454545454543, 8.433734939759036, 14.925373134328357, 9.25925925925926, 5.128205128205128, 3.9215686274509802, 21.390374331550802, 8.187134502923977, 9.75609756097561, 2.247191011235955, 18.775510204081634, 9.917355371900827, 6.593406593406594, 15.789473684210526, 6.2015503875969, 7.046070460704606, 9.655172413793103, 11.055276381909549, 8.664259927797833, 5.208333333333334, 10.526315789473683, 16.56804733727811, 4.694835680751173, 9.271523178807946, 4.678362573099415]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [10][   8/7542]\tLoss 7.08e-01 (8.35e-01)\tAccuracy@Bitmap 93.06 (92.82)\tPrecision@Bitmap 13.64 (12.12)\tRecall@Bitmap 21.43 (17.17)\taccuracy: 92.82198865532199, precision: 12.11734693877551, recall: 17.16867469879518, F_score: 14.207377866400797\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797]\n",
      "epoch_loss=26.47489327476138\n",
      "micro_fsoce=[0, 36.31010794896958, 37.268128161888704, 38.37753510140406, 1.2024048096192386, 16.68426610348469, 0.0, 49.38450398262128, 0.0, 13.945578231292515, 36.53846153846153, 22.849462365591396, 1.8072289156626504, 33.777038269550744, 33.501513622603426, 20.556745182012847, 32.41206030150754, 31.69164882226981, 28.160919540229884, 21.79930795847751, 12.5, 22.71604938271605, 16.08040201005025, 27.281648675171738, 26.87830687830688, 14.150943396226415, 20.497803806734993, 31.12183353437877, 0.0, 29.61672473867596, 22.4025974025974, 26.45241038318912, 25.0, 21.65137614678899, 19.289340101522843, 27.98913043478261, 17.043478260869566, 23.544631306597672, 10.204081632653061, 22.857142857142858, 22.65625, 22.8099173553719, 28.68369351669941, 21.220159151193634, 19.66019417475728, 23.121387283236995, 24.010554089709764, 18.696186961869618, 22.594142259414227, 23.284823284823286, 28.620102214650768, 18.326693227091635, 29.411764705882355, 23.776223776223777]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [11][  22/7542]\tLoss 6.70e-01 (6.74e-01)\tAccuracy@Bitmap 93.35 (93.68)\tPrecision@Bitmap 21.54 (21.97)\tRecall@Bitmap 33.33 (32.57)\taccuracy: 93.68032843238359, precision: 21.96947883674057, recall: 32.569721115537845, F_score: 26.239468103398867\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867]\n",
      "epoch_loss=21.538671464233076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 27.027027027027028, 30.909090909090907, 37.13235294117647, 0.5, 8.0, 0.0, 27.586206896551722, 0.0, 1.1363636363636365, 22.006472491909385, 7.179487179487179, 0.0, 21.982758620689655, 16.9811320754717, 32.32876712328767, 20.304568527918782, 16.194331983805668, 25.296442687747035, 3.4482758620689653, 1.092896174863388, 7.441860465116279, 6.896551724137931, 14.871794871794872, 19.269102990033225, 0.0, 9.045226130653267, 12.021857923497267, 0.0, 16.091954022988507, 9.467455621301776, 15.135135135135137, 10.084033613445378, 4.166666666666666, 3.9215686274509802, 21.11111111111111, 7.650273224043716, 9.900990099009901, 2.2988505747126435, 16.867469879518072, 10.16949152542373, 7.567567567567568, 14.666666666666666, 6.504065040650407, 7.784431137724551, 8.571428571428571, 10.83743842364532, 8.791208791208792, 4.060913705583756, 12.121212121212121, 17.61006289308176, 1.1299435028248588, 9.333333333333334, 6.289308176100629]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [11][   8/7542]\tLoss 7.05e-01 (8.35e-01)\tAccuracy@Bitmap 92.59 (92.89)\tPrecision@Bitmap 17.86 (12.13)\tRecall@Bitmap 35.71 (16.87)\taccuracy: 92.89080747414081, precision: 12.126461671719358, recall: 16.867469879518072, F_score: 14.109347442680775\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775]\n",
      "epoch_loss=26.48503149691082\n",
      "micro_fsoce=[0, 35.637779941577406, 37.5, 38.057948316366485, 1.2024048096192386, 18.59504132231405, 0.0, 48.99135446685879, 0.0, 10.75268817204301, 36.459246275197195, 23.376623376623375, 1.2084592145015105, 33.53090601185436, 33.49851337958374, 21.25, 32.78688524590164, 31.196581196581196, 27.83109404990403, 20.998278829604132, 9.467455621301776, 23.028785982478098, 17.45635910224439, 27.19033232628399, 25.708502024291498, 15.74074074074074, 19.694868238557557, 30.95823095823096, 0.0, 29.896907216494846, 20.462046204620464, 26.13065326633166, 25.106382978723403, 20.51282051282051, 20.0, 28.451882845188287, 17.996604414261462, 23.177083333333336, 9.473684210526317, 23.293172690763054, 22.403258655804482, 22.666666666666664, 29.22201138519924, 19.696969696969695, 21.38200782268579, 25.036390101892287, 23.79084967320261, 19.87421383647799, 21.518987341772153, 24.789915966386555, 28.52233676975945, 19.693654266958426, 32.25806451612903, 24.285714285714285]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [12][  22/7542]\tLoss 6.34e-01 (6.73e-01)\tAccuracy@Bitmap 94.36 (93.70)\tPrecision@Bitmap 15.22 (22.03)\tRecall@Bitmap 20.00 (32.49)\taccuracy: 93.70144474891227, precision: 22.030873130728413, recall: 32.49146272054639, F_score: 26.257689875237165\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165]\n",
      "epoch_loss=21.5145334636761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.06574394463668, 30.52391799544419, 35.48983364140481, 0.5, 9.174311926605505, 0.0, 28.142589118198874, 0.0, 1.1695906432748537, 22.149837133550488, 8.24742268041237, 0.0, 21.21212121212121, 19.230769230769234, 34.054054054054056, 20.94240837696335, 16.06425702811245, 24.81203007518797, 3.6363636363636362, 0.0, 7.894736842105263, 7.8431372549019605, 14.987080103359174, 19.661016949152543, 0.0, 10.16949152542373, 12.290502793296088, 0.0, 13.872832369942195, 10.526315789473683, 15.053763440860216, 9.836065573770492, 5.755395683453238, 4.166666666666666, 22.35294117647059, 7.4074074074074066, 10.1010101010101, 2.3529411764705883, 17.00404858299595, 8.130081300813007, 9.195402298850574, 13.924050632911392, 6.504065040650407, 7.164179104477612, 9.58904109589041, 9.777777777777779, 7.773851590106007, 3.9603960396039604, 9.230769230769232, 17.8343949044586, 1.1173184357541899, 9.271523178807946, 5.063291139240507]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [12][   8/7542]\tLoss 7.29e-01 (8.35e-01)\tAccuracy@Bitmap 93.06 (92.89)\tPrecision@Bitmap 16.67 (12.16)\tRecall@Bitmap 28.57 (16.93)\taccuracy: 92.89219775330886, precision: 12.162747078343674, recall: 16.927710843373493, F_score: 14.154982789018556\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556]\n",
      "epoch_loss=26.48827626591637\n",
      "micro_fsoce=[0, 36.15160349854227, 37.573715248525694, 38.68954758190328, 0.8, 17.237798546209763, 0.0, 48.92395982783357, 0.0, 10.247349823321555, 36.36363636363637, 22.465753424657535, 1.1976047904191618, 34.43037974683544, 33.63006923837784, 20.964360587002094, 33.583959899749374, 31.397849462365592, 28.46299810246679, 21.352313167259787, 9.35672514619883, 23.096446700507613, 15.308641975308642, 26.5625, 26.059979317476735, 15.813953488372093, 21.764705882352942, 31.57894736842105, 0.0, 30.985915492957744, 20.48, 26.368159203980102, 24.839400428265524, 21.65137614678899, 19.230769230769234, 28.61111111111111, 18.83116883116883, 24.133504492939668, 10.471204188481675, 22.54901960784314, 21.44249512670565, 22.82793867120954, 30.443159922928707, 21.92513368983957, 21.22347066167291, 24.67343976777939, 23.27909887359199, 19.663648124191464, 22.707423580786028, 24.516129032258064, 29.225352112676056, 17.88617886178862, 28.57142857142857, 23.214285714285715]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [13][  22/7542]\tLoss 6.67e-01 (6.73e-01)\tAccuracy@Bitmap 94.44 (93.71)\tPrecision@Bitmap 27.27 (22.10)\tRecall@Bitmap 36.59 (32.63)\taccuracy: 93.70512782737657, precision: 22.100698626836905, recall: 32.63375071143996, F_score: 26.35373876073655\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655]\n",
      "epoch_loss=21.508740460973677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.263157894736842, 29.024943310657598, 35.621521335807046, 0.0, 9.523809523809524, 0.0, 27.42857142857143, 0.0, 2.3529411764705883, 21.476510067114095, 8.91089108910891, 0.0, 21.748400852878465, 17.59259259259259, 32.59668508287293, 18.181818181818183, 17.28395061728395, 24.53531598513011, 1.7391304347826086, 3.1413612565445024, 8.294930875576037, 8.860759493670885, 15.66579634464752, 19.333333333333332, 0.0, 7.650273224043716, 13.559322033898304, 0.0, 16.867469879518072, 9.35672514619883, 14.207650273224044, 9.67741935483871, 4.026845637583892, 4.444444444444445, 20.76502732240437, 5.714285714285714, 9.090909090909092, 0.0, 18.487394957983195, 10.084033613445378, 6.666666666666667, 14.473684210526317, 4.411764705882353, 7.242339832869081, 8.633093525179856, 11.822660098522167, 8.275862068965518, 4.232804232804233, 11.200000000000001, 15.0, 1.257861635220126, 9.271523178807946, 5.0]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [13][   8/7542]\tLoss 7.20e-01 (8.34e-01)\tAccuracy@Bitmap 93.06 (92.89)\tPrecision@Bitmap 16.67 (12.06)\tRecall@Bitmap 28.57 (16.75)\taccuracy: 92.89219775330886, precision: 12.064226819036598, recall: 16.74698795180723, F_score: 14.025056756075003\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003]\n",
      "epoch_loss=26.443540005456832\n",
      "micro_fsoce=[0, 36.67953667953668, 37.573715248525694, 39.06614785992218, 0.8032128514056224, 18.39080459770115, 0.0, 49.182658137882015, 0.0, 11.827956989247312, 36.459246275197195, 23.35958005249344, 1.812688821752266, 33.77926421404682, 33.46774193548387, 21.008403361344538, 33.292231812577064, 30.90128755364807, 29.665071770334926, 20.28985507246377, 11.1731843575419, 22.613065326633166, 17.1990171990172, 27.33668341708543, 26.289180990899897, 13.953488372093023, 19.734904270986746, 32.06854345165239, 0.0, 31.15942028985507, 21.001615508885298, 25.757575757575758, 24.40087145969499, 21.468926553672315, 20.304568527918782, 28.45303867403315, 18.874172185430464, 23.14694408322497, 7.567567567567568, 22.805247225025226, 21.96078431372549, 23.223570190641247, 29.469548133595286, 22.163588390501317, 20.51282051282051, 24.48377581120944, 24.02088772845953, 18.75, 23.605150214592275, 24.94432071269488, 29.749103942652326, 20.47244094488189, 30.303030303030305, 24.305555555555554]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [14][  22/7542]\tLoss 6.75e-01 (6.72e-01)\tAccuracy@Bitmap 94.02 (93.73)\tPrecision@Bitmap 24.07 (22.26)\tRecall@Bitmap 30.23 (32.75)\taccuracy: 93.73115491519098, precision: 22.259826910989702, recall: 32.75469550369949, F_score: 26.506232188606464\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464]\n",
      "epoch_loss=21.470354261034625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.87248322147651, 28.95927601809955, 37.33826247689464, 0.0, 10.909090909090908, 0.0, 28.023032629558543, 0.0, 3.4482758620689653, 21.333333333333336, 6.896551724137931, 0.0, 21.45922746781116, 18.099547511312217, 30.985915492957744, 22.22222222222222, 17.647058823529413, 24.175824175824175, 3.5398230088495577, 1.092896174863388, 7.792207792207792, 11.180124223602485, 14.75826972010178, 19.93355481727575, 0.0, 8.695652173913043, 12.429378531073446, 0.0, 13.953488372093023, 8.284023668639055, 15.135135135135137, 9.30232558139535, 5.47945205479452, 4.25531914893617, 21.22905027932961, 4.3478260869565215, 9.950248756218906, 0.0, 18.473895582329316, 9.836065573770492, 9.467455621301776, 14.965986394557824, 6.349206349206349, 7.55813953488372, 9.859154929577464, 9.25925925925926, 8.727272727272728, 4.301075268817205, 9.090909090909092, 16.25, 1.282051282051282, 10.32258064516129, 5.649717514124294]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [14][   8/7542]\tLoss 7.29e-01 (8.34e-01)\tAccuracy@Bitmap 93.29 (92.89)\tPrecision@Bitmap 17.39 (12.18)\tRecall@Bitmap 28.57 (16.97)\taccuracy: 92.88872205538871, precision: 12.17579250720461, recall: 16.967871485943775, F_score: 14.177852348993289\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289]\n",
      "epoch_loss=26.44473355724698\n",
      "micro_fsoce=[0, 36.345966958211854, 36.99914748508099, 38.267716535433074, 1.2024048096192386, 17.708333333333336, 0.0, 49.421965317919074, 0.0, 11.07011070110701, 37.282229965156795, 23.169107856191744, 3.003003003003003, 33.5016835016835, 33.6318407960199, 20.416666666666668, 33.37547408343868, 32.608695652173914, 28.38095238095238, 21.070811744386873, 9.195402298850574, 23.32065906210393, 16.458852867830423, 27.6, 26.880641925777333, 14.814814814814813, 22.157434402332363, 31.941031941031937, 0.0, 31.338028169014088, 21.169036334913113, 26.075949367088608, 24.583333333333332, 20.522388059701495, 21.568627450980394, 27.362482369534558, 19.2, 23.81596752368065, 7.4866310160427805, 23.138832997987926, 21.79732313575526, 23.450586264656618, 29.01960784313726, 21.93211488250653, 20.903225806451616, 24.466571834992887, 24.556962025316455, 21.185372005044137, 22.41014799154334, 25.31645569620253, 29.116117850953206, 19.913419913419915, 30.303030303030305, 23.776223776223777]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [15][  22/7542]\tLoss 6.87e-01 (6.71e-01)\tAccuracy@Bitmap 93.86 (93.73)\tPrecision@Bitmap 25.42 (22.30)\tRecall@Bitmap 34.09 (32.85)\taccuracy: 93.7326281465767, precision: 22.303791354745233, recall: 32.85429709732499, F_score: 26.57000661661057\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057]\n",
      "epoch_loss=21.452876467826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.612244897959183, 28.507795100222715, 36.56716417910448, 0.0, 8.968609865470851, 0.0, 27.547169811320753, 0.0, 2.2988505747126435, 21.639344262295083, 6.730769230769231, 0.0, 21.978021978021978, 16.74418604651163, 31.549295774647888, 19.48717948717949, 17.21311475409836, 25.757575757575758, 3.389830508474576, 0.0, 8.071748878923767, 10.843373493975903, 15.306122448979592, 19.867549668874172, 0.0, 10.256410256410255, 12.154696132596685, 0.0, 15.568862275449103, 10.285714285714285, 14.893617021276595, 8.130081300813007, 4.137931034482759, 3.9215686274509802, 23.121387283236995, 6.629834254143646, 10.050251256281408, 2.4096385542168677, 18.0327868852459, 8.0, 8.13953488372093, 15.172413793103448, 4.444444444444445, 6.837606837606838, 7.792207792207792, 9.950248756218906, 8.96551724137931, 5.347593582887701, 10.144927536231885, 15.853658536585366, 3.9215686274509802, 11.76470588235294, 4.9079754601226995]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [15][   8/7542]\tLoss 7.13e-01 (8.33e-01)\tAccuracy@Bitmap 93.06 (92.86)\tPrecision@Bitmap 13.64 (12.09)\tRecall@Bitmap 21.43 (16.93)\taccuracy: 92.8636970303637, precision: 12.091222030981069, recall: 16.927710843373493, F_score: 14.106425702811245\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245]\n",
      "epoch_loss=26.428609093030293\n",
      "micro_fsoce=[0, 36.55705996131528, 37.233134073441505, 38.64353312302839, 0.4024144869215292, 18.012422360248447, 0.0, 49.41860465116279, 0.0, 12.302284710017574, 36.41207815275311, 22.542595019659238, 1.8181818181818181, 34.154630416312656, 33.33333333333333, 21.47368421052632, 32.75, 32.4265505984766, 28.32699619771863, 22.535211267605636, 10.526315789473683, 22.72159800249688, 20.28985507246377, 26.7591674925669, 25.858585858585858, 12.903225806451612, 21.13095238095238, 30.730478589420656, 0.0, 30.303030303030305, 20.933977455716587, 26.56641604010025, 24.786324786324787, 21.11111111111111, 22.22222222222222, 28.650137741046834, 20.563847429519072, 23.89261744966443, 8.51063829787234, 22.313203684749233, 22.179732313575524, 21.84873949579832, 29.118773946360154, 19.22077922077922, 20.79589216944801, 25.0, 25.12690355329949, 18.939393939393938, 22.99349240780911, 25.75107296137339, 30.66202090592334, 20.659340659340657, 27.77777777777778, 23.91681109185442]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [16][  22/7542]\tLoss 6.66e-01 (6.71e-01)\tAccuracy@Bitmap 92.85 (93.74)\tPrecision@Bitmap 18.57 (22.29)\tRecall@Bitmap 31.71 (32.71)\taccuracy: 93.74146753489103, precision: 22.289010616122933, recall: 32.71200910643142, F_score: 26.512901830762576\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576]\n",
      "epoch_loss=21.446641327465993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 31.944444444444443, 29.42528735632184, 36.666666666666664, 0.0, 10.714285714285714, 0.0, 27.44360902255639, 0.0, 2.4242424242424243, 21.548821548821547, 8.955223880597014, 0.0, 21.88183807439825, 18.433179723502306, 32.87671232876712, 21.428571428571427, 15.767634854771783, 25.735294117647058, 1.8018018018018018, 3.225806451612903, 8.771929824561402, 8.974358974358974, 15.343915343915343, 19.333333333333332, 0.0, 11.11111111111111, 12.359550561797752, 0.0, 15.204678362573098, 8.284023668639055, 14.973262032085561, 9.6, 5.47945205479452, 4.3478260869565215, 22.988505747126435, 7.4074074074074066, 10.0, 0.0, 17.355371900826448, 7.936507936507936, 7.865168539325842, 14.666666666666666, 6.015037593984962, 8.0, 8.571428571428571, 10.945273631840797, 8.362369337979095, 4.060913705583756, 12.5, 15.18987341772152, 2.6490066225165565, 9.210526315789473, 5.780346820809249]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [16][   8/7542]\tLoss 6.95e-01 (8.34e-01)\tAccuracy@Bitmap 93.06 (92.92)\tPrecision@Bitmap 16.67 (12.34)\tRecall@Bitmap 28.57 (17.13)\taccuracy: 92.91791791791792, precision: 12.337286664738212, recall: 17.1285140562249, F_score: 14.343366403228519\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519]\n",
      "epoch_loss=26.443420546395437\n",
      "micro_fsoce=[0, 36.36363636363637, 36.83304647160069, 38.23760818253344, 1.2, 17.49209694415174, 0.0, 49.63820549927641, 0.0, 12.186379928315413, 37.37024221453287, 23.52941176470588, 2.3880597014925375, 35.0727117194183, 34.25742574257426, 21.45922746781116, 32.78271918678526, 31.718061674008812, 27.659574468085108, 23.239436619718308, 10.465116279069768, 23.425692695214106, 17.26618705035971, 27.172827172827173, 25.89641434262948, 17.84037558685446, 21.669106881405565, 31.75, 0.0, 29.28571428571429, 22.503961965134707, 26.649746192893403, 24.307036247334754, 23.26454033771107, 23.88059701492537, 27.53824756606398, 18.887015177065766, 24.635761589403973, 8.51063829787234, 23.943661971830984, 22.562141491395792, 22.70450751252087, 27.63915547024952, 19.338422391857506, 21.011673151750973, 24.817518248175183, 24.102564102564102, 20.151133501259448, 23.63238512035011, 25.738396624472575, 29.411764705882355, 18.79194630872483, 31.25, 25.0]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [17][  22/7542]\tLoss 7.40e-01 (6.71e-01)\tAccuracy@Bitmap 93.18 (93.77)\tPrecision@Bitmap 18.00 (22.47)\tRecall@Bitmap 18.37 (32.86)\taccuracy: 93.77019554691259, precision: 22.472511433297655, recall: 32.861411496869664, F_score: 26.69170759895984\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984]\n",
      "epoch_loss=21.432236542135982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.201342281879196, 30.344827586206897, 37.735849056603776, 0.5025125628140703, 10.909090909090908, 0.0, 27.27272727272727, 0.0, 2.2988505747126435, 21.40468227424749, 6.6350710900473935, 0.0, 20.915032679738562, 18.779342723004692, 32.5068870523416, 19.19191919191919, 16.666666666666664, 25.287356321839084, 5.3097345132743365, 2.197802197802198, 8.108108108108109, 7.741935483870968, 15.789473684210526, 19.52861952861953, 0.0, 8.791208791208792, 11.299435028248588, 0.0, 15.66265060240964, 10.588235294117647, 15.730337078651685, 7.936507936507936, 5.633802816901409, 3.8461538461538463, 20.87912087912088, 7.526881720430108, 10.0, 2.4390243902439024, 18.852459016393443, 11.29032258064516, 4.938271604938271, 13.513513513513514, 6.4, 7.647058823529412, 9.859154929577464, 10.476190476190476, 8.421052631578947, 4.232804232804233, 12.030075187969924, 17.391304347826086, 1.3333333333333335, 9.210526315789473, 5.813953488372093]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [17][   8/7542]\tLoss 7.41e-01 (8.35e-01)\tAccuracy@Bitmap 93.06 (92.94)\tPrecision@Bitmap 10.00 (12.32)\tRecall@Bitmap 14.29 (16.99)\taccuracy: 92.94155266377489, precision: 12.321584619866007, recall: 16.987951807228914, F_score: 14.283302380550397\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397]\n",
      "epoch_loss=26.483486368542625\n",
      "micro_fsoce=[0, 36.08147429679923, 37.86078098471987, 38.89763779527559, 1.2024048096192386, 18.958333333333332, 0.0, 49.63820549927641, 0.0, 11.051693404634582, 36.251105216622456, 23.225806451612904, 2.3880597014925375, 34.78260869565217, 34.489593657086225, 21.008403361344538, 33.29161451814768, 31.956521739130434, 28.974600188146756, 21.238938053097346, 9.090909090909092, 22.807017543859647, 15.841584158415841, 26.89243027888446, 25.844930417495032, 16.289592760180994, 21.021897810218977, 31.725888324873097, 0.0, 29.629629629629626, 22.00956937799043, 26.54639175257732, 26.033057851239672, 21.601489757914337, 20.51282051282051, 28.53146853146853, 19.237147595356554, 24.6684350132626, 8.743169398907105, 23.123732251521297, 20.155038759689923, 23.890784982935152, 30.79922027290448, 19.94750656167979, 20.330368487928844, 24.489795918367346, 24.181360201511335, 20.30075187969925, 23.326133909287257, 26.406926406926406, 30.36649214659686, 20.13129102844639, 23.52941176470588, 27.387387387387385]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [18][  22/7542]\tLoss 7.60e-01 (6.71e-01)\tAccuracy@Bitmap 93.69 (93.76)\tPrecision@Bitmap 15.79 (22.46)\tRecall@Bitmap 25.00 (32.98)\taccuracy: 93.75816415726254, precision: 22.464505499830402, recall: 32.9823562891292, F_score: 26.725852477445017\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017]\n",
      "epoch_loss=21.440869921849945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.25170068027211, 30.454545454545457, 36.43122676579926, 0.0, 9.1324200913242, 0.0, 27.44360902255639, 0.0, 3.571428571428571, 23.050847457627118, 6.862745098039216, 0.0, 21.58590308370044, 17.431192660550458, 32.402234636871505, 22.448979591836736, 15.261044176706829, 24.354243542435423, 3.571428571428571, 0.0, 7.142857142857142, 7.792207792207792, 15.384615384615385, 20.0, 0.0, 10.0, 12.941176470588237, 0.0, 15.294117647058824, 8.187134502923977, 16.39344262295082, 9.6, 5.298013245033113, 4.081632653061225, 21.839080459770116, 5.649717514124294, 9.950248756218906, 2.2988505747126435, 17.599999999999998, 8.064516129032258, 6.8181818181818175, 14.666666666666666, 7.633587786259542, 8.358208955223882, 8.333333333333332, 11.594202898550725, 8.51063829787234, 4.301075268817205, 12.598425196850393, 16.867469879518072, 2.5806451612903225, 9.271523178807946, 5.9880239520958085]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [18][   8/7542]\tLoss 7.27e-01 (8.34e-01)\tAccuracy@Bitmap 92.13 (92.93)\tPrecision@Bitmap 11.54 (12.27)\tRecall@Bitmap 21.43 (16.93)\taccuracy: 92.9346012679346, precision: 12.270742358078603, recall: 16.927710843373493, F_score: 14.227848101265822\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822]\n",
      "epoch_loss=26.45666944412958\n",
      "micro_fsoce=[0, 37.524177949709866, 37.169650468883205, 38.648860958366065, 0.0, 18.672199170124482, 0.0, 49.100071994240466, 0.0, 13.571428571428571, 37.258347978910365, 22.542595019659238, 4.129793510324483, 33.44594594594595, 33.67139959432049, 20.545073375262053, 32.78271918678526, 31.67220376522702, 28.434197886647457, 22.99651567944251, 9.248554913294797, 23.008849557522122, 16.9811320754717, 27.40814299900695, 25.324027916251246, 17.194570135746606, 19.940476190476193, 31.8407960199005, 0.0, 29.84014209591474, 20.634920634920633, 25.94458438287154, 24.369747899159663, 22.932330827067666, 22.0, 27.20897615708275, 18.688524590163937, 24.074074074074073, 9.523809523809524, 22.8, 21.135029354207436, 23.1433506044905, 30.418250950570343, 22.395833333333336, 22.02753441802253, 23.78223495702006, 24.358974358974358, 19.5, 23.580786026200872, 26.382978723404253, 29.31937172774869, 18.41541755888651, 23.52941176470588, 25.13274336283186]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [19][  22/7542]\tLoss 6.24e-01 (6.71e-01)\tAccuracy@Bitmap 94.61 (93.74)\tPrecision@Bitmap 23.40 (22.30)\tRecall@Bitmap 28.21 (32.81)\taccuracy: 93.73582014791243, precision: 22.30174081237911, recall: 32.81161070005692, F_score: 26.554583141409488\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488]\n",
      "epoch_loss=21.4385654107999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.240549828178693, 31.65137614678899, 37.86764705882353, 0.5012531328320802, 10.95890410958904, 0.0, 27.80952380952381, 0.0, 3.5502958579881656, 22.364217252396166, 8.695652173913043, 0.0, 20.434782608695652, 17.391304347826086, 33.06233062330624, 19.895287958115183, 15.139442231075698, 24.150943396226417, 5.357142857142857, 2.197802197802198, 6.986899563318777, 6.578947368421052, 14.83375959079284, 19.93355481727575, 0.0, 11.049723756906078, 15.028901734104046, 0.0, 12.941176470588237, 8.433734939759036, 15.957446808510639, 9.6, 4.3478260869565215, 3.8461538461538463, 22.75449101796407, 6.666666666666667, 9.70873786407767, 2.4390243902439024, 17.670682730923694, 9.090909090909092, 6.629834254143646, 14.76510067114094, 8.955223880597014, 7.647058823529412, 7.9470198675496695, 11.707317073170733, 7.665505226480835, 4.2105263157894735, 8.88888888888889, 14.634146341463413, 1.3333333333333335, 9.210526315789473, 4.624277456647398]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [19][   8/7542]\tLoss 7.31e-01 (8.35e-01)\tAccuracy@Bitmap 92.82 (92.90)\tPrecision@Bitmap 16.00 (12.26)\tRecall@Bitmap 28.57 (17.09)\taccuracy: 92.89636859081304, precision: 12.260481198674542, recall: 17.08835341365462, F_score: 14.277325727707407\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407]\n",
      "epoch_loss=26.490230724925087\n",
      "micro_fsoce=[0, 37.487922705314006, 37.362637362637365, 38.93249607535322, 1.6, 18.125, 0.0, 49.0294751976995, 0.0, 12.7208480565371, 36.869565217391305, 21.60737812911726, 3.003003003003003, 34.45945945945946, 32.47011952191235, 21.656050955414013, 34.01015228426396, 31.33841131664853, 28.5442435775452, 22.727272727272727, 11.494252873563218, 22.813688212927758, 17.51824817518248, 27.537688442211056, 26.08695652173913, 14.545454545454545, 19.7962154294032, 31.367628607277293, 0.0, 29.577464788732392, 20.933977455716587, 26.801517067003793, 24.63465553235908, 22.05029013539652, 20.2020202020202, 27.53824756606398, 18.76046901172529, 24.210526315789473, 8.55614973262032, 23.217922606924642, 22.39685658153242, 23.389830508474578, 29.615384615384617, 21.93211488250653, 21.553884711779446, 24.172661870503596, 23.45360824742268, 20.074349442379184, 25.494505494505493, 25.217391304347824, 29.809358752166375, 20.985010706638114, 28.57142857142857, 25.964912280701753]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [20][  22/7542]\tLoss 6.28e-01 (6.70e-01)\tAccuracy@Bitmap 94.11 (93.75)\tPrecision@Bitmap 22.41 (22.40)\tRecall@Bitmap 34.21 (32.95)\taccuracy: 93.74515061335534, precision: 22.39628662605164, recall: 32.95389869095048, F_score: 26.668201969025272\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272]\n",
      "epoch_loss=21.422742925458035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 31.292517006802722, 29.79683972911964, 38.02559414990859, 0.0, 7.30593607305936, 0.0, 27.692307692307693, 0.0, 2.312138728323699, 21.153846153846153, 8.955223880597014, 0.0, 21.030042918454935, 16.51376146788991, 33.60433604336043, 20.833333333333336, 16.46090534979424, 24.817518248175183, 5.263157894736842, 2.1505376344086025, 7.929515418502203, 9.937888198757763, 15.064935064935064, 19.661016949152543, 0.0, 8.465608465608465, 13.40782122905028, 0.0, 13.714285714285715, 9.195402298850574, 14.659685863874344, 9.67741935483871, 5.797101449275362, 4.0, 21.59090909090909, 4.395604395604396, 8.780487804878048, 2.3529411764705883, 19.08713692946058, 8.75912408759124, 9.03954802259887, 14.56953642384106, 4.545454545454546, 7.514450867052023, 9.722222222222223, 10.476190476190476, 8.664259927797833, 4.145077720207254, 9.448818897637794, 15.18987341772152, 1.4084507042253522, 10.526315789473683, 4.819277108433735]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [20][   8/7542]\tLoss 7.11e-01 (8.34e-01)\tAccuracy@Bitmap 92.82 (92.88)\tPrecision@Bitmap 16.00 (12.20)\tRecall@Bitmap 28.57 (17.07)\taccuracy: 92.87690468246024, precision: 12.200373187885747, recall: 17.06827309236948, F_score: 14.229513685444045\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045]\n",
      "epoch_loss=26.44468347231547\n",
      "micro_fsoce=[0, 36.77042801556421, 36.9620253164557, 38.52779953014879, 0.8016032064128256, 17.665615141955836, 0.0, 49.35251798561151, 0.0, 12.926391382405743, 36.809815950920246, 23.08724832214765, 2.380952380952381, 33.86960203217612, 32.46492985971944, 21.84873949579832, 33.54350567465322, 31.868131868131865, 29.00763358778626, 21.602787456445995, 8.045977011494253, 22.950819672131146, 18.75, 27.037773359840955, 25.72283150548355, 15.74074074074074, 21.282798833819243, 31.38231631382316, 0.0, 29.432624113475175, 20.8, 26.801517067003793, 23.30508474576271, 21.923076923076923, 22.564102564102566, 29.01849217638691, 20.563847429519072, 22.92490118577075, 8.791208791208792, 23.756345177664976, 22.700587084148726, 25.17241379310345, 30.18867924528302, 19.895287958115183, 20.506329113924053, 25.323741007194243, 23.237597911227155, 20.050761421319795, 21.49122807017544, 25.917926565874733, 29.757785467128027, 20.346320346320347, 35.294117647058826, 23.885918003565063]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [21][  22/7542]\tLoss 5.46e-01 (6.71e-01)\tAccuracy@Bitmap 94.44 (93.76)\tPrecision@Bitmap 30.99 (22.39)\tRecall@Bitmap 56.41 (32.78)\taccuracy: 93.75914631151969, precision: 22.393934975944017, recall: 32.783153101878206, F_score: 26.61045823347674\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674]\n",
      "epoch_loss=21.45914989457292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.152542372881356, 29.81651376146789, 36.80297397769517, 1.4925373134328357, 10.045662100456621, 0.0, 28.30188679245283, 0.0, 2.3255813953488373, 23.050847457627118, 8.61244019138756, 0.0, 21.888412017167383, 17.59259259259259, 31.232876712328768, 21.98952879581152, 15.767634854771783, 25.0, 3.508771929824561, 2.1621621621621623, 8.144796380090497, 9.876543209876543, 14.173228346456693, 20.394736842105264, 0.0, 12.222222222222221, 13.017751479289942, 0.0, 14.117647058823529, 9.411764705882353, 15.135135135135137, 10.0, 5.88235294117647, 3.9215686274509802, 22.35294117647059, 5.376344086021505, 10.1010101010101, 2.3529411764705883, 18.181818181818183, 7.874015748031496, 8.588957055214724, 14.56953642384106, 5.88235294117647, 7.492795389048991, 9.79020979020979, 11.594202898550725, 8.633093525179856, 4.232804232804233, 12.903225806451612, 15.686274509803921, 2.5806451612903225, 7.9470198675496695, 6.0606060606060606]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [21][   8/7542]\tLoss 7.11e-01 (8.34e-01)\tAccuracy@Bitmap 93.98 (92.94)\tPrecision@Bitmap 20.00 (12.40)\tRecall@Bitmap 28.57 (17.13)\taccuracy: 92.94363808252697, precision: 12.403664388541515, recall: 17.1285140562249, F_score: 14.388125158134436\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436]\n",
      "epoch_loss=26.4546533425649\n",
      "micro_fsoce=[0, 35.87270973963356, 38.33757421543681, 38.84103367267032, 1.2024048096192386, 18.988648090815275, 0.0, 49.7469269703543, 0.0, 11.449016100178891, 36.267605633802816, 23.05699481865285, 1.1976047904191618, 33.13609467455622, 33.36604514229637, 20.76271186440678, 34.05336721728081, 31.544359255202632, 28.81516587677725, 20.701754385964914, 7.0588235294117645, 22.25, 18.357487922705314, 27.14570858283433, 25.728643216080403, 16.363636363636363, 22.157434402332363, 31.155778894472363, 0.0, 30.526315789473685, 21.26984126984127, 26.666666666666668, 24.786324786324787, 23.339317773788153, 20.408163265306122, 28.328611898016998, 19.173553719008265, 24.06417112299465, 9.574468085106384, 22.974358974358974, 21.484375, 24.870466321243523, 28.78787878787879, 21.21212121212121, 20.330368487928844, 24.891461649782922, 25.0, 19.524405506883603, 21.551724137931032, 26.439232409381663, 29.071803852889666, 19.298245614035086, 28.57142857142857, 24.775583482944345]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [22][  22/7542]\tLoss 6.73e-01 (6.71e-01)\tAccuracy@Bitmap 93.01 (93.74)\tPrecision@Bitmap 20.90 (22.34)\tRecall@Bitmap 31.82 (32.83)\taccuracy: 93.74269522771247, precision: 22.34001355407106, recall: 32.83295389869095, F_score: 26.58869620326093\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093]\n",
      "epoch_loss=21.428950528472157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 28.859060402684566, 29.42528735632184, 37.13235294117647, 0.0, 9.049773755656108, 0.0, 28.35538752362949, 0.0, 4.651162790697675, 22.516556291390728, 9.569377990430622, 0.0, 21.69197396963124, 18.269230769230766, 31.491712707182316, 20.408163265306122, 16.39344262295082, 23.134328358208954, 5.263157894736842, 1.0752688172043012, 7.82608695652174, 11.39240506329114, 15.549597855227882, 19.607843137254903, 0.0, 8.83977900552486, 11.363636363636363, 0.0, 16.184971098265898, 10.344827586206897, 15.053763440860216, 10.256410256410255, 5.405405405405405, 4.25531914893617, 22.22222222222222, 5.714285714285714, 10.050251256281408, 0.0, 17.5, 6.4, 8.235294117647058, 15.483870967741936, 5.797101449275362, 6.547619047619048, 9.79020979020979, 9.523809523809524, 7.665505226480835, 5.376344086021505, 10.606060606060606, 16.560509554140125, 1.3605442176870748, 10.457516339869281, 4.819277108433735]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [22][   8/7542]\tLoss 7.17e-01 (8.34e-01)\tAccuracy@Bitmap 92.59 (92.92)\tPrecision@Bitmap 15.38 (12.23)\tRecall@Bitmap 28.57 (16.95)\taccuracy: 92.91583249916583, precision: 12.23365705174663, recall: 16.947791164658636, F_score: 14.209950332519572\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572]\n",
      "epoch_loss=26.45408350513095\n",
      "micro_fsoce=[0, 36.168132942326494, 37.12574850299401, 37.93911007025761, 0.8032128514056224, 18.314255983350677, 0.0, 49.24187725631769, 0.0, 11.785714285714285, 37.58741258741259, 22.28187919463087, 1.8072289156626504, 34.68013468013468, 34.097706879361915, 21.428571428571427, 32.82442748091603, 31.135135135135133, 28.844317096466092, 22.338568935427574, 10.404624277456648, 24.25, 16.786570743405278, 26.89243027888446, 26.973026973026975, 14.814814814814813, 21.73274596182085, 31.880448318804483, 0.0, 32.098765432098766, 21.052631578947366, 27.490542244640604, 26.124197002141326, 22.22222222222222, 22.0, 28.251748251748253, 18.855218855218855, 24.40318302387268, 8.51063829787234, 23.3502538071066, 22.612085769980506, 23.03839732888147, 31.61904761904762, 20.051413881748072, 20.998719590268884, 24.892703862660944, 24.26564495530013, 19.475655430711612, 24.034334763948497, 25.48596112311015, 28.670120898100173, 20.085470085470085, 34.285714285714285, 25.435540069686414]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [23][  22/7542]\tLoss 5.95e-01 (6.71e-01)\tAccuracy@Bitmap 95.03 (93.75)\tPrecision@Bitmap 25.58 (22.48)\tRecall@Bitmap 28.95 (33.08)\taccuracy: 93.75374446310538, precision: 22.482231784557367, recall: 33.0819578827547, F_score: 26.771064221768043\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043]\n",
      "epoch_loss=21.435286436040524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 31.506849315068493, 30.136986301369863, 37.20073664825046, 0.5012531328320802, 9.30232558139535, 0.0, 27.977315689981097, 0.0, 1.1904761904761905, 22.22222222222222, 7.729468599033816, 0.0, 21.83406113537118, 16.822429906542055, 32.15258855585831, 20.0, 16.39344262295082, 23.44322344322344, 1.7241379310344827, 2.197802197802198, 7.048458149779736, 8.860759493670885, 15.303430079155673, 19.863013698630137, 0.0, 8.88888888888889, 14.457831325301203, 0.0, 15.476190476190476, 10.05586592178771, 15.053763440860216, 9.523809523809524, 6.015037593984962, 3.9215686274509802, 21.839080459770116, 7.446808510638298, 10.0, 0.0, 18.25726141078838, 8.264462809917356, 7.865168539325842, 14.965986394557824, 7.518796992481203, 7.647058823529412, 8.333333333333332, 10.784313725490197, 7.638888888888889, 5.1020408163265305, 9.090909090909092, 15.18987341772152, 2.5806451612903225, 9.271523178807946, 4.848484848484849]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [23][   8/7542]\tLoss 7.21e-01 (8.33e-01)\tAccuracy@Bitmap 93.06 (92.93)\tPrecision@Bitmap 16.67 (12.26)\tRecall@Bitmap 28.57 (16.95)\taccuracy: 92.92556445334223, precision: 12.258533042846768, recall: 16.947791164658636, F_score: 14.226717235566793\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793]\n",
      "epoch_loss=26.431802386329288\n",
      "micro_fsoce=[0, 36.59244917715392, 38.58466722830666, 39.08589440504334, 0.8032128514056224, 18.44559585492228, 0.0, 49.749103942652326, 0.0, 12.237762237762238, 36.31578947368421, 23.342175066312997, 2.4024024024024024, 32.91351805205709, 33.663366336633665, 22.641509433962266, 32.82828282828283, 31.33841131664853, 29.44550669216061, 21.98581560283688, 10.112359550561797, 22.44640605296343, 18.138424821002385, 28.343313373253494, 26.49140546006067, 14.814814814814813, 21.282798833819243, 30.750605326876514, 0.0, 30.36649214659686, 20.952380952380953, 26.700898587933246, 26.08695652173913, 23.81852551984877, 23.0, 27.566807313642755, 18.333333333333332, 23.96804260985353, 6.486486486486487, 23.10030395136778, 22.92490118577075, 23.931623931623932, 30.418250950570343, 21.1340206185567, 21.27659574468085, 24.113475177304963, 23.969072164948454, 20.31823745410037, 23.214285714285715, 25.321888412017167, 29.876977152899826, 21.397379912663755, 29.411764705882355, 26.223776223776223]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [24][  22/7542]\tLoss 7.47e-01 (6.70e-01)\tAccuracy@Bitmap 94.02 (93.75)\tPrecision@Bitmap 22.22 (22.49)\tRecall@Bitmap 21.74 (33.17)\taccuracy: 93.74883369181963, precision: 22.492401215805472, recall: 33.167330677290835, F_score: 26.806198430267656\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656]\n",
      "epoch_loss=21.41724717263448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.629629629629626, 29.6127562642369, 35.44776119402985, 0.0, 9.90990990990991, 0.0, 27.06766917293233, 0.0, 2.3529411764705883, 23.1023102310231, 7.8431372549019605, 0.0, 21.53846153846154, 17.142857142857142, 32.417582417582416, 19.791666666666664, 15.637860082304528, 22.0532319391635, 3.389830508474576, 2.1739130434782608, 6.986899563318777, 8.974358974358974, 16.145833333333336, 19.205298013245034, 0.0, 9.94475138121547, 12.359550561797752, 0.0, 15.568862275449103, 8.0, 15.957446808510639, 9.67741935483871, 5.714285714285714, 4.166666666666666, 21.965317919075144, 7.82122905027933, 9.803921568627452, 2.2988505747126435, 17.813765182186234, 8.333333333333332, 6.70391061452514, 14.56953642384106, 5.755395683453238, 8.259587020648967, 8.51063829787234, 11.76470588235294, 8.480565371024735, 5.0761421319796955, 11.29032258064516, 17.94871794871795, 2.7210884353741496, 10.526315789473683, 4.651162790697675]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [24][   8/7542]\tLoss 7.14e-01 (8.34e-01)\tAccuracy@Bitmap 93.98 (92.90)\tPrecision@Bitmap 20.00 (12.15)\tRecall@Bitmap 28.57 (16.85)\taccuracy: 92.90471026582138, precision: 12.150615496017378, recall: 16.84738955823293, F_score: 14.118636937315946\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946]\n",
      "epoch_loss=26.45012300922757\n",
      "micro_fsoce=[0, 35.95724003887269, 36.71742808798646, 37.96875, 0.8032128514056224, 17.82383419689119, 0.0, 49.81949458483754, 0.0, 12.522361359570661, 35.180299032541775, 22.63157894736842, 1.1976047904191618, 34.179357021996616, 33.73253493013972, 21.205821205821206, 33.75314861460957, 31.24312431243124, 28.219696969696972, 21.12676056338028, 10.714285714285714, 24.721878862793574, 19.32367149758454, 26.77322677322677, 26.826826826826828, 17.194570135746606, 21.776504297994272, 31.3527180783818, 0.0, 30.19538188277087, 22.5, 25.782227784730914, 24.947145877378436, 22.676579925650557, 21.428571428571427, 28.208744710860366, 19.805194805194805, 23.667100130039014, 10.75268817204301, 23.387096774193548, 21.653543307086615, 23.46938775510204, 29.056603773584904, 20.259740259740262, 21.364221364221365, 23.9067055393586, 23.3502538071066, 18.858560794044664, 23.126338329764454, 23.861171366594363, 30.76923076923077, 20.21978021978022, 27.027027027027028, 24.295774647887324]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [25][  22/7542]\tLoss 7.02e-01 (6.71e-01)\tAccuracy@Bitmap 92.76 (93.73)\tPrecision@Bitmap 18.57 (22.26)\tRecall@Bitmap 30.95 (32.80)\taccuracy: 93.7269807595981, precision: 22.260307038717777, recall: 32.804496300512234, F_score: 26.52286453839517\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517]\n",
      "epoch_loss=21.43708350900876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.931972789115648, 29.68036529680365, 36.39705882352941, 0.0, 11.607142857142858, 0.0, 27.86259541984733, 0.0, 3.571428571428571, 23.026315789473685, 8.0, 0.0, 21.397379912663755, 17.194570135746606, 31.868131868131865, 21.649484536082475, 18.181818181818183, 26.119402985074625, 4.878048780487805, 2.1739130434782608, 9.1324200913242, 8.641975308641975, 15.424164524421593, 19.463087248322147, 0.0, 8.743169398907105, 13.40782122905028, 0.0, 14.285714285714285, 8.045977011494253, 15.135135135135137, 10.0, 5.970149253731343, 4.166666666666666, 23.121387283236995, 6.741573033707865, 9.900990099009901, 2.380952380952381, 18.930041152263374, 9.375, 5.813953488372093, 15.172413793103448, 6.2015503875969, 7.18562874251497, 10.218978102189782, 11.76470588235294, 8.60215053763441, 5.128205128205128, 9.523809523809524, 15.286624203821656, 2.7027027027027026, 10.457516339869281, 4.878048780487805]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [25][   8/7542]\tLoss 7.19e-01 (8.34e-01)\tAccuracy@Bitmap 93.29 (92.95)\tPrecision@Bitmap 17.39 (12.45)\tRecall@Bitmap 28.57 (17.17)\taccuracy: 92.9540651762874, precision: 12.452665307311388, recall: 17.16867469879518, F_score: 14.435252405875401\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401]\n",
      "epoch_loss=26.452503550620307\n",
      "micro_fsoce=[0, 37.073170731707314, 36.271186440677965, 38.01261829652997, 1.2, 17.857142857142858, 0.0, 50.07153075822603, 0.0, 13.309982486865149, 37.38977072310406, 23.00653594771242, 1.812688821752266, 35.04633529907329, 32.90386521308226, 21.38364779874214, 32.70440251572327, 30.93681917211329, 28.57142857142857, 21.516754850088184, 8.13953488372093, 23.72448979591837, 17.307692307692307, 28.090999010880317, 26.25863770977295, 14.150943396226415, 21.313868613138688, 33.04130162703379, 0.0, 31.17338003502627, 21.187800963081862, 26.683608640406607, 25.887265135699373, 20.463320463320464, 20.408163265306122, 28.04532577903683, 19.633943427620633, 24.074074074074073, 8.743169398907105, 23.588709677419356, 22.770398481973434, 22.93423271500843, 30.919765166340508, 21.298701298701296, 20.865139949109416, 25.43352601156069, 23.455233291298867, 19.18819188191882, 22.698072805139187, 23.35456475583864, 30.0, 19.957537154989385, 33.33333333333333, 24.113475177304963]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [26][  22/7542]\tLoss 6.95e-01 (6.71e-01)\tAccuracy@Bitmap 93.60 (93.74)\tPrecision@Bitmap 29.58 (22.38)\tRecall@Bitmap 44.68 (32.99)\taccuracy: 93.73925768781245, precision: 22.38366480015447, recall: 32.989470688673876, F_score: 26.670884619809044\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044]\n",
      "epoch_loss=21.428953963316093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.757785467128027, 29.157175398633257, 37.33826247689464, 0.5012531328320802, 9.25925925925926, 0.0, 28.24858757062147, 0.0, 2.2988505747126435, 22.516556291390728, 6.091370558375635, 0.0, 22.17391304347826, 16.9811320754717, 31.868131868131865, 19.689119170984455, 15.510204081632653, 24.334600760456272, 3.5398230088495577, 2.1621621621621623, 7.239819004524888, 9.032258064516128, 15.748031496062993, 20.066889632107024, 0.0, 10.695187165775401, 12.571428571428573, 0.0, 14.942528735632186, 9.580838323353294, 13.829787234042554, 9.6, 4.166666666666666, 4.25531914893617, 21.468926553672315, 6.8181818181818175, 10.204081632653061, 0.0, 18.930041152263374, 9.375, 8.235294117647058, 14.76510067114094, 5.839416058394161, 7.580174927113703, 8.823529411764707, 9.75609756097561, 7.829181494661921, 5.0761421319796955, 10.852713178294573, 15.18987341772152, 3.9735099337748347, 10.457516339869281, 4.878048780487805]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [26][   8/7542]\tLoss 7.16e-01 (8.34e-01)\tAccuracy@Bitmap 92.82 (92.93)\tPrecision@Bitmap 13.04 (12.25)\tRecall@Bitmap 21.43 (16.91)\taccuracy: 92.93112557001446, precision: 12.25083660701295, recall: 16.907630522088354, F_score: 14.207373660676623\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623]\n",
      "epoch_loss=26.461501666477748\n",
      "micro_fsoce=[0, 36.15384615384615, 37.510656436487636, 38.170347003154575, 0.8032128514056224, 18.181818181818183, 0.0, 49.27745664739884, 0.0, 11.012433392539965, 36.587510993843445, 23.45191040843215, 2.967359050445104, 33.527939949958295, 32.83283283283283, 21.231422505307858, 31.869510664993726, 31.120783460282915, 29.565217391304348, 21.403508771929825, 8.187134502923977, 24.102564102564102, 18.705035971223023, 27.82258064516129, 26.76056338028169, 16.74418604651163, 20.414201183431953, 31.618569636135508, 0.0, 28.622540250447226, 20.12779552715655, 25.91194968553459, 25.53191489361702, 21.550094517958414, 20.48780487804878, 27.52808988764045, 21.192052980132452, 23.49869451697128, 8.60215053763441, 23.115577889447238, 21.53846153846154, 23.12925170068027, 29.770992366412212, 20.0, 21.518987341772153, 24.147727272727273, 24.96815286624204, 19.622641509433965, 19.51219512195122, 24.947145877378436, 30.19538188277087, 19.78494623655914, 30.303030303030305, 26.36203866432337]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [27][  22/7542]\tLoss 6.83e-01 (6.70e-01)\tAccuracy@Bitmap 93.43 (93.74)\tPrecision@Bitmap 23.08 (22.26)\tRecall@Bitmap 34.88 (32.70)\taccuracy: 93.73557460934815, precision: 22.260423224056947, recall: 32.70489470688674, F_score: 26.49033336214596\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596]\n",
      "epoch_loss=21.412863592475148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.931972789115648, 29.47845804988662, 38.059701492537314, 0.5012531328320802, 10.0, 0.0, 29.213483146067414, 0.0, 2.3952095808383236, 22.972972972972975, 7.766990291262135, 0.0, 20.77922077922078, 17.061611374407583, 33.14917127071823, 18.461538461538463, 15.936254980079681, 24.53531598513011, 5.128205128205128, 1.0869565217391304, 8.071748878923767, 8.484848484848486, 15.34526854219949, 18.91891891891892, 0.0, 9.03954802259887, 12.571428571428573, 0.0, 14.457831325301203, 9.142857142857142, 15.873015873015872, 9.67741935483871, 4.477611940298507, 4.081632653061225, 22.22222222222222, 4.597701149425287, 10.152284263959391, 2.4390243902439024, 17.741935483870968, 6.666666666666667, 7.017543859649122, 14.76510067114094, 4.615384615384616, 7.784431137724551, 6.896551724137931, 10.42654028436019, 7.665505226480835, 4.2105263157894735, 12.307692307692308, 15.09433962264151, 2.7777777777777777, 11.688311688311687, 4.651162790697675]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [27][   8/7542]\tLoss 7.24e-01 (8.35e-01)\tAccuracy@Bitmap 92.82 (92.92)\tPrecision@Bitmap 16.00 (12.24)\tRecall@Bitmap 28.57 (16.93)\taccuracy: 92.92417417417418, precision: 12.24400871459695, recall: 16.927710843373493, F_score: 14.20986093552465\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465]\n",
      "epoch_loss=26.48539960952032\n",
      "micro_fsoce=[0, 35.95724003887269, 38.912489379779096, 39.12704598597038, 0.8032128514056224, 17.573221757322173, 0.0, 48.87599709934735, 0.0, 12.4777183600713, 35.75221238938053, 22.92490118577075, 2.9850746268656714, 34.66440101954121, 32.9064039408867, 21.987315010570825, 32.540675844806, 31.69164882226981, 29.00473933649289, 21.164021164021165, 9.467455621301776, 23.214285714285715, 16.786570743405278, 27.391742195367573, 26.719840478564304, 13.397129186602871, 21.83406113537118, 32.5, 0.0, 29.181494661921707, 22.29199372056515, 27.250000000000004, 25.311203319502074, 21.722846441947567, 20.2020202020202, 28.208744710860366, 18.241042345276874, 25.132275132275133, 8.64864864864865, 22.686567164179106, 22.22222222222222, 22.33502538071066, 28.846153846153843, 21.108179419525065, 21.065989847715734, 23.919308357348704, 24.111675126903553, 19.899244332493705, 23.24561403508772, 24.568965517241377, 30.19538188277087, 21.50537634408602, 31.25, 24.682395644283122]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [28][  22/7542]\tLoss 6.44e-01 (6.71e-01)\tAccuracy@Bitmap 93.86 (93.74)\tPrecision@Bitmap 22.22 (22.37)\tRecall@Bitmap 36.84 (32.90)\taccuracy: 93.74367738196962, precision: 22.371094127890103, recall: 32.904097894137735, F_score: 26.634033976389286\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286]\n",
      "epoch_loss=21.433920805232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.830508474576273, 30.59360730593607, 35.82089552238806, 0.0, 9.1324200913242, 0.0, 27.2552783109405, 0.0, 1.1627906976744187, 22.149837133550488, 8.737864077669903, 0.0, 21.27659574468085, 18.51851851851852, 32.967032967032964, 19.587628865979383, 15.702479338842975, 24.354243542435423, 5.263157894736842, 1.1235955056179776, 7.82608695652174, 5.095541401273886, 14.507772020725387, 18.729096989966553, 0.0, 10.16949152542373, 13.872832369942195, 0.0, 14.285714285714285, 9.411764705882353, 14.814814814814813, 9.6, 5.633802816901409, 3.9215686274509802, 21.59090909090909, 6.486486486486487, 10.0, 2.2988505747126435, 18.106995884773664, 8.130081300813007, 9.580838323353294, 14.473684210526317, 5.673758865248227, 8.115942028985506, 9.859154929577464, 9.615384615384617, 8.421052631578947, 4.18848167539267, 11.428571428571429, 15.09433962264151, 1.36986301369863, 9.210526315789473, 4.878048780487805]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [28][   8/7542]\tLoss 7.11e-01 (8.34e-01)\tAccuracy@Bitmap 93.29 (92.89)\tPrecision@Bitmap 17.39 (12.09)\tRecall@Bitmap 28.57 (16.81)\taccuracy: 92.88872205538871, precision: 12.088388214904679, recall: 16.80722891566265, F_score: 14.0625\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625]\n",
      "epoch_loss=26.463015187354316\n",
      "micro_fsoce=[0, 35.70731707317073, 37.34015345268542, 38.65939204988308, 0.8032128514056224, 17.31784582893347, 0.0, 49.63609898107715, 0.0, 10.338680926916222, 36.58536585365854, 22.25130890052356, 1.812688821752266, 32.82571912013537, 33.13492063492063, 21.610169491525426, 34.08521303258145, 31.683168316831683, 27.87193973634652, 21.52777777777778, 5.9880239520958085, 23.273657289002557, 19.95249406175772, 27.200000000000003, 25.992063492063494, 12.037037037037036, 21.574344023323615, 31.07769423558897, 0.0, 30.685920577617328, 22.366288492706644, 25.879396984924625, 26.41509433962264, 21.521335807050093, 20.304568527918782, 27.85515320334262, 21.01806239737274, 24.804177545691903, 6.521739130434782, 22.983870967741936, 20.930232558139537, 23.011844331641285, 29.37853107344633, 20.618556701030926, 20.565552699228792, 24.709302325581394, 23.308270676691727, 21.07904642409034, 22.566371681415927, 24.52431289640592, 29.655172413793103, 18.72340425531915, 30.303030303030305, 24.686940966010734]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [29][  22/7542]\tLoss 7.75e-01 (6.71e-01)\tAccuracy@Bitmap 93.60 (93.72)\tPrecision@Bitmap 29.69 (22.20)\tRecall@Bitmap 38.00 (32.67)\taccuracy: 93.72403429682666, precision: 22.19644238205723, recall: 32.669322709163346, F_score: 26.433341008519456\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456]\n",
      "epoch_loss=21.43547240455272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 28.474576271186443, 31.53153153153153, 36.36363636363637, 0.0, 10.85972850678733, 0.0, 27.586206896551722, 0.0, 2.2988505747126435, 21.052631578947366, 8.080808080808081, 0.0, 21.304347826086957, 16.9811320754717, 31.693989071038253, 20.2020202020202, 16.59751037344398, 23.970037453183522, 6.666666666666667, 1.1049723756906076, 7.929515418502203, 9.210526315789473, 15.466666666666667, 20.33898305084746, 0.0, 12.698412698412698, 14.3646408839779, 0.0, 14.035087719298245, 8.641975308641975, 15.957446808510639, 8.130081300813007, 5.839416058394161, 4.0, 20.994475138121548, 6.779661016949152, 10.050251256281408, 2.4096385542168677, 17.670682730923694, 8.264462809917356, 6.666666666666667, 15.277777777777779, 5.839416058394161, 7.471264367816093, 11.267605633802818, 11.76470588235294, 8.421052631578947, 5.208333333333334, 12.121212121212121, 16.049382716049383, 1.2987012987012987, 10.457516339869281, 5.952380952380952]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [29][   8/7542]\tLoss 7.27e-01 (8.34e-01)\tAccuracy@Bitmap 93.29 (92.92)\tPrecision@Bitmap 14.29 (12.31)\tRecall@Bitmap 21.43 (17.09)\taccuracy: 92.91652763874986, precision: 12.311921296296296, recall: 17.08835341365462, F_score: 14.312142616885302\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302]\n",
      "epoch_loss=26.45795374257224\n",
      "micro_fsoce=[0, 36.27546071774976, 36.77966101694915, 38.93666927286943, 0.4024144869215292, 19.206680584551147, 0.0, 49.421965317919074, 0.0, 10.638297872340425, 36.202307009760425, 22.280471821756226, 1.8018018018018018, 34.038950042337, 33.69458128078818, 21.413276231263385, 33.460076045627375, 31.783783783783782, 29.254302103250478, 19.642857142857142, 10.112359550561797, 22.72159800249688, 17.1990171990172, 27.85571142284569, 26.53061224489796, 17.117117117117118, 21.408450704225352, 31.4070351758794, 0.0, 29.525483304042176, 20.833333333333336, 26.448362720403022, 25.311203319502074, 22.181146025878004, 21.0, 28.085106382978726, 19.205298013245034, 23.809523809523807, 11.76470588235294, 23.397761953204476, 23.25581395348837, 22.75042444821732, 29.44550669216061, 21.93877551020408, 20.256410256410255, 23.51233671988389, 23.85786802030457, 19.164619164619165, 22.832980972515855, 26.01279317697228, 29.948364888123923, 21.428571428571427, 24.242424242424242, 25.749559082892414]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [30][  22/7542]\tLoss 7.20e-01 (6.70e-01)\tAccuracy@Bitmap 93.35 (93.73)\tPrecision@Bitmap 13.79 (22.30)\tRecall@Bitmap 21.62 (32.88)\taccuracy: 93.72992722236955, precision: 22.299971045265902, recall: 32.875640295959016, F_score: 26.57427109091955\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955]\n",
      "epoch_loss=21.414740086612056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.53020134228188, 30.979498861047837, 37.243947858473, 0.5012531328320802, 9.865470852017937, 0.0, 28.083491461100568, 0.0, 1.2269938650306749, 21.639344262295083, 9.75609756097561, 0.0, 20.600858369098713, 17.35159817351598, 31.805929919137466, 19.900497512437813, 17.46031746031746, 24.06015037593985, 4.838709677419355, 3.2085561497326207, 7.207207207207207, 7.547169811320755, 14.987080103359174, 19.594594594594593, 0.0, 10.869565217391305, 13.714285714285715, 0.0, 17.341040462427745, 8.383233532934131, 14.893617021276595, 11.570247933884298, 4.3478260869565215, 4.0, 21.59090909090909, 6.8181818181818175, 10.784313725490197, 0.0, 18.326693227091635, 7.8125, 7.865168539325842, 13.422818791946309, 7.352941176470589, 6.547619047619048, 9.523809523809524, 12.206572769953052, 8.362369337979095, 5.05050505050505, 9.6, 16.666666666666664, 3.896103896103896, 12.903225806451612, 4.9079754601226995]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [30][   8/7542]\tLoss 7.09e-01 (8.34e-01)\tAccuracy@Bitmap 93.52 (92.89)\tPrecision@Bitmap 18.18 (12.32)\tRecall@Bitmap 28.57 (17.25)\taccuracy: 92.8859414970526, precision: 12.320711417096959, recall: 17.248995983935743, F_score: 14.374163319946454\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454]\n",
      "epoch_loss=26.452462951342266\n",
      "micro_fsoce=[0, 36.22200584225901, 37.351443123938886, 38.34762275915822, 0.8016032064128256, 17.954070981210858, 0.0, 49.17325664989217, 0.0, 14.362657091561939, 37.719298245614034, 23.576158940397352, 3.003003003003003, 33.41902313624679, 33.87096774193548, 21.84873949579832, 33.9622641509434, 30.985915492957744, 29.750479846449135, 22.68041237113402, 7.317073170731707, 23.55889724310777, 16.587677725118482, 26.479438314944836, 25.97402597402597, 15.384615384615385, 20.444444444444446, 32.41206030150754, 0.0, 30.270270270270274, 21.904761904761905, 27.054361567635905, 26.34989200863931, 22.641509433962266, 18.461538461538463, 27.10413694721826, 20.13201320132013, 22.98546895640687, 6.382978723404255, 21.951219512195124, 22.00392927308448, 22.596964586846543, 28.185328185328185, 20.65491183879093, 21.065989847715734, 25.03556187766714, 24.583866837387962, 19.607843137254903, 21.982758620689655, 24.086021505376344, 28.87323943661972, 18.614718614718615, 24.242424242424242, 24.0]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [31][  22/7542]\tLoss 6.98e-01 (6.71e-01)\tAccuracy@Bitmap 93.77 (93.74)\tPrecision@Bitmap 22.73 (22.30)\tRecall@Bitmap 39.47 (32.74)\taccuracy: 93.74073091919817, precision: 22.296511627906977, recall: 32.740466704610135, F_score: 26.527553608485128\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128]\n",
      "epoch_loss=21.432271403276314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.405405405405407, 30.454545454545457, 37.47680890538033, 0.0, 10.045662100456621, 0.0, 27.80952380952381, 0.0, 3.5294117647058822, 20.666666666666668, 7.6923076923076925, 0.0, 20.915032679738562, 18.34862385321101, 32.78688524590164, 18.848167539267017, 18.106995884773664, 25.925925925925924, 5.263157894736842, 2.1621621621621623, 9.00900900900901, 11.25, 15.425531914893616, 20.13422818791946, 0.0, 10.05586592178771, 12.941176470588237, 0.0, 14.285714285714285, 7.909604519774012, 16.93121693121693, 9.6, 5.797101449275362, 4.081632653061225, 21.839080459770116, 5.58659217877095, 9.75609756097561, 2.3529411764705883, 16.40625, 8.19672131147541, 8.187134502923977, 14.56953642384106, 6.0606060606060606, 7.761194029850746, 10.81081081081081, 12.560386473429952, 7.746478873239436, 5.0761421319796955, 11.11111111111111, 15.950920245398773, 1.3513513513513513, 6.7114093959731544, 4.819277108433735]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [31][   8/7542]\tLoss 7.07e-01 (8.34e-01)\tAccuracy@Bitmap 93.06 (92.93)\tPrecision@Bitmap 16.67 (12.38)\tRecall@Bitmap 28.57 (17.15)\taccuracy: 92.92904015126237, precision: 12.376811594202898, recall: 17.14859437751004, F_score: 14.377104377104377\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377]\n",
      "epoch_loss=26.453817895480565\n",
      "micro_fsoce=[0, 36.310679611650485, 37.573715248525694, 38.161993769470406, 0.4024144869215292, 17.801047120418847, 0.0, 49.130434782608695, 0.0, 11.76470588235294, 36.971830985915496, 22.92490118577075, 2.4096385542168677, 33.617747440273035, 33.03482587064677, 20.042643923240938, 33.122629582806574, 32.21621621621622, 28.679962013295345, 21.837088388214905, 7.18562874251497, 23.232323232323232, 17.6039119804401, 26.666666666666668, 25.68250758341759, 15.09433962264151, 21.994134897360702, 31.960049937578027, 0.0, 31.282952548330407, 21.939586645468996, 27.261146496815286, 24.31865828092243, 23.032629558541267, 20.51282051282051, 28.36676217765043, 19.01639344262295, 24.074074074074073, 8.695652173913043, 22.874493927125506, 21.235521235521233, 21.830985915492956, 30.057803468208093, 21.428571428571427, 20.565552699228792, 24.669603524229075, 23.767383059418457, 19.753086419753085, 23.63238512035011, 27.631578947368425, 29.31937172774869, 19.522776572668114, 28.57142857142857, 24.817518248175183]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [32][  22/7542]\tLoss 6.97e-01 (6.71e-01)\tAccuracy@Bitmap 94.11 (93.76)\tPrecision@Bitmap 28.36 (22.36)\tRecall@Bitmap 46.34 (32.71)\taccuracy: 93.7571820030054, precision: 22.35837588135181, recall: 32.71200910643142, F_score: 26.56191328962191\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191]\n",
      "epoch_loss=21.42964334356583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.152542372881356, 30.112359550561795, 37.47680890538033, 0.0, 8.968609865470851, 0.0, 27.49529190207156, 0.0, 2.366863905325444, 21.548821548821547, 7.8431372549019605, 0.0, 21.413276231263385, 16.51376146788991, 32.87671232876712, 18.274111675126903, 14.87603305785124, 23.754789272030653, 3.4482758620689653, 1.098901098901099, 6.986899563318777, 8.9171974522293, 14.910025706940875, 19.17808219178082, 0.0, 13.186813186813188, 10.81081081081081, 0.0, 15.476190476190476, 8.235294117647058, 16.129032258064516, 8.130081300813007, 5.555555555555555, 4.25531914893617, 22.485207100591715, 5.555555555555555, 9.75609756097561, 2.380952380952381, 17.5, 8.264462809917356, 7.017543859649122, 14.965986394557824, 7.4074074074074066, 6.876790830945559, 9.395973154362416, 10.377358490566039, 7.801418439716312, 4.301075268817205, 11.200000000000001, 16.99346405228758, 4.137931034482759, 9.090909090909092, 5.031446540880504]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [32][   8/7542]\tLoss 7.40e-01 (8.35e-01)\tAccuracy@Bitmap 92.59 (92.91)\tPrecision@Bitmap 12.50 (12.11)\tRecall@Bitmap 21.43 (16.77)\taccuracy: 92.9054054054054, precision: 12.1084686774942, recall: 16.76706827309237, F_score: 14.061973728528123\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123]\n",
      "epoch_loss=26.46628013111296\n",
      "micro_fsoce=[0, 36.39883833494676, 36.930860033726816, 38.61308116627266, 0.4024144869215292, 17.782426778242677, 0.0, 49.056603773584904, 0.0, 11.785714285714285, 37.55458515283843, 23.26797385620915, 2.9940119760479043, 33.840947546531304, 34.03826787512588, 21.29436325678497, 33.50383631713555, 31.65938864628821, 28.51674641148325, 23.239436619718308, 9.523809523809524, 22.63222632226322, 15.421686746987953, 27.606752730883816, 26.34730538922156, 15.74074074074074, 21.511627906976745, 31.46067415730337, 0.0, 29.28571428571429, 20.569620253164558, 25.790139064475348, 24.842105263157897, 21.052631578947366, 19.801980198019802, 26.907073509015255, 18.70748299319728, 23.482849604221638, 8.64864864864865, 22.535211267605636, 21.153846153846153, 22.030981067125648, 29.78723404255319, 20.918367346938776, 20.506329113924053, 25.183016105417277, 25.12690355329949, 19.672131147540984, 22.707423580786028, 26.200873362445414, 30.155979202772965, 21.84873949579832, 27.77777777777778, 24.416517055655294]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [33][  22/7542]\tLoss 6.02e-01 (6.71e-01)\tAccuracy@Bitmap 93.35 (93.73)\tPrecision@Bitmap 25.33 (22.26)\tRecall@Bitmap 45.24 (32.72)\taccuracy: 93.73483799365529, precision: 22.262561719430728, recall: 32.71912350597609, F_score: 26.49651437460391\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391]\n",
      "epoch_loss=21.431417825868575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.054054054054053, 30.373831775700932, 36.39705882352941, 0.0, 13.157894736842104, 0.0, 28.298279158699806, 0.0, 4.651162790697675, 22.516556291390728, 8.695652173913043, 0.0, 20.985010706638114, 17.22488038277512, 32.78688524590164, 20.8955223880597, 17.28395061728395, 24.354243542435423, 5.263157894736842, 1.06951871657754, 8.071748878923767, 12.738853503184714, 15.18324607329843, 19.333333333333332, 0.0, 8.938547486033519, 13.714285714285715, 0.0, 14.723926380368098, 10.404624277456648, 16.129032258064516, 8.264462809917356, 5.839416058394161, 4.081632653061225, 22.099447513812155, 6.70391061452514, 9.950248756218906, 2.380952380952381, 17.142857142857142, 7.936507936507936, 8.092485549132949, 14.76510067114094, 5.755395683453238, 8.211143695014663, 9.395973154362416, 11.320754716981133, 8.571428571428571, 5.208333333333334, 9.6, 16.560509554140125, 1.3157894736842104, 9.271523178807946, 5.813953488372093]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [33][   8/7542]\tLoss 7.23e-01 (8.34e-01)\tAccuracy@Bitmap 92.82 (92.92)\tPrecision@Bitmap 16.00 (12.42)\tRecall@Bitmap 28.57 (17.25)\taccuracy: 92.92278389500612, precision: 12.415088885677122, recall: 17.248995983935743, F_score: 14.438188083032188\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188]\n",
      "epoch_loss=26.461902714910963\n",
      "micro_fsoce=[0, 35.499515033947624, 37.703513281919456, 38.057948316366485, 0.8032128514056224, 17.382198952879584, 0.0, 49.421965317919074, 0.0, 11.051693404634582, 36.93931398416886, 23.26797385620915, 2.4096385542168677, 33.587786259541986, 33.233830845771145, 21.38364779874214, 33.078880407124686, 31.03448275862069, 28.76190476190476, 21.602787456445995, 5.9880239520958085, 23.308270676691727, 17.114914425427873, 28.024193548387093, 26.13861386138614, 13.084112149532709, 22.255192878338278, 31.446540880503143, 0.0, 30.335097001763668, 21.138211382113823, 26.56641604010025, 25.75107296137339, 20.74074074074074, 23.762376237623762, 28.41068917018284, 20.0339558573854, 23.390275952693823, 8.791208791208792, 22.99084435401831, 21.79732313575526, 22.673434856175973, 30.038022813688215, 21.882951653944023, 20.278833967046893, 24.74820143884892, 24.090338770388957, 19.75, 23.399558498896248, 25.806451612903224, 29.965156794425084, 19.088937093275486, 31.25, 23.75886524822695]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [34][  22/7542]\tLoss 6.49e-01 (6.71e-01)\tAccuracy@Bitmap 94.70 (93.74)\tPrecision@Bitmap 27.08 (22.27)\tRecall@Bitmap 31.71 (32.70)\taccuracy: 93.73876661068388, precision: 22.27444519817812, recall: 32.70489470688674, F_score: 26.500259410849136\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136]\n",
      "epoch_loss=21.43111591167369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.931972789115648, 28.899082568807337, 37.243947858473, 0.5, 8.849557522123893, 0.0, 27.32447817836812, 0.0, 1.1976047904191618, 22.0, 10.050251256281408, 0.0, 21.53846153846154, 16.289592760180994, 30.684931506849317, 19.19191919191919, 16.736401673640167, 25.563909774436087, 1.7543859649122806, 1.092896174863388, 8.0, 7.5, 16.666666666666664, 18.79194630872483, 0.0, 7.650273224043716, 12.290502793296088, 0.0, 16.0, 10.344827586206897, 15.384615384615385, 8.064516129032258, 5.755395683453238, 4.0, 22.47191011235955, 8.0, 9.950248756218906, 2.380952380952381, 17.959183673469386, 7.936507936507936, 8.235294117647058, 13.793103448275861, 6.153846153846154, 6.8181818181818175, 7.792207792207792, 10.526315789473683, 8.60215053763441, 4.18848167539267, 11.29032258064516, 16.149068322981368, 1.2987012987012987, 9.271523178807946, 4.819277108433735]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [34][   8/7542]\tLoss 7.30e-01 (8.35e-01)\tAccuracy@Bitmap 93.98 (92.91)\tPrecision@Bitmap 16.67 (12.10)\tRecall@Bitmap 21.43 (16.75)\taccuracy: 92.90749082415749, precision: 12.102742707879843, recall: 16.74698795180723, F_score: 14.051048774323982\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982]\n",
      "epoch_loss=26.471922391936893\n",
      "micro_fsoce=[0, 36.82664054848188, 36.734693877551024, 38.47980997624703, 0.8032128514056224, 18.124341412012647, 0.0, 49.168474331164134, 0.0, 12.296564195298371, 37.050043898156275, 23.390275952693823, 2.4024024024024024, 33.83838383838384, 33.432245301681505, 21.656050955414013, 34.0, 31.77366702937976, 28.488931665062562, 21.785714285714285, 10.526315789473683, 22.900763358778626, 17.142857142857142, 27.878787878787882, 25.734549138804457, 13.82488479262673, 22.060957910014515, 32.61694058154235, 0.0, 30.526315789473685, 21.371610845295056, 26.14213197969543, 25.10460251046025, 21.013133208255162, 20.792079207920793, 26.853146853146853, 19.83739837398374, 23.969072164948454, 8.55614973262032, 23.694779116465863, 22.22222222222222, 23.728813559322035, 28.846153846153843, 21.994884910485936, 20.253164556962027, 25.17882689556509, 24.747474747474747, 19.402985074626866, 21.518987341772153, 25.69593147751606, 29.47368421052631, 17.48400852878465, 27.77777777777778, 25.0]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [35][  22/7542]\tLoss 6.40e-01 (6.71e-01)\tAccuracy@Bitmap 93.86 (93.74)\tPrecision@Bitmap 18.33 (22.32)\tRecall@Bitmap 31.43 (32.84)\taccuracy: 93.73729337929815, precision: 22.31892466879412, recall: 32.84006829823563, F_score: 26.57608382750878\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878]\n",
      "epoch_loss=21.435011231293114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 27.874564459930312, 29.953917050691242, 37.72893772893773, 0.5012531328320802, 9.95475113122172, 0.0, 28.46299810246679, 0.0, 3.571428571428571, 22.442244224422442, 8.530805687203792, 0.0, 22.269807280513916, 18.2648401826484, 31.062670299727518, 21.21212121212121, 17.21311475409836, 24.548736462093864, 3.508771929824561, 2.185792349726776, 7.339449541284404, 10.32258064516129, 14.933333333333335, 19.141914191419144, 0.0, 9.89010989010989, 12.290502793296088, 0.0, 16.0, 8.092485549132949, 16.0427807486631, 9.523809523809524, 4.444444444444445, 4.081632653061225, 21.839080459770116, 6.593406593406594, 10.1010101010101, 2.3529411764705883, 18.852459016393443, 7.633587786259542, 9.142857142857142, 14.864864864864865, 5.755395683453238, 7.580174927113703, 8.333333333333332, 10.576923076923077, 7.885304659498208, 4.166666666666666, 12.213740458015266, 16.883116883116884, 2.8169014084507045, 11.76470588235294, 6.25]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [35][   8/7542]\tLoss 7.19e-01 (8.35e-01)\tAccuracy@Bitmap 93.29 (92.93)\tPrecision@Bitmap 17.39 (12.41)\tRecall@Bitmap 28.57 (17.23)\taccuracy: 92.92556445334223, precision: 12.411398813829019, recall: 17.2289156626506, F_score: 14.428655511645506\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506]\n",
      "epoch_loss=26.492810345831373\n",
      "micro_fsoce=[0, 36.85741998060136, 36.7034834324554, 38.745098039215684, 0.8016032064128256, 17.875920084121976, 0.0, 49.31308749096168, 0.0, 10.412926391382406, 36.33187772925764, 22.66139657444005, 1.7964071856287425, 34.23728813559322, 33.366238894373154, 22.317596566523605, 32.29036295369212, 31.735889243876464, 29.142857142857142, 21.015761821366024, 8.0, 23.296158612143742, 18.138424821002385, 27.61998041136141, 25.922233300099702, 13.145539906103288, 21.145374449339208, 32.622333751568384, 0.0, 30.714285714285715, 21.753246753246753, 26.683291770573565, 25.94142259414226, 21.65137614678899, 18.65284974093264, 28.172942817294285, 19.661016949152543, 23.7467018469657, 9.574468085106384, 23.400000000000002, 21.96078431372549, 22.487223168654175, 28.680688336520078, 21.052631578947366, 21.052631578947366, 24.242424242424242, 23.876765083440308, 20.843672456575682, 22.17573221757322, 26.439232409381663, 30.44982698961938, 17.316017316017316, 30.303030303030305, 23.843416370106763]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [36][  22/7542]\tLoss 6.62e-01 (6.70e-01)\tAccuracy@Bitmap 93.60 (93.72)\tPrecision@Bitmap 21.54 (22.25)\tRecall@Bitmap 35.90 (32.87)\taccuracy: 93.71887798697664, precision: 22.24897664339032, recall: 32.86852589641434, F_score: 26.535711208753337\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337]\n",
      "epoch_loss=21.41959483290123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 27.796610169491526, 30.87557603686636, 36.83241252302026, 0.0, 8.968609865470851, 0.0, 26.84310018903592, 0.0, 2.3391812865497075, 23.411371237458194, 8.080808080808081, 0.0, 21.192052980132452, 18.81188118811881, 31.197771587743734, 18.181818181818183, 15.702479338842975, 22.878228782287824, 1.7391304347826086, 1.098901098901099, 8.21917808219178, 9.032258064516128, 15.66579634464752, 18.305084745762713, 0.0, 10.416666666666668, 13.333333333333334, 0.0, 14.545454545454545, 6.8181818181818175, 15.555555555555555, 9.836065573770492, 5.714285714285714, 4.166666666666666, 22.727272727272727, 4.3478260869565215, 9.950248756218906, 0.0, 18.62348178137652, 9.448818897637794, 7.317073170731707, 13.422818791946309, 5.88235294117647, 7.18562874251497, 9.395973154362416, 9.615384615384617, 8.362369337979095, 5.154639175257731, 9.16030534351145, 16.352201257861633, 4.026845637583892, 11.688311688311687, 4.819277108433735]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [36][   8/7542]\tLoss 7.17e-01 (8.34e-01)\tAccuracy@Bitmap 93.75 (92.91)\tPrecision@Bitmap 19.05 (12.06)\tRecall@Bitmap 28.57 (16.65)\taccuracy: 92.91235680124569, precision: 12.059935990689555, recall: 16.646586345381525, F_score: 13.986839885270793\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793]\n",
      "epoch_loss=26.464386321249464\n",
      "micro_fsoce=[0, 36.8780487804878, 37.27959697732997, 38.9937106918239, 0.4024144869215292, 18.16283924843424, 0.0, 50.25417574437182, 0.0, 11.151079136690647, 36.55536028119508, 23.513870541611624, 3.0120481927710845, 33.901192504258944, 34.523809523809526, 21.141649048625794, 32.689832689832684, 31.8232044198895, 28.68217054263566, 20.869565217391305, 6.024096385542169, 22.279129321382843, 15.49636803874092, 26.934673366834172, 24.674022066198596, 17.674418604651162, 22.73381294964029, 32.04968944099379, 0.0, 30.579964850615116, 20.588235294117645, 26.362484157160964, 25.213675213675213, 22.676579925650557, 20.51282051282051, 27.23404255319149, 19.56882255389718, 24.0620957309185, 8.51063829787234, 23.302938196555218, 23.09197651663405, 23.050847457627118, 28.952380952380953, 21.374045801526716, 20.930232558139537, 25.985401459854014, 24.010217113665387, 19.851116625310176, 24.190064794816415, 25.64102564102564, 30.017452006980804, 17.817371937639198, 28.57142857142857, 22.816399286987522]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [37][  22/7542]\tLoss 6.84e-01 (6.71e-01)\tAccuracy@Bitmap 95.20 (93.76)\tPrecision@Bitmap 38.60 (22.39)\tRecall@Bitmap 50.00 (32.73)\taccuracy: 93.76160169716256, precision: 22.386026370846103, recall: 32.73335230506545, F_score: 26.588459649224188\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188]\n",
      "epoch_loss=21.43376396268101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 28.865979381443296, 29.931972789115648, 35.99257884972171, 0.0, 10.85972850678733, 0.0, 27.42857142857143, 0.0, 2.380952380952381, 23.225806451612904, 8.737864077669903, 0.0, 21.304347826086957, 18.433179723502306, 32.240437158469945, 18.947368421052634, 17.254901960784313, 24.372759856630825, 1.5873015873015872, 2.1621621621621623, 8.144796380090497, 7.9470198675496695, 16.358839050131927, 18.543046357615893, 0.0, 10.285714285714285, 13.559322033898304, 0.0, 13.872832369942195, 8.284023668639055, 16.574585635359114, 9.67741935483871, 4.10958904109589, 3.8461538461538463, 22.093023255813954, 7.82122905027933, 10.152284263959391, 2.4390243902439024, 19.08713692946058, 9.836065573770492, 6.8181818181818175, 14.37908496732026, 7.142857142857142, 7.647058823529412, 9.271523178807946, 9.66183574879227, 9.454545454545455, 4.102564102564102, 9.836065573770492, 16.99346405228758, 2.5974025974025974, 8.0, 6.0606060606060606]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [37][   8/7542]\tLoss 7.25e-01 (8.33e-01)\tAccuracy@Bitmap 93.29 (92.91)\tPrecision@Bitmap 17.39 (12.25)\tRecall@Bitmap 28.57 (17.01)\taccuracy: 92.91096652207763, precision: 12.254050925925926, recall: 17.008032128514056, F_score: 14.244870501177262\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262]\n",
      "epoch_loss=26.426767252740405\n",
      "micro_fsoce=[0, 36.46944713870029, 37.07482993197279, 38.9630793401414, 1.2024048096192386, 16.455696202531644, 0.0, 49.20863309352518, 0.0, 10.163339382940109, 36.991150442477874, 23.298429319371728, 1.8072289156626504, 34.34856175972927, 32.5024925224327, 21.141649048625794, 32.7909887359199, 31.487513572204122, 28.40909090909091, 21.75438596491228, 10.465116279069768, 23.232323232323232, 17.073170731707318, 27.091633466135455, 26.078234704112337, 15.887850467289718, 21.43906020558003, 31.65829145728643, 0.0, 30.742049469964666, 20.90032154340836, 26.04298356510746, 24.47257383966245, 22.509225092250922, 18.65284974093264, 28.085106382978726, 20.29459901800327, 23.82198952879581, 6.521739130434782, 23.3739837398374, 20.809248554913296, 22.972972972972975, 29.558541266794624, 20.155038759689923, 20.454545454545457, 24.853801169590643, 24.22680412371134, 20.869565217391305, 23.376623376623375, 25.53191489361702, 29.31937172774869, 20.13129102844639, 29.411764705882355, 24.727272727272727]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [38][  22/7542]\tLoss 7.03e-01 (6.71e-01)\tAccuracy@Bitmap 93.77 (93.74)\tPrecision@Bitmap 29.23 (22.27)\tRecall@Bitmap 40.43 (32.67)\taccuracy: 93.74122199632674, precision: 22.271801338636145, recall: 32.669322709163346, F_score: 26.486704735536716\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716]\n",
      "epoch_loss=21.432755327325758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 28.668941979522184, 30.52391799544419, 38.37638376383764, 0.5025125628140703, 9.734513274336283, 0.0, 27.977315689981097, 0.0, 2.3529411764705883, 22.74247491638796, 7.035175879396985, 0.0, 21.397379912663755, 17.59259259259259, 32.78688524590164, 19.289340101522843, 17.355371900826448, 24.53531598513011, 3.508771929824561, 2.185792349726776, 7.142857142857142, 8.695652173913043, 16.103896103896105, 19.54397394136808, 0.0, 7.82122905027933, 13.48314606741573, 0.0, 14.37125748502994, 9.30232558139535, 14.207650273224044, 9.523809523809524, 5.9259259259259265, 3.8461538461538463, 21.11111111111111, 7.0588235294117645, 10.1010101010101, 2.380952380952381, 17.599999999999998, 7.6923076923076925, 9.195402298850574, 14.193548387096774, 7.352941176470589, 7.602339181286549, 9.271523178807946, 10.891089108910892, 8.391608391608392, 4.166666666666666, 10.526315789473683, 16.455696202531644, 1.282051282051282, 10.457516339869281, 4.733727810650888]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [38][   8/7542]\tLoss 7.31e-01 (8.34e-01)\tAccuracy@Bitmap 92.82 (92.90)\tPrecision@Bitmap 16.00 (12.30)\tRecall@Bitmap 28.57 (17.13)\taccuracy: 92.90262484706929, precision: 12.298154555940023, recall: 17.1285140562249, F_score: 14.316884860691506\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506]\n",
      "epoch_loss=26.457641788891383\n",
      "micro_fsoce=[0, 36.416747809152874, 37.351443123938886, 37.89308176100629, 0.8032128514056224, 17.263157894736842, 0.0, 49.26900584795322, 0.0, 11.992945326278658, 36.99825479930192, 23.025435073627847, 2.3880597014925375, 33.895446880269816, 33.46534653465347, 21.711899791231733, 32.44613434727503, 31.372549019607842, 28.6527514231499, 21.453287197231834, 9.03954802259887, 22.670025188916874, 16.867469879518072, 28.000000000000004, 25.728643216080403, 14.814814814814813, 21.15942028985507, 32.226322263222634, 0.0, 31.54121863799283, 20.846905537459286, 27.1356783919598, 24.947145877378436, 21.923076923076923, 21.53846153846154, 26.944444444444443, 18.93687707641196, 24.44733420026008, 8.55614973262032, 23.0, 21.176470588235293, 25.299145299145298, 30.623818525519848, 20.460358056265985, 20.278833967046893, 24.541607898448518, 23.62002567394095, 19.849246231155778, 22.657952069716774, 25.0, 29.166666666666668, 17.218543046357617, 29.411764705882355, 25.806451612903224]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [39][  22/7542]\tLoss 7.03e-01 (6.71e-01)\tAccuracy@Bitmap 93.52 (93.73)\tPrecision@Bitmap 21.67 (22.25)\tRecall@Bitmap 30.23 (32.72)\taccuracy: 93.73140045375527, precision: 22.24748452012384, recall: 32.71912350597609, F_score: 26.48583275742916\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916]\n",
      "epoch_loss=21.432539783291897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 32.323232323232325, 29.166666666666668, 37.707948243992604, 0.5012531328320802, 8.968609865470851, 0.0, 28.083491461100568, 0.0, 1.1560693641618496, 22.07792207792208, 5.825242718446602, 0.0, 22.36842105263158, 18.627450980392158, 31.40495867768595, 19.48717948717949, 16.260162601626014, 24.427480916030532, 5.3097345132743365, 1.092896174863388, 8.968609865470851, 7.6923076923076925, 15.425531914893616, 19.867549668874172, 0.0, 8.333333333333332, 12.429378531073446, 0.0, 14.457831325301203, 8.284023668639055, 16.483516483516482, 9.523809523809524, 5.797101449275362, 4.081632653061225, 20.54054054054054, 5.681818181818182, 9.803921568627452, 0.0, 17.88617886178862, 7.936507936507936, 10.112359550561797, 14.666666666666666, 5.797101449275362, 7.7994428969359335, 8.391608391608392, 10.628019323671497, 7.829181494661921, 4.060913705583756, 10.687022900763358, 15.66265060240964, 2.684563758389262, 9.090909090909092, 5.681818181818182]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [39][   8/7542]\tLoss 7.17e-01 (8.34e-01)\tAccuracy@Bitmap 93.75 (92.89)\tPrecision@Bitmap 19.05 (12.17)\tRecall@Bitmap 28.57 (16.97)\taccuracy: 92.8859414970526, precision: 12.168778801843319, recall: 16.967871485943775, F_score: 14.17309627641731\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731]\n",
      "epoch_loss=26.459255950791494\n",
      "micro_fsoce=[0, 36.39883833494676, 36.28620102214651, 38.522012578616355, 0.4024144869215292, 18.84057971014493, 0.0, 49.96400287976962, 0.0, 10.338680926916222, 36.809815950920246, 22.279792746113987, 1.7857142857142856, 33.69839932603201, 33.696729435084244, 22.083333333333332, 33.29161451814768, 32.16630196936542, 28.019323671497588, 23.367697594501717, 11.1731843575419, 22.807017543859647, 17.874396135265698, 27.19033232628399, 26.666666666666668, 12.903225806451612, 22.514619883040936, 31.75, 0.0, 30.633802816901408, 21.794871794871796, 26.13065326633166, 24.358974358974358, 22.509225092250922, 18.90547263681592, 28.040057224606578, 19.463087248322147, 23.591087811271297, 11.702127659574469, 23.06122448979592, 23.166023166023166, 21.80579216354344, 30.303030303030305, 20.418848167539267, 21.71717171717172, 23.953823953823957, 22.967741935483872, 19.548872180451127, 24.892703862660944, 25.321888412017167, 30.65953654188948, 18.594104308390023, 34.285714285714285, 24.548736462093864]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [40][  22/7542]\tLoss 6.99e-01 (6.71e-01)\tAccuracy@Bitmap 93.27 (93.75)\tPrecision@Bitmap 21.21 (22.36)\tRecall@Bitmap 33.33 (32.83)\taccuracy: 93.74736046043391, precision: 22.360579485440184, recall: 32.83295389869095, F_score: 26.603256953451503\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503]\n",
      "epoch_loss=21.43078653640666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.333333333333332, 29.953917050691242, 36.76470588235294, 0.5012531328320802, 10.045662100456621, 0.0, 28.030303030303028, 0.0, 2.366863905325444, 22.22222222222222, 8.695652173913043, 0.0, 21.397379912663755, 17.061611374407583, 32.240437158469945, 19.587628865979383, 16.194331983805668, 23.220973782771537, 3.508771929824561, 1.098901098901099, 7.2727272727272725, 10.126582278481013, 14.948453608247423, 19.17808219178082, 0.0, 11.363636363636363, 11.891891891891893, 0.0, 14.285714285714285, 9.696969696969697, 13.903743315508022, 9.67741935483871, 5.755395683453238, 4.0, 21.22905027932961, 6.779661016949152, 9.900990099009901, 0.0, 18.775510204081634, 8.620689655172415, 6.9364161849710975, 14.76510067114094, 6.2015503875969, 7.669616519174041, 8.333333333333332, 12.440191387559809, 8.080808080808081, 4.371584699453552, 11.023622047244094, 16.560509554140125, 1.3157894736842104, 10.38961038961039, 4.571428571428571]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [40][   8/7542]\tLoss 7.40e-01 (8.35e-01)\tAccuracy@Bitmap 93.52 (92.91)\tPrecision@Bitmap 18.18 (12.21)\tRecall@Bitmap 28.57 (16.91)\taccuracy: 92.91374708041374, precision: 12.206436648303857, recall: 16.907630522088354, F_score: 14.177470954706179\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179]\n",
      "epoch_loss=26.480107528822764\n",
      "micro_fsoce=[0, 35.45279383429673, 37.39279588336192, 38.61308116627266, 0.8032128514056224, 17.782426778242677, 0.0, 49.21090387374462, 0.0, 11.151079136690647, 36.23693379790941, 21.65775401069519, 1.8018018018018018, 34.09282700421941, 33.29989969909729, 20.171673819742487, 33.83458646616541, 31.08695652173913, 29.03533906399236, 22.535211267605636, 9.248554913294797, 23.39622641509434, 18.439716312056735, 27.490039840637447, 26.506024096385545, 15.023474178403756, 20.869565217391305, 31.11111111111111, 0.0, 29.31937172774869, 22.294022617124394, 26.869455006337134, 24.25531914893617, 21.84557438794727, 23.115577889447238, 28.085106382978726, 21.01806239737274, 24.6031746031746, 10.989010989010989, 23.790322580645164, 22.39089184060721, 22.033898305084744, 30.36053130929791, 20.833333333333336, 19.948849104859335, 23.61516034985423, 24.352331606217618, 19.306930693069308, 24.40087145969499, 23.88059701492537, 29.38053097345133, 19.616204690831555, 29.411764705882355, 26.523297491039425]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [41][  22/7542]\tLoss 6.82e-01 (6.71e-01)\tAccuracy@Bitmap 93.10 (93.74)\tPrecision@Bitmap 26.09 (22.33)\tRecall@Bitmap 36.73 (32.79)\taccuracy: 93.74367738196962, precision: 22.328262765235927, recall: 32.79026750142288, F_score: 26.566372701596634\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634]\n",
      "epoch_loss=21.431307964910896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.508474576271187, 29.47845804988662, 37.20073664825046, 0.5012531328320802, 9.345794392523365, 0.0, 27.06766917293233, 0.0, 1.1627906976744187, 22.295081967213115, 6.730769230769231, 0.0, 21.166306695464364, 16.43835616438356, 32.13296398891966, 20.408163265306122, 16.93548387096774, 23.970037453183522, 3.361344537815126, 2.209944751381215, 9.00900900900901, 10.32258064516129, 13.917525773195877, 19.727891156462583, 0.0, 9.473684210526317, 12.571428571428573, 0.0, 14.201183431952662, 8.284023668639055, 15.873015873015872, 8.19672131147541, 4.444444444444445, 4.0, 21.839080459770116, 5.681818181818182, 9.950248756218906, 2.3529411764705883, 18.487394957983195, 7.936507936507936, 5.952380952380952, 14.666666666666666, 5.797101449275362, 7.164179104477612, 10.0, 11.538461538461538, 9.15492957746479, 3.260869565217391, 9.523809523809524, 15.853658536585366, 1.4285714285714286, 9.210526315789473, 4.678362573099415]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [41][   8/7542]\tLoss 7.34e-01 (8.34e-01)\tAccuracy@Bitmap 92.59 (92.91)\tPrecision@Bitmap 12.50 (12.12)\tRecall@Bitmap 21.43 (16.77)\taccuracy: 92.90957624290958, precision: 12.119013062409287, recall: 16.76706827309237, F_score: 14.069081718618365\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365]\n",
      "epoch_loss=26.456825210934593\n",
      "micro_fsoce=[0, 36.31123919308357, 37.615449202350966, 38.4012539184953, 0.8032128514056224, 17.083333333333332, 0.0, 49.46236559139785, 0.0, 11.408199643493761, 37.03703703703704, 22.07621550591327, 2.416918429003021, 33.52990732940185, 33.069306930693074, 21.57676348547718, 32.75, 31.76341730558598, 29.600778967867576, 21.79930795847751, 9.35672514619883, 23.604060913705585, 18.138424821002385, 27.200000000000003, 26.095617529880478, 18.34862385321101, 21.683309557774606, 32.540675844806, 0.0, 32.200357781753134, 20.70063694267516, 26.39593908629442, 26.582278481012654, 21.88679245283019, 19.09547738693467, 27.566807313642755, 19.51219512195122, 24.146981627296586, 10.638297872340425, 22.977022977022976, 21.611001964636543, 22.29845626072041, 29.601518026565465, 21.025641025641026, 20.539152759948653, 24.48377581120944, 25.1604621309371, 20.40302267002519, 22.698072805139187, 26.923076923076923, 29.577464788732392, 21.794871794871796, 23.52941176470588, 25.97864768683274]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [42][  22/7542]\tLoss 6.47e-01 (6.70e-01)\tAccuracy@Bitmap 93.77 (93.74)\tPrecision@Bitmap 12.73 (22.42)\tRecall@Bitmap 21.21 (33.02)\taccuracy: 93.74465953622676, precision: 22.41812385276785, recall: 33.01792828685259, F_score: 26.704643535301226\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226]\n",
      "epoch_loss=21.409754175250814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.303030303030305, 29.47845804988662, 37.33826247689464, 0.5012531328320802, 9.90990990990991, 0.0, 27.703984819734345, 0.0, 1.2048192771084338, 20.80536912751678, 8.653846153846153, 0.0, 21.444201312910284, 16.74418604651163, 32.77777777777778, 21.105527638190953, 16.535433070866144, 26.865671641791046, 5.405405405405405, 3.225806451612903, 8.256880733944955, 9.090909090909092, 15.503875968992247, 20.327868852459016, 0.0, 8.743169398907105, 13.114754098360656, 0.0, 14.942528735632186, 8.0, 16.216216216216218, 9.375, 5.633802816901409, 4.081632653061225, 22.22222222222222, 5.4945054945054945, 9.852216748768473, 0.0, 16.733067729083665, 9.6, 8.0, 14.56953642384106, 5.88235294117647, 8.187134502923977, 9.655172413793103, 12.560386473429952, 8.275862068965518, 4.3478260869565215, 10.852713178294573, 14.285714285714285, 2.6490066225165565, 9.271523178807946, 5.649717514124294]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [42][   8/7542]\tLoss 7.27e-01 (8.34e-01)\tAccuracy@Bitmap 92.82 (92.88)\tPrecision@Bitmap 16.00 (12.29)\tRecall@Bitmap 28.57 (17.21)\taccuracy: 92.88177065954844, precision: 12.288500143389733, recall: 17.20883534136546, F_score: 14.338296804416931\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931]\n",
      "epoch_loss=26.464362984611874\n",
      "micro_fsoce=[0, 37.173281703775416, 37.933954276037255, 37.80392156862745, 1.2024048096192386, 17.87941787941788, 0.0, 49.820014398848095, 0.0, 10.676156583629894, 35.51236749116608, 23.435419440745672, 2.976190476190476, 33.78378378378378, 32.84169124877089, 22.129436325678498, 32.95019157088122, 31.56756756756757, 29.174664107485604, 21.070811744386873, 9.03954802259887, 22.97979797979798, 17.073170731707318, 26.91552062868369, 26.923076923076923, 16.589861751152075, 21.99710564399421, 33.33333333333333, 0.0, 30.49645390070922, 23.454833597464344, 26.229508196721312, 25.75107296137339, 22.22222222222222, 23.232323232323232, 27.762039660056658, 18.512396694214875, 23.576158940397352, 8.64864864864865, 23.636363636363637, 21.19460500963391, 23.18339100346021, 31.456310679611647, 20.971867007672635, 20.742637644046095, 24.259520451339917, 23.79746835443038, 19.03584672435105, 22.026431718061673, 25.53191489361702, 29.772329246935204, 20.29598308668076, 28.57142857142857, 25.53191489361702]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [43][  22/7542]\tLoss 6.00e-01 (6.70e-01)\tAccuracy@Bitmap 94.19 (93.74)\tPrecision@Bitmap 20.37 (22.37)\tRecall@Bitmap 29.73 (32.95)\taccuracy: 93.73876661068388, precision: 22.368166892022405, recall: 32.95389869095048, F_score: 26.64825681739731\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731]\n",
      "epoch_loss=21.42086053197667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.034129692832767, 30.76923076923077, 36.56307129798903, 0.0, 10.0, 0.0, 27.92452830188679, 0.0, 2.3255813953488373, 21.92691029900332, 8.955223880597014, 0.0, 21.69197396963124, 17.84037558685446, 31.868131868131865, 19.289340101522843, 16.06425702811245, 23.970037453183522, 3.149606299212598, 3.225806451612903, 7.373271889400922, 9.090909090909092, 15.384615384615385, 19.93127147766323, 0.0, 11.299435028248588, 12.290502793296088, 0.0, 16.56804733727811, 9.523809523809524, 15.135135135135137, 9.090909090909092, 5.633802816901409, 4.25531914893617, 21.839080459770116, 5.681818181818182, 9.75609756097561, 0.0, 19.591836734693878, 6.557377049180328, 5.714285714285714, 16.3265306122449, 7.246376811594203, 7.580174927113703, 9.722222222222223, 11.374407582938389, 8.450704225352112, 5.128205128205128, 9.67741935483871, 16.883116883116884, 1.3793103448275863, 9.15032679738562, 6.70391061452514]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [43][   8/7542]\tLoss 7.21e-01 (8.34e-01)\tAccuracy@Bitmap 93.29 (92.91)\tPrecision@Bitmap 17.39 (12.31)\tRecall@Bitmap 28.57 (17.11)\taccuracy: 92.9102713824936, precision: 12.306803408926765, recall: 17.10843373493976, F_score: 14.315718726371504\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504]\n",
      "epoch_loss=26.461398970513116\n",
      "micro_fsoce=[0, 36.08445297504799, 37.89836347975883, 38.81987577639752, 0.4024144869215292, 18.69158878504673, 0.0, 49.63820549927641, 0.0, 12.411347517730496, 37.53303964757709, 21.721854304635762, 1.2012012012012012, 34.035383319292336, 33.86454183266932, 21.428571428571427, 33.165829145728644, 32.18645948945616, 28.110161443494775, 19.9288256227758, 10.588235294117647, 22.75, 17.061611374407583, 27.517447657028914, 26.01787487586892, 15.887850467289718, 21.037037037037038, 33.04130162703379, 0.0, 30.28169014084507, 20.846905537459286, 26.295828065739567, 25.376344086021508, 21.96969696969697, 19.41747572815534, 29.219858156028366, 19.666666666666664, 24.299065420560748, 8.60215053763441, 23.983739837398375, 22.900763358778626, 23.809523809523807, 30.46875, 20.460358056265985, 21.292775665399237, 24.92753623188406, 23.72448979591837, 19.298245614035086, 22.566371681415927, 26.46420824295011, 31.57894736842105, 19.327731092436977, 30.303030303030305, 24.647887323943664]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [44][  22/7542]\tLoss 6.40e-01 (6.70e-01)\tAccuracy@Bitmap 94.19 (93.76)\tPrecision@Bitmap 25.00 (22.48)\tRecall@Bitmap 34.15 (32.97)\taccuracy: 93.76209277429113, precision: 22.476596983072223, recall: 32.96812749003984, F_score: 26.72973206817985\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985]\n",
      "epoch_loss=21.42612039184166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 28.57142857142857, 29.22374429223744, 38.07763401109057, 0.0, 9.25925925925926, 0.0, 27.599243856332706, 0.0, 5.747126436781609, 22.80130293159609, 7.766990291262135, 0.0, 20.869565217391305, 18.099547511312217, 32.32876712328767, 18.848167539267017, 16.666666666666664, 25.27881040892193, 3.389830508474576, 3.3333333333333335, 8.21917808219178, 10.0, 14.698162729658792, 19.93127147766323, 0.0, 9.782608695652174, 14.52513966480447, 0.0, 14.457831325301203, 7.650273224043716, 13.40782122905028, 7.751937984496124, 5.405405405405405, 4.0, 21.22905027932961, 6.8181818181818175, 10.050251256281408, 2.4691358024691357, 19.08713692946058, 8.0, 6.024096385542169, 14.37908496732026, 7.194244604316546, 8.211143695014663, 8.16326530612245, 10.891089108910892, 7.612456747404845, 4.081632653061225, 8.064516129032258, 16.25, 1.3513513513513513, 10.457516339869281, 5.847953216374268]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [44][   8/7542]\tLoss 7.13e-01 (8.34e-01)\tAccuracy@Bitmap 92.13 (92.90)\tPrecision@Bitmap 11.54 (12.20)\tRecall@Bitmap 21.43 (16.97)\taccuracy: 92.89775886998109, precision: 12.19864299119388, recall: 16.967871485943775, F_score: 14.193331653649114\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114]\n",
      "epoch_loss=26.46316186587016\n",
      "micro_fsoce=[0, 35.90243902439024, 36.255319148936174, 38.9937106918239, 0.8032128514056224, 17.665615141955836, 0.0, 49.85507246376812, 0.0, 12.121212121212121, 36.44444444444444, 23.04635761589404, 1.8018018018018018, 33.840947546531304, 32.701894317048854, 21.656050955414013, 33.20659062103929, 31.77366702937976, 28.736740597878494, 23.46760070052539, 8.187134502923977, 22.835633626097867, 17.78846153846154, 27.800000000000004, 26.373626373626376, 15.023474178403756, 20.408163265306122, 30.48780487804878, 0.0, 30.742049469964666, 20.602218700475436, 26.362484157160964, 25.052192066805844, 21.468926553672315, 18.274111675126903, 27.412587412587413, 19.124797406807133, 24.22680412371134, 8.743169398907105, 22.494887525562373, 21.052631578947366, 22.375215146299485, 29.545454545454547, 20.833333333333336, 20.636942675159236, 25.0, 23.36328626444159, 20.0, 22.698072805139187, 24.40087145969499, 30.526315789473685, 20.25862068965517, 22.857142857142858, 25.13274336283186]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [45][  22/7542]\tLoss 6.10e-01 (6.70e-01)\tAccuracy@Bitmap 94.53 (93.74)\tPrecision@Bitmap 31.48 (22.22)\tRecall@Bitmap 37.78 (32.59)\taccuracy: 93.73557460934815, precision: 22.21737232649498, recall: 32.59106431417189, F_score: 26.422494592646\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646]\n",
      "epoch_loss=21.423997022337833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.152542372881356, 30.04484304932735, 37.174721189591075, 0.5012531328320802, 10.909090909090908, 0.0, 28.08988764044944, 0.0, 2.2988505747126435, 20.945945945945947, 7.804878048780488, 0.0, 21.145374449339208, 18.95734597156398, 32.15258855585831, 20.94240837696335, 15.32258064516129, 23.88059701492537, 3.278688524590164, 2.13903743315508, 8.658008658008658, 6.493506493506493, 15.384615384615385, 17.940199335548172, 0.0, 11.363636363636363, 12.643678160919542, 0.0, 16.049382716049383, 8.333333333333332, 15.135135135135137, 10.0, 5.673758865248227, 4.166666666666666, 21.468926553672315, 6.666666666666667, 9.66183574879227, 2.4096385542168677, 18.930041152263374, 8.19672131147541, 8.235294117647058, 14.473684210526317, 6.2015503875969, 7.323943661971831, 9.523809523809524, 9.615384615384617, 7.194244604316546, 4.166666666666666, 10.294117647058822, 14.906832298136646, 1.2269938650306749, 10.457516339869281, 4.597701149425287]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [45][   8/7542]\tLoss 7.13e-01 (8.35e-01)\tAccuracy@Bitmap 93.52 (92.89)\tPrecision@Bitmap 20.83 (12.12)\tRecall@Bitmap 35.71 (16.87)\taccuracy: 92.88802691580469, precision: 12.119463280911845, recall: 16.867469879518072, F_score: 14.10460918478717\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717]\n",
      "epoch_loss=26.473972967692784\n",
      "micro_fsoce=[0, 36.52173913043478, 37.55310110450297, 38.48580441640379, 0.8032128514056224, 18.10613943808533, 0.0, 49.2040520984081, 0.0, 11.552346570397113, 37.06293706293706, 23.57512953367876, 2.380952380952381, 34.38297872340426, 33.75609756097561, 21.656050955414013, 31.69811320754717, 31.33841131664853, 29.14669223394056, 20.27972027972028, 7.100591715976331, 21.855146124523507, 16.54501216545012, 27.016129032258064, 26.506024096385545, 15.09433962264151, 21.700879765395893, 31.30434782608696, 0.0, 30.442477876106196, 21.829855537720707, 27.376425855513308, 25.684210526315788, 22.641509433962266, 21.428571428571427, 28.41068917018284, 20.36727879799666, 23.607427055702917, 7.526881720430108, 23.88663967611336, 23.552123552123554, 23.208191126279864, 29.32330827067669, 21.079691516709513, 21.079691516709513, 25.036390101892287, 24.38391699092088, 19.92619926199262, 22.894168466522675, 25.607064017660043, 30.65953654188948, 18.88412017167382, 18.75, 23.063063063063062]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [46][  22/7542]\tLoss 6.41e-01 (6.71e-01)\tAccuracy@Bitmap 94.11 (93.76)\tPrecision@Bitmap 26.67 (22.41)\tRecall@Bitmap 38.10 (32.83)\taccuracy: 93.75767308013397, precision: 22.406175656649026, recall: 32.83295389869095, F_score: 26.63550053386431\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431]\n",
      "epoch_loss=21.43810108708123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.931972789115648, 30.76923076923077, 36.059479553903344, 0.0, 9.25925925925926, 0.0, 27.80952380952381, 0.0, 3.4482758620689653, 21.568627450980394, 10.83743842364532, 0.0, 20.915032679738562, 17.75700934579439, 31.318681318681318, 19.148936170212767, 15.637860082304528, 24.62686567164179, 1.834862385321101, 3.1746031746031744, 8.0, 7.741935483870968, 14.545454545454545, 19.269102990033225, 0.0, 10.344827586206897, 13.186813186813188, 0.0, 16.470588235294116, 8.092485549132949, 17.877094972067038, 9.6, 5.88235294117647, 4.166666666666666, 21.34831460674157, 8.0, 8.955223880597014, 0.0, 18.69918699186992, 8.130081300813007, 6.976744186046512, 14.666666666666666, 7.142857142857142, 7.624633431085044, 9.58904109589041, 10.256410256410255, 7.746478873239436, 5.181347150259067, 10.526315789473683, 14.457831325301203, 1.3071895424836601, 9.15032679738562, 5.4945054945054945]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [46][   8/7542]\tLoss 7.07e-01 (8.35e-01)\tAccuracy@Bitmap 93.52 (92.91)\tPrecision@Bitmap 18.18 (12.18)\tRecall@Bitmap 28.57 (16.89)\taccuracy: 92.90749082415749, precision: 12.179580014482259, recall: 16.887550200803215, F_score: 14.152292806058057\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057]\n",
      "epoch_loss=26.46628682953971\n",
      "micro_fsoce=[0, 35.76287657920311, 37.71331058020478, 37.569060773480665, 0.0, 18.541666666666668, 0.0, 49.23747276688453, 0.0, 11.449016100178891, 36.506550218340614, 23.218997361477573, 2.3952095808383236, 34.8122866894198, 32.87671232876712, 21.205821205821206, 32.75, 32.06106870229007, 28.789323164918972, 21.951219512195124, 8.333333333333332, 23.647798742138367, 17.0316301703163, 27.29124236252546, 26.252505010020037, 13.761467889908257, 21.70767004341534, 31.565656565656564, 0.0, 31.597845601436266, 21.019108280254777, 25.757575757575758, 25.213675213675213, 22.22222222222222, 20.792079207920793, 28.011204481792717, 19.249592169657422, 24.313725490196077, 11.518324607329843, 23.647294589178355, 22.700587084148726, 22.895622895622896, 30.76923076923077, 21.374045801526716, 20.35623409669211, 23.75366568914956, 23.65038560411311, 19.696969696969695, 22.99349240780911, 26.41509433962264, 30.36649214659686, 18.818380743982495, 27.77777777777778, 25.0]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [47][  22/7542]\tLoss 5.57e-01 (6.70e-01)\tAccuracy@Bitmap 93.43 (93.74)\tPrecision@Bitmap 20.59 (22.33)\tRecall@Bitmap 36.84 (32.82)\taccuracy: 93.7419586120196, precision: 22.33141308031176, recall: 32.81872509960159, F_score: 26.577939100625127\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127]\n",
      "epoch_loss=21.420008826558874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.508474576271187, 31.08108108108108, 36.43122676579926, 0.0, 9.090909090909092, 0.0, 27.703984819734345, 0.0, 2.366863905325444, 21.052631578947366, 8.695652173913043, 0.0, 21.78649237472767, 18.433179723502306, 33.97260273972603, 19.587628865979383, 14.399999999999999, 24.62686567164179, 5.128205128205128, 1.092896174863388, 7.339449541284404, 7.9470198675496695, 15.66579634464752, 19.795221843003414, 0.0, 9.03954802259887, 12.834224598930483, 0.0, 15.476190476190476, 8.187134502923977, 15.957446808510639, 9.523809523809524, 5.755395683453238, 4.0, 21.59090909090909, 4.25531914893617, 10.891089108910892, 2.3529411764705883, 17.647058823529413, 8.130081300813007, 5.9880239520958085, 14.56953642384106, 4.545454545454546, 7.4074074074074066, 9.58904109589041, 10.42654028436019, 8.275862068965518, 4.18848167539267, 10.218978102189782, 16.352201257861633, 2.684563758389262, 8.0, 4.705882352941177]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [47][   8/7542]\tLoss 7.17e-01 (8.34e-01)\tAccuracy@Bitmap 93.52 (92.89)\tPrecision@Bitmap 20.83 (12.14)\tRecall@Bitmap 35.71 (16.91)\taccuracy: 92.88872205538871, precision: 12.143063167003172, recall: 16.907630522088354, F_score: 14.134631525935873\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873]\n",
      "epoch_loss=26.44304058665321\n",
      "micro_fsoce=[0, 36.964980544747085, 37.48939779474131, 38.588235294117645, 0.8032128514056224, 18.010471204188484, 0.0, 49.52932657494569, 0.0, 11.408199643493761, 36.82373472949389, 23.915900131406044, 1.8072289156626504, 33.702127659574465, 33.46534653465347, 21.47368421052632, 33.0, 32.096069868995635, 29.7790585975024, 22.064056939501782, 11.494252873563218, 22.8643216080402, 17.26618705035971, 27.586206896551722, 26.907630522088354, 15.668202764976957, 22.22222222222222, 30.538172715894866, 0.0, 29.61672473867596, 22.044728434504794, 26.54639175257732, 24.894514767932492, 22.779922779922778, 19.801980198019802, 27.932960893854748, 18.30065359477124, 24.538258575197887, 9.782608695652174, 22.92732855680655, 21.235521235521233, 24.242424242424242, 29.411764705882355, 20.105820105820104, 20.42875157629256, 24.606580829756798, 23.439490445859875, 19.849246231155778, 24.728850325379607, 25.70806100217865, 30.526315789473685, 20.346320346320347, 28.57142857142857, 25.263157894736842]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [48][  22/7542]\tLoss 7.62e-01 (6.71e-01)\tAccuracy@Bitmap 92.34 (93.76)\tPrecision@Bitmap 11.76 (22.46)\tRecall@Bitmap 20.51 (32.97)\taccuracy: 93.75742754156968, precision: 22.455902306648575, recall: 32.96812749003984, F_score: 26.715092816787735\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735]\n",
      "epoch_loss=21.43061161950483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.72972972972973, 29.88505747126437, 37.20073664825046, 0.5, 9.95475113122172, 0.0, 27.74566473988439, 0.0, 3.4682080924855487, 22.508038585209004, 6.896551724137931, 0.0, 22.07792207792208, 17.674418604651162, 29.545454545454547, 20.212765957446805, 16.535433070866144, 25.547445255474454, 1.8518518518518516, 1.0752688172043012, 7.2727272727272725, 8.75, 15.706806282722512, 18.543046357615893, 0.0, 9.72972972972973, 13.636363636363635, 0.0, 14.117647058823529, 10.650887573964498, 15.469613259668508, 8.0, 4.411764705882353, 3.8461538461538463, 21.839080459770116, 8.743169398907105, 10.256410256410255, 0.0, 18.181818181818183, 8.264462809917356, 8.0, 14.285714285714285, 6.25, 7.536231884057972, 8.0, 11.707317073170733, 8.480565371024735, 4.324324324324325, 9.230769230769232, 15.950920245398773, 2.5974025974025974, 10.38961038961039, 5.681818181818182]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [48][   8/7542]\tLoss 7.36e-01 (8.34e-01)\tAccuracy@Bitmap 93.29 (92.91)\tPrecision@Bitmap 14.29 (12.20)\tRecall@Bitmap 21.43 (16.93)\taccuracy: 92.90818596374152, precision: 12.203242617255356, recall: 16.927710843373493, F_score: 14.182368775235531\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531]\n",
      "epoch_loss=26.44946213563283\n",
      "micro_fsoce=[0, 36.95861405197305, 37.26495726495727, 38.21456538762725, 0.8016032064128256, 17.78697001034126, 0.0, 49.85507246376812, 0.0, 11.573236889692586, 36.74911660777385, 24.010554089709764, 1.812688821752266, 34.32963279248506, 33.233830845771145, 20.920502092050206, 33.458177278402, 32.03463203463203, 28.217349857006674, 22.735346358792185, 8.433734939759036, 23.27909887359199, 17.647058823529413, 27.290836653386453, 25.5859375, 18.91891891891892, 22.61380323054332, 31.19496855345912, 0.0, 30.742049469964666, 21.702838063439064, 27.307206068268012, 26.069246435845212, 21.30841121495327, 22.0, 28.49162011173184, 19.732441471571907, 22.963951935914555, 11.702127659574469, 23.684210526315788, 21.153846153846153, 22.641509433962266, 29.588014981273407, 20.3125, 21.27107652399481, 25.106990014265335, 23.827629911280102, 19.49367088607595, 22.174840085287848, 25.321888412017167, 29.537366548042705, 19.700214132762312, 31.25, 24.504504504504503]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [49][  22/7542]\tLoss 6.08e-01 (6.70e-01)\tAccuracy@Bitmap 94.36 (93.75)\tPrecision@Bitmap 22.58 (22.43)\tRecall@Bitmap 42.42 (32.93)\taccuracy: 93.75497215592681, precision: 22.431672804807135, recall: 32.93255549231645, F_score: 26.686267727429957\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957]\n",
      "epoch_loss=21.41966024798862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.553264604810998, 30.180180180180184, 37.89868667917448, 0.0, 10.95890410958904, 0.0, 28.30188679245283, 0.0, 3.508771929824561, 21.85430463576159, 8.823529411764707, 0.0, 20.915032679738562, 16.74418604651163, 32.86908077994429, 19.047619047619047, 15.767634854771783, 24.81203007518797, 6.896551724137931, 3.2085561497326207, 7.547169811320755, 10.32258064516129, 15.303430079155673, 19.801980198019802, 0.0, 9.03954802259887, 14.201183431952662, 0.0, 13.17365269461078, 8.98876404494382, 15.625, 7.874015748031496, 4.316546762589928, 4.0, 22.727272727272727, 5.376344086021505, 8.866995073891626, 0.0, 17.42738589211618, 9.67741935483871, 4.848484848484849, 15.584415584415584, 7.633587786259542, 7.017543859649122, 9.655172413793103, 10.679611650485436, 7.586206896551724, 4.102564102564102, 9.448818897637794, 17.177914110429448, 1.3605442176870748, 10.457516339869281, 4.790419161676647]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [49][   8/7542]\tLoss 7.22e-01 (8.35e-01)\tAccuracy@Bitmap 93.52 (92.93)\tPrecision@Bitmap 15.00 (12.25)\tRecall@Bitmap 21.43 (16.93)\taccuracy: 92.92625959292626, precision: 12.249346120313863, recall: 16.927710843373493, F_score: 14.213454729387962\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962]\n",
      "epoch_loss=26.47042939208803\n",
      "micro_fsoce=[0, 36.01161665053243, 37.30834752981261, 39.346811819595644, 0.8032128514056224, 18.658280922431867, 0.0, 49.85549132947977, 0.0, 10.849909584086799, 37.08260105448154, 23.404255319148938, 1.21580547112462, 34.060402684563755, 33.496571988246814, 21.50537634408602, 32.992327365728904, 32.78688524590164, 29.25890279114533, 21.951219512195124, 10.588235294117647, 23.037974683544306, 17.874396135265698, 27.54491017964072, 25.176233635448135, 17.75700934579439, 22.028985507246375, 31.960049937578027, 0.0, 31.15942028985507, 21.939586645468996, 26.632522407170296, 25.363825363825367, 21.933085501858738, 21.21212121212121, 27.57660167130919, 18.573797678275287, 24.258064516129032, 6.629834254143646, 23.3502538071066, 21.663442940038685, 23.06368330464716, 29.069767441860467, 20.918367346938776, 20.82810539523212, 24.312590448625183, 23.83419689119171, 19.672131147540984, 21.888412017167383, 24.463519313304722, 30.472854640980735, 19.78494623655914, 29.411764705882355, 24.91103202846975]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [50][  22/7542]\tLoss 7.14e-01 (6.71e-01)\tAccuracy@Bitmap 93.86 (93.76)\tPrecision@Bitmap 22.00 (22.44)\tRecall@Bitmap 24.44 (32.93)\taccuracy: 93.75767308013397, precision: 22.440963972263976, recall: 32.92544109277177, F_score: 26.690504339802185\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185]\n",
      "epoch_loss=21.428875842842004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.629629629629626, 29.88505747126437, 36.734693877551024, 1.0, 8.256880733944955, 0.0, 27.22117202268431, 0.0, 2.380952380952381, 22.082018927444793, 7.8431372549019605, 0.0, 21.304347826086957, 16.43835616438356, 32.32876712328767, 19.689119170984455, 15.686274509803921, 25.27881040892193, 5.0, 3.1746031746031744, 8.0, 6.622516556291391, 16.0857908847185, 20.0, 0.0, 8.290155440414509, 12.790697674418606, 0.0, 16.56804733727811, 8.284023668639055, 15.300546448087433, 9.090909090909092, 4.37956204379562, 4.166666666666666, 21.965317919075144, 6.741573033707865, 10.1010101010101, 0.0, 16.260162601626014, 9.917355371900827, 6.8181818181818175, 14.864864864864865, 7.6923076923076925, 7.647058823529412, 9.45945945945946, 9.569377990430622, 7.168458781362006, 4.145077720207254, 9.448818897637794, 15.18987341772152, 1.3888888888888888, 9.271523178807946, 5.88235294117647]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [50][   8/7542]\tLoss 7.30e-01 (8.34e-01)\tAccuracy@Bitmap 93.06 (92.90)\tPrecision@Bitmap 16.67 (12.12)\tRecall@Bitmap 28.57 (16.81)\taccuracy: 92.9005394283172, precision: 12.118141016360214, recall: 16.80722891566265, F_score: 14.082611255993942\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942]\n",
      "epoch_loss=26.452261374110268\n",
      "micro_fsoce=[0, 35.797665369649806, 37.28813559322034, 38.810641627543035, 0.4016064257028112, 17.628541448058762, 0.0, 49.31308749096168, 0.0, 11.66077738515901, 36.46017699115045, 22.133333333333333, 1.8018018018018018, 34.21276595744681, 32.30921704658078, 21.656050955414013, 33.0, 31.601731601731604, 28.893058161350844, 22.064056939501782, 10.285714285714285, 22.36024844720497, 17.349397590361445, 27.634194831013914, 26.534653465346537, 17.040358744394617, 21.438645980253877, 32.49370277078086, 0.0, 29.965156794425084, 22.71293375394322, 26.097867001254706, 25.311203319502074, 21.731123388581953, 21.105527638190953, 28.690807799442897, 19.078947368421055, 23.76502002670227, 8.51063829787234, 23.660262891809907, 21.52641878669276, 24.695652173913043, 30.245746691871457, 21.447721179624665, 20.35623409669211, 24.46043165467626, 24.30379746835443, 20.672478206724783, 23.861171366594363, 24.836601307189543, 29.47368421052631, 19.36842105263158, 28.57142857142857, 24.319419237749546]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [51][  22/7542]\tLoss 6.64e-01 (6.70e-01)\tAccuracy@Bitmap 93.77 (93.73)\tPrecision@Bitmap 24.62 (22.31)\tRecall@Bitmap 39.02 (32.91)\taccuracy: 93.72968168380525, precision: 22.31225582404862, recall: 32.91121229368241, F_score: 26.594613239817182\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182]\n",
      "epoch_loss=21.427444095328703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 31.125827814569533, 31.797235023041477, 36.36363636363637, 0.0, 8.108108108108109, 0.0, 27.692307692307693, 0.0, 2.3529411764705883, 20.59800664451827, 9.0, 0.0, 22.4622030237581, 18.01801801801802, 31.40495867768595, 20.618556701030926, 15.573770491803279, 23.272727272727273, 1.7391304347826086, 1.1173184357541899, 8.071748878923767, 9.032258064516128, 15.384615384615385, 19.93355481727575, 0.0, 12.222222222222221, 12.290502793296088, 0.0, 14.942528735632186, 10.285714285714285, 15.217391304347828, 10.0, 5.633802816901409, 3.9215686274509802, 21.59090909090909, 7.329842931937172, 10.0, 0.0, 18.181818181818183, 8.264462809917356, 5.681818181818182, 14.473684210526317, 8.633093525179856, 7.492795389048991, 9.395973154362416, 11.707317073170733, 8.934707903780069, 5.181347150259067, 9.230769230769232, 15.384615384615385, 1.2903225806451613, 7.9470198675496695, 4.790419161676647]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [51][   8/7542]\tLoss 7.23e-01 (8.34e-01)\tAccuracy@Bitmap 92.59 (92.90)\tPrecision@Bitmap 15.38 (12.22)\tRecall@Bitmap 28.57 (17.01)\taccuracy: 92.89567345122902, precision: 12.215171618113644, recall: 17.008032128514056, F_score: 14.218566392479437\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437]\n",
      "epoch_loss=26.435263752937317\n",
      "micro_fsoce=[0, 36.66343355965083, 37.38317757009346, 38.56362217017954, 0.8016032064128256, 18.314255983350677, 0.0, 49.85590778097983, 0.0, 10.507246376811594, 36.666666666666664, 21.727748691099478, 1.8072289156626504, 34.10059676044331, 34.26294820717131, 21.894736842105264, 33.66834170854271, 31.8232044198895, 28.87189292543021, 22.22222222222222, 12.429378531073446, 23.48578491965389, 17.96116504854369, 27.689243027888445, 26.380368098159508, 14.545454545454545, 20.058997050147493, 31.435643564356436, 0.0, 31.616341030195382, 21.12, 27.054361567635905, 24.358974358974358, 22.920517560073936, 22.0, 28.49002849002849, 19.898819561551434, 24.441524310118265, 9.67741935483871, 23.983739837398375, 22.65625, 23.890784982935152, 30.01949317738791, 19.689119170984455, 21.53846153846154, 24.466571834992887, 23.455233291298867, 20.326223337515685, 24.175824175824175, 26.75438596491228, 30.687830687830687, 20.302375809935207, 30.303030303030305, 22.743682310469314]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [52][  22/7542]\tLoss 7.02e-01 (6.71e-01)\tAccuracy@Bitmap 94.44 (93.77)\tPrecision@Bitmap 28.57 (22.54)\tRecall@Bitmap 38.10 (33.03)\taccuracy: 93.77166877829832, precision: 22.54054579003593, recall: 33.02504268639726, F_score: 26.79365079365079\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079]\n",
      "epoch_loss=21.43291141572645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.72972972972973, 31.506849315068493, 37.63837638376384, 0.5025125628140703, 10.045662100456621, 0.0, 28.19047619047619, 0.0, 2.380952380952381, 20.80536912751678, 7.000000000000001, 0.0, 20.985010706638114, 17.84037558685446, 31.693989071038253, 20.0, 14.229249011857709, 22.962962962962962, 1.680672268907563, 4.324324324324325, 9.865470852017937, 7.8431372549019605, 14.736842105263156, 21.262458471760798, 0.0, 8.55614973262032, 12.154696132596685, 0.0, 15.204678362573098, 10.227272727272728, 14.285714285714285, 7.751937984496124, 4.37956204379562, 4.081632653061225, 21.978021978021978, 4.49438202247191, 9.852216748768473, 0.0, 17.813765182186234, 8.064516129032258, 8.13953488372093, 15.172413793103448, 7.462686567164178, 7.647058823529412, 8.633093525179856, 12.440191387559809, 7.971014492753622, 4.2105263157894735, 9.30232558139535, 15.09433962264151, 1.2987012987012987, 9.210526315789473, 6.172839506172839]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [52][   8/7542]\tLoss 7.24e-01 (8.33e-01)\tAccuracy@Bitmap 92.59 (92.91)\tPrecision@Bitmap 12.50 (12.20)\tRecall@Bitmap 21.43 (16.93)\taccuracy: 92.90610054498943, precision: 12.197945304586892, recall: 16.927710843373493, F_score: 14.178790682028424\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424]\n",
      "epoch_loss=26.42801070780981\n",
      "micro_fsoce=[0, 35.94202898550725, 38.11129848229342, 38.43137254901961, 0.8032128514056224, 17.99163179916318, 0.0, 49.4608195542775, 0.0, 11.208406304728546, 36.74911660777385, 22.827496757457848, 3.003003003003003, 33.78151260504202, 33.23500491642085, 21.338912133891213, 32.540675844806, 32.57328990228013, 29.03533906399236, 20.49469964664311, 11.494252873563218, 23.243933588761177, 16.019417475728158, 27.66169154228856, 26.532663316582916, 15.887850467289718, 21.037463976945244, 31.880448318804483, 0.0, 31.393298059964724, 21.508828250401287, 25.831202046035806, 27.253668763102723, 22.55639097744361, 22.660098522167488, 28.691983122362867, 20.401337792642142, 24.30647291941876, 6.417112299465241, 22.89156626506024, 23.076923076923077, 23.48993288590604, 28.952380952380953, 21.108179419525065, 21.20051085568327, 24.926686217008797, 24.484536082474225, 20.884520884520885, 22.271714922049, 24.946236559139784, 29.965156794425084, 19.06779661016949, 29.411764705882355, 25.13274336283186]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [53][  22/7542]\tLoss 6.02e-01 (6.71e-01)\tAccuracy@Bitmap 93.86 (93.74)\tPrecision@Bitmap 22.58 (22.43)\tRecall@Bitmap 35.90 (33.05)\taccuracy: 93.74490507479105, precision: 22.42986141291226, recall: 33.046385885031306, F_score: 26.722278153315116\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116]\n",
      "epoch_loss=21.432452411469768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.72972972972973, 29.698375870069604, 37.9182156133829, 0.0, 9.90990990990991, 0.0, 26.741996233521657, 0.0, 3.508771929824561, 21.794871794871796, 7.6190476190476195, 0.0, 21.350762527233115, 17.59259259259259, 34.065934065934066, 18.75, 16.3265306122449, 24.53531598513011, 3.278688524590164, 2.1505376344086025, 8.108108108108109, 10.126582278481013, 15.143603133159269, 19.333333333333332, 0.0, 11.235955056179774, 13.636363636363635, 0.0, 14.285714285714285, 8.235294117647058, 16.304347826086957, 9.75609756097561, 5.714285714285714, 3.9215686274509802, 21.714285714285715, 5.88235294117647, 9.615384615384617, 0.0, 15.637860082304528, 9.917355371900827, 8.187134502923977, 14.76510067114094, 7.4074074074074066, 7.492795389048991, 8.333333333333332, 10.328638497652582, 7.6923076923076925, 4.18848167539267, 11.29032258064516, 16.455696202531644, 1.282051282051282, 7.894736842105263, 4.848484848484849]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [53][   8/7542]\tLoss 7.12e-01 (8.36e-01)\tAccuracy@Bitmap 93.29 (92.90)\tPrecision@Bitmap 17.39 (12.18)\tRecall@Bitmap 28.57 (16.91)\taccuracy: 92.90262484706929, precision: 12.178189181371131, recall: 16.907630522088354, F_score: 14.158399192870355\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355]\n",
      "epoch_loss=26.500164838064286\n",
      "micro_fsoce=[0, 36.46944713870029, 37.787234042553195, 38.37118245888802, 0.8032128514056224, 17.13688610240334, 0.0, 48.914616497829236, 0.0, 12.4777183600713, 36.7311072056239, 23.591087811271297, 1.2084592145015105, 33.78151260504202, 34.093161546085234, 20.920502092050206, 32.06106870229007, 30.53435114503817, 28.46299810246679, 20.761245674740483, 9.523809523809524, 23.047375160051217, 17.0316301703163, 26.961770623742453, 25.574425574425575, 15.238095238095239, 19.854014598540147, 31.435643564356436, 0.0, 30.344827586206897, 21.337579617834397, 26.27551020408163, 26.41509433962264, 21.804511278195488, 21.105527638190953, 28.53146853146853, 19.28104575163399, 23.49869451697128, 11.049723756906078, 23.67101303911735, 21.57996146435453, 23.154362416107382, 30.0, 20.99737532808399, 20.387096774193548, 23.309352517985612, 24.352331606217618, 20.31823745410037, 23.946784922394677, 26.69491525423729, 30.017452006980804, 20.96069868995633, 29.411764705882355, 25.179856115107913]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [54][  22/7542]\tLoss 7.57e-01 (6.71e-01)\tAccuracy@Bitmap 92.51 (93.73)\tPrecision@Bitmap 15.87 (22.27)\tRecall@Bitmap 21.74 (32.75)\taccuracy: 93.73410137796242, precision: 22.270066282839036, recall: 32.74758110415481, F_score: 26.51115910727142\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116, 26.51115910727142]\n",
      "epoch_loss=21.435436634694117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 28.95622895622896, 31.25, 36.49906890130354, 0.5, 10.909090909090908, 0.0, 28.037383177570092, 0.0, 1.1764705882352942, 21.85430463576159, 8.61244019138756, 0.0, 22.07792207792208, 16.822429906542055, 32.22222222222222, 19.791666666666664, 17.21311475409836, 24.06015037593985, 3.6036036036036037, 1.1049723756906076, 7.792207792207792, 7.643312101910828, 15.143603133159269, 18.666666666666668, 0.0, 9.836065573770492, 13.40782122905028, 0.0, 15.66265060240964, 9.35672514619883, 15.555555555555555, 9.30232558139535, 6.015037593984962, 4.081632653061225, 21.468926553672315, 6.629834254143646, 8.866995073891626, 2.380952380952381, 18.106995884773664, 10.9375, 5.88235294117647, 15.172413793103448, 5.797101449275362, 7.90273556231003, 8.391608391608392, 11.594202898550725, 7.773851590106007, 4.123711340206185, 11.666666666666666, 15.950920245398773, 2.631578947368421, 8.108108108108109, 4.968944099378882]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [54][   8/7542]\tLoss 7.17e-01 (8.34e-01)\tAccuracy@Bitmap 93.75 (92.93)\tPrecision@Bitmap 19.05 (12.27)\tRecall@Bitmap 28.57 (16.97)\taccuracy: 92.92556445334223, precision: 12.269493248148686, recall: 16.967871485943775, F_score: 14.241173000758407\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355, 14.241173000758407]\n",
      "epoch_loss=26.434064325832185\n",
      "micro_fsoce=[0, 36.15160349854227, 37.233134073441505, 39.0625, 0.4024144869215292, 19.08713692946058, 0.0, 49.676956209619526, 0.0, 11.051693404634582, 37.10801393728223, 21.628838451268358, 2.4096385542168677, 33.61629881154499, 33.93213572854291, 21.75732217573222, 32.5, 31.9290465631929, 28.053435114503817, 21.238938053097346, 9.30232558139535, 22.641509433962266, 16.786570743405278, 27.054108216432866, 25.374625374625374, 14.150943396226415, 21.145374449339208, 32.758620689655174, 0.0, 30.08849557522124, 20.253164556962027, 26.75, 26.195426195426197, 20.610687022900763, 20.2020202020202, 27.05718270571827, 21.311475409836063, 24.281984334203656, 10.869565217391305, 22.833843017329254, 20.352250489236788, 23.011844331641285, 29.277566539923956, 21.705426356589147, 19.53727506426735, 24.390243902439025, 24.327784891165173, 19.45137157107232, 22.746781115879827, 24.175824175824175, 30.579964850615116, 18.88412017167382, 31.25, 24.642857142857146]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [55][  22/7542]\tLoss 8.32e-01 (6.71e-01)\tAccuracy@Bitmap 91.50 (93.73)\tPrecision@Bitmap 11.59 (22.24)\tRecall@Bitmap 16.67 (32.68)\taccuracy: 93.73189153088384, precision: 22.23620522749274, recall: 32.683551508252705, F_score: 26.466182739946998\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116, 26.51115910727142, 26.466182739946998]\n",
      "epoch_loss=21.439945211855033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 29.629629629629626, 29.767441860465116, 37.03703703703704, 0.0, 9.174311926605505, 0.0, 28.083491461100568, 0.0, 2.3952095808383236, 22.950819672131146, 7.8431372549019605, 0.0, 21.551724137931032, 18.6046511627907, 32.417582417582416, 22.0, 18.106995884773664, 24.53531598513011, 3.7735849056603774, 0.0, 8.256880733944955, 8.9171974522293, 15.584415584415584, 20.0, 0.0, 8.743169398907105, 12.865497076023392, 0.0, 15.909090909090908, 7.0588235294117645, 15.469613259668508, 9.6, 5.673758865248227, 3.8461538461538463, 21.965317919075144, 6.896551724137931, 9.950248756218906, 2.2988505747126435, 18.326693227091635, 9.75609756097561, 4.761904761904762, 13.986013986013987, 6.0606060606060606, 8.0, 9.655172413793103, 11.267605633802818, 6.896551724137931, 5.263157894736842, 9.448818897637794, 17.72151898734177, 2.6490066225165565, 9.333333333333334, 4.705882352941177]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [55][   8/7542]\tLoss 7.08e-01 (8.34e-01)\tAccuracy@Bitmap 93.75 (92.93)\tPrecision@Bitmap 19.05 (12.32)\tRecall@Bitmap 28.57 (17.05)\taccuracy: 92.9269547325103, precision: 12.31684317423473, recall: 17.048192771084338, F_score: 14.301356017855637\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355, 14.241173000758407, 14.301356017855637]\n",
      "epoch_loss=26.46251842521486\n",
      "micro_fsoce=[0, 36.55705996131528, 37.02451394759087, 39.02439024390244, 0.8032128514056224, 19.23474663908997, 0.0, 49.92743105950653, 0.0, 11.827956989247312, 36.15520282186949, 22.84196547144754, 1.791044776119403, 34.470989761092156, 32.83582089552239, 20.94017094017094, 33.71356147021547, 30.786026200873362, 28.709055876685934, 23.117338003502628, 11.494252873563218, 22.5031605562579, 17.391304347826086, 27.40814299900695, 25.450901803607213, 14.814814814814813, 23.768115942028984, 31.41104294478528, 0.0, 30.96085409252669, 21.578099838969404, 26.649746192893403, 23.25581395348837, 21.973929236499067, 21.21212121212121, 27.932960893854748, 18.43003412969283, 23.390275952693823, 8.421052631578947, 24.291497975708502, 21.292775665399237, 23.46938775510204, 29.389312977099237, 20.418848167539267, 21.065989847715734, 24.198250728862973, 23.707440100882724, 20.812182741116754, 22.844827586206897, 25.59652928416486, 28.819444444444443, 21.58590308370044, 25.0, 24.604569420035148]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [56][  22/7542]\tLoss 6.76e-01 (6.71e-01)\tAccuracy@Bitmap 94.53 (93.75)\tPrecision@Bitmap 26.92 (22.40)\tRecall@Bitmap 34.15 (32.86)\taccuracy: 93.75349892454109, precision: 22.398409465619242, recall: 32.861411496869664, F_score: 26.639367898956113\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116, 26.51115910727142, 26.466182739946998, 26.639367898956113]\n",
      "epoch_loss=21.436103038868662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 27.2108843537415, 31.60270880361174, 37.988826815642454, 0.0, 8.144796380090497, 0.0, 28.30188679245283, 0.0, 2.3529411764705883, 23.333333333333332, 7.6190476190476195, 0.0, 21.978021978021978, 16.589861751152075, 31.491712707182316, 19.289340101522843, 15.637860082304528, 24.087591240875913, 1.7543859649122806, 2.1621621621621623, 7.239819004524888, 6.493506493506493, 14.698162729658792, 20.066889632107024, 0.0, 11.363636363636363, 12.716763005780345, 0.0, 12.790697674418606, 8.235294117647058, 14.207650273224044, 8.264462809917356, 4.316546762589928, 3.9215686274509802, 20.994475138121548, 6.666666666666667, 9.950248756218906, 2.4390243902439024, 17.28395061728395, 7.8125, 6.976744186046512, 15.384615384615385, 10.218978102189782, 7.471264367816093, 11.11111111111111, 11.320754716981133, 8.571428571428571, 4.145077720207254, 9.30232558139535, 14.545454545454545, 2.7586206896551726, 9.210526315789473, 3.6809815950920246]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [56][   8/7542]\tLoss 7.22e-01 (8.34e-01)\tAccuracy@Bitmap 93.29 (92.91)\tPrecision@Bitmap 14.29 (12.14)\tRecall@Bitmap 21.43 (16.81)\taccuracy: 92.90749082415749, precision: 12.13571117877338, recall: 16.80722891566265, F_score: 14.094468300075777\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355, 14.241173000758407, 14.301356017855637, 14.094468300075777]\n",
      "epoch_loss=26.44149953410739\n",
      "micro_fsoce=[0, 36.61148977604674, 37.362637362637365, 38.30455259026688, 0.8032128514056224, 18.860103626943005, 0.0, 49.12536443148688, 0.0, 12.142857142857142, 36.157205240174676, 22.62678803641092, 2.4096385542168677, 34.280936454849495, 32.77393879565646, 21.166306695464364, 32.953105196451205, 31.646932185145317, 29.305423406279736, 23.223570190641247, 9.696969696969697, 23.037974683544306, 17.15686274509804, 27.860696517412936, 25.273631840796018, 15.887850467289718, 20.839363241678726, 32.27383863080684, 0.0, 30.419580419580424, 21.26984126984127, 26.165803108808287, 23.678646934460886, 22.752293577981654, 18.556701030927837, 27.887323943661972, 18.855218855218855, 24.320827943078914, 10.695187165775401, 22.944162436548226, 20.784313725490197, 22.602739726027394, 30.443159922928707, 20.887728459530024, 20.733249051833123, 25.25399129172714, 23.589743589743588, 20.64676616915423, 22.07792207792208, 23.504273504273502, 30.7426597582038, 21.00656455142232, 29.411764705882355, 23.885918003565063]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [57][  22/7542]\tLoss 6.67e-01 (6.71e-01)\tAccuracy@Bitmap 93.77 (93.73)\tPrecision@Bitmap 13.73 (22.30)\tRecall@Bitmap 18.92 (32.83)\taccuracy: 93.73459245509099, precision: 22.304383548402686, recall: 32.83295389869095, F_score: 26.563444326128877\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116, 26.51115910727142, 26.466182739946998, 26.639367898956113, 26.563444326128877]\n",
      "epoch_loss=21.435967455981142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 31.186440677966104, 29.411764705882355, 35.92592592592593, 0.5012531328320802, 10.762331838565023, 0.0, 26.79245283018868, 0.0, 3.488372093023256, 20.52980132450331, 8.080808080808081, 0.0, 22.03023758099352, 17.142857142857142, 31.521739130434785, 19.48717948717949, 15.32258064516129, 23.846153846153847, 4.958677685950414, 0.0, 7.441860465116279, 7.59493670886076, 15.343915343915343, 20.0, 0.0, 9.67741935483871, 13.829787234042554, 0.0, 18.072289156626507, 9.30232558139535, 15.053763440860216, 9.523809523809524, 5.839416058394161, 4.0, 21.11111111111111, 7.777777777777778, 10.050251256281408, 0.0, 18.106995884773664, 7.8125, 8.187134502923977, 16.0, 6.0606060606060606, 8.092485549132949, 9.79020979020979, 10.328638497652582, 7.829181494661921, 5.970149253731343, 11.11111111111111, 16.049382716049383, 1.3986013986013985, 10.526315789473683, 5.9171597633136095]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [57][   8/7542]\tLoss 7.21e-01 (8.34e-01)\tAccuracy@Bitmap 92.82 (92.90)\tPrecision@Bitmap 16.00 (12.20)\tRecall@Bitmap 28.57 (16.97)\taccuracy: 92.89984428873318, precision: 12.203928365106876, recall: 16.967871485943775, F_score: 14.196908602150538\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355, 14.241173000758407, 14.301356017855637, 14.094468300075777, 14.196908602150538]\n",
      "epoch_loss=26.45192191146669\n",
      "micro_fsoce=[0, 36.27546071774976, 37.86078098471987, 38.6994448850119, 1.2, 18.35245046923879, 0.0, 49.4269340974212, 0.0, 10.909090909090908, 37.38977072310406, 22.516556291390728, 3.571428571428571, 34.37764606265876, 34.75670307845085, 21.987315010570825, 33.37484433374844, 31.23644251626898, 28.842504743833018, 19.538188277087034, 10.404624277456648, 23.27909887359199, 15.676959619952493, 27.04339051463169, 26.25863770977295, 17.674418604651162, 21.613832853025936, 31.565656565656564, 0.0, 30.715532286212916, 22.042139384116695, 26.666666666666668, 25.477707006369428, 22.794117647058822, 20.304568527918782, 27.401129943502823, 17.845117845117844, 24.296675191815854, 9.67741935483871, 23.302938196555218, 22.55639097744361, 23.12925170068027, 29.942418426103647, 20.051413881748072, 20.480404551201012, 24.277456647398843, 24.010217113665387, 19.899244332493705, 23.144104803493452, 27.43362831858407, 29.37062937062937, 17.634408602150536, 28.57142857142857, 25.992779783393498]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [58][  22/7542]\tLoss 6.35e-01 (6.71e-01)\tAccuracy@Bitmap 94.02 (93.75)\tPrecision@Bitmap 22.41 (22.41)\tRecall@Bitmap 33.33 (32.94)\taccuracy: 93.74907923038393, precision: 22.40828574194173, recall: 32.93966989186113, F_score: 26.67204332046777\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116, 26.51115910727142, 26.466182739946998, 26.639367898956113, 26.563444326128877, 26.67204332046777]\n",
      "epoch_loss=21.44110198394727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.100334448160538, 30.909090909090907, 35.92592592592593, 0.5012531328320802, 9.090909090909092, 0.0, 28.030303030303028, 0.0, 2.380952380952381, 21.122112211221122, 7.8431372549019605, 0.0, 20.25862068965517, 16.267942583732058, 32.686980609418285, 20.833333333333336, 14.5748987854251, 24.264705882352942, 3.225806451612903, 1.0869565217391304, 8.035714285714286, 6.369426751592357, 14.987080103359174, 21.08843537414966, 0.0, 8.64864864864865, 13.095238095238097, 0.0, 15.384615384615385, 8.484848484848486, 14.973262032085561, 7.633587786259542, 5.47945205479452, 4.166666666666666, 21.714285714285715, 6.741573033707865, 10.204081632653061, 2.380952380952381, 19.834710743801654, 7.8125, 8.98876404494382, 14.864864864864865, 5.839416058394161, 7.580174927113703, 9.58904109589041, 11.483253588516746, 8.02919708029197, 4.0, 9.30232558139535, 16.666666666666664, 2.5, 12.903225806451612, 4.761904761904762]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [58][   8/7542]\tLoss 7.48e-01 (8.34e-01)\tAccuracy@Bitmap 93.52 (92.89)\tPrecision@Bitmap 15.00 (12.13)\tRecall@Bitmap 21.43 (16.89)\taccuracy: 92.88802691580469, precision: 12.130390884177125, recall: 16.887550200803215, F_score: 14.119029631495007\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355, 14.241173000758407, 14.301356017855637, 14.094468300075777, 14.196908602150538, 14.119029631495007]\n",
      "epoch_loss=26.43707003479912\n",
      "micro_fsoce=[0, 36.46944713870029, 37.71331058020478, 38.497652582159624, 1.2, 18.580375782881003, 0.0, 49.63820549927641, 0.0, 10.915492957746478, 36.716681376875556, 22.192866578599734, 4.154302670623145, 34.51178451178451, 32.80318091451292, 22.736842105263158, 33.91959798994975, 31.72866520787746, 29.03533906399236, 20.738137082601053, 8.13953488372093, 24.358974358974358, 16.831683168316832, 27.391742195367573, 26.518218623481783, 13.82488479262673, 20.431654676258994, 32.378580323785805, 0.0, 30.0, 21.153846153846153, 25.954198473282442, 24.680851063829788, 21.052631578947366, 21.105527638190953, 26.89075630252101, 19.736842105263158, 25.593667546174142, 9.473684210526317, 23.316582914572866, 21.44249512670565, 22.033898305084744, 31.238095238095237, 21.079691516709513, 20.584498094027953, 24.277456647398843, 23.711340206185564, 21.662468513853906, 24.190064794816415, 24.47257383966245, 29.86111111111111, 19.53290870488323, 30.303030303030305, 25.352112676056336]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [59][  22/7542]\tLoss 6.38e-01 (6.71e-01)\tAccuracy@Bitmap 93.60 (93.75)\tPrecision@Bitmap 25.71 (22.42)\tRecall@Bitmap 42.86 (32.93)\taccuracy: 93.75202569315537, precision: 22.415964351448224, recall: 32.92544109277177, F_score: 26.672814247017463\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116, 26.51115910727142, 26.466182739946998, 26.639367898956113, 26.563444326128877, 26.67204332046777, 26.672814247017463]\n",
      "epoch_loss=21.436938982393784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.927835051546392, 30.0, 36.90036900369004, 0.0, 11.059907834101383, 0.0, 27.969348659003828, 0.0, 2.3952095808383236, 21.49837133550489, 6.9306930693069315, 0.0, 21.413276231263385, 18.181818181818183, 32.69754768392371, 20.304568527918782, 15.32258064516129, 24.334600760456272, 6.666666666666667, 4.395604395604396, 8.88888888888889, 8.536585365853659, 14.933333333333335, 20.0, 0.0, 9.62566844919786, 11.560693641618498, 0.0, 13.872832369942195, 8.13953488372093, 16.216216216216218, 9.523809523809524, 5.797101449275362, 3.8461538461538463, 22.093023255813954, 7.608695652173914, 10.309278350515463, 0.0, 17.21311475409836, 8.064516129032258, 7.865168539325842, 16.3265306122449, 5.839416058394161, 8.115942028985506, 11.11111111111111, 11.707317073170733, 7.638888888888889, 4.081632653061225, 9.67741935483871, 16.560509554140125, 2.631578947368421, 11.612903225806452, 4.819277108433735]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [59][   8/7542]\tLoss 7.35e-01 (8.34e-01)\tAccuracy@Bitmap 92.59 (92.92)\tPrecision@Bitmap 15.38 (12.34)\tRecall@Bitmap 28.57 (17.11)\taccuracy: 92.92347903459014, precision: 12.340672074159906, recall: 17.10843373493976, F_score: 14.33860652978795\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355, 14.241173000758407, 14.301356017855637, 14.094468300075777, 14.196908602150538, 14.119029631495007, 14.33860652978795]\n",
      "epoch_loss=26.46383211158571\n",
      "micro_fsoce=[0, 36.908212560386474, 36.86006825938566, 38.93249607535322, 0.4024144869215292, 17.935349322210637, 0.0, 49.168474331164134, 0.0, 11.247803163444638, 35.870516185476816, 23.35958005249344, 2.4024024024024024, 33.6417157275021, 34.1948310139165, 21.748400852878465, 32.7455919395466, 32.711306256860595, 29.361296472831267, 22.758620689655174, 9.467455621301776, 23.455233291298867, 17.452830188679243, 27.57242757242757, 25.8, 16.51376146788991, 21.306818181818183, 31.5527950310559, 0.0, 30.742049469964666, 19.96779388083736, 25.660377358490567, 25.523012552301257, 22.181146025878004, 21.0, 28.29403606102635, 19.765494137353436, 24.299065420560748, 7.567567567567568, 24.444444444444443, 22.900763358778626, 22.641509433962266, 29.433962264150942, 20.99737532808399, 20.330368487928844, 24.858757062146893, 23.333333333333332, 19.950124688279303, 22.844827586206897, 27.586206896551722, 29.876977152899826, 18.789144050104383, 29.411764705882355, 25.71428571428571]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [60][  22/7542]\tLoss 6.75e-01 (6.71e-01)\tAccuracy@Bitmap 94.36 (93.73)\tPrecision@Bitmap 30.36 (22.36)\tRecall@Bitmap 37.78 (33.00)\taccuracy: 93.73361030083385, precision: 22.364171045653954, recall: 33.003699487763235, F_score: 26.661685680623005\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116, 26.51115910727142, 26.466182739946998, 26.639367898956113, 26.563444326128877, 26.67204332046777, 26.672814247017463, 26.661685680623005]\n",
      "epoch_loss=21.432142167273213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.612244897959183, 31.264367816091955, 36.666666666666664, 0.0, 11.11111111111111, 0.0, 27.599243856332706, 0.0, 1.1627906976744187, 22.07792207792208, 7.729468599033816, 0.0, 21.894736842105264, 17.431192660550458, 32.065217391304344, 19.689119170984455, 17.28395061728395, 24.719101123595504, 1.680672268907563, 1.0869565217391304, 7.2727272727272725, 10.126582278481013, 14.973262032085561, 20.875420875420875, 0.0, 11.299435028248588, 11.76470588235294, 0.0, 16.184971098265898, 9.090909090909092, 16.666666666666664, 9.230769230769232, 5.839416058394161, 3.9215686274509802, 22.857142857142858, 9.03954802259887, 10.050251256281408, 2.3529411764705883, 17.254901960784313, 8.130081300813007, 6.976744186046512, 14.473684210526317, 7.194244604316546, 7.71513353115727, 9.271523178807946, 11.881188118811881, 7.829181494661921, 5.025125628140704, 10.852713178294573, 15.384615384615385, 1.3071895424836601, 10.457516339869281, 4.848484848484849]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [60][   8/7542]\tLoss 7.36e-01 (8.33e-01)\tAccuracy@Bitmap 94.21 (92.90)\tPrecision@Bitmap 21.05 (12.35)\tRecall@Bitmap 28.57 (17.23)\taccuracy: 92.9005394283172, precision: 12.347100302201754, recall: 17.2289156626506, F_score: 14.38511191214687\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355, 14.241173000758407, 14.301356017855637, 14.094468300075777, 14.196908602150538, 14.119029631495007, 14.33860652978795, 14.38511191214687]\n",
      "epoch_loss=26.43120689051492\n",
      "micro_fsoce=[0, 36.41618497109826, 37.43589743589744, 38.87147335423197, 1.2024048096192386, 18.711018711018713, 0.0, 49.06204906204906, 0.0, 11.367673179396093, 36.3951473136915, 22.685788787483702, 2.4024024024024024, 33.81478334749362, 33.33333333333333, 21.052631578947366, 32.40506329113924, 31.956521739130434, 28.846153846153843, 19.96497373029772, 10.344827586206897, 22.87166454891995, 18.30985915492958, 28.344895936570865, 26.173826173826175, 16.51376146788991, 21.613832853025936, 32.378580323785805, 0.0, 29.484902309058615, 20.880913539967374, 27.122940430925226, 26.05042016806723, 20.817843866171003, 20.304568527918782, 28.815977175463626, 21.01694915254237, 23.94736842105263, 7.4866310160427805, 23.053589484327603, 21.27659574468085, 22.14650766609881, 30.566037735849054, 22.164948453608247, 21.185372005044137, 25.11078286558346, 24.643320363164722, 19.900497512437813, 23.52941176470588, 25.267665952890795, 29.268292682926827, 19.823788546255507, 30.303030303030305, 24.372759856630825]\n",
      "label_num=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
      "Epoch: [61][  22/7542]\tLoss 5.89e-01 (6.70e-01)\tAccuracy@Bitmap 93.86 (93.75)\tPrecision@Bitmap 17.86 (22.40)\tRecall@Bitmap 27.03 (32.92)\taccuracy: 93.74858815325535, precision: 22.39810243005131, recall: 32.91832669322709, F_score: 26.657832574753705\n",
      "[0.7103393843725335, 10.14504697544091, 16.178924399948656, 18.244485294117645, 19.670326646302872, 23.25555493679345, 24.347487339306582, 24.899621105016116, 25.11215823481279, 25.646563974307963, 26.1067615658363, 26.239468103398867, 26.257689875237165, 26.35373876073655, 26.506232188606464, 26.57000661661057, 26.512901830762576, 26.69170759895984, 26.725852477445017, 26.554583141409488, 26.668201969025272, 26.61045823347674, 26.58869620326093, 26.771064221768043, 26.806198430267656, 26.52286453839517, 26.670884619809044, 26.49033336214596, 26.634033976389286, 26.433341008519456, 26.57427109091955, 26.527553608485128, 26.56191328962191, 26.49651437460391, 26.500259410849136, 26.57608382750878, 26.535711208753337, 26.588459649224188, 26.486704735536716, 26.48583275742916, 26.603256953451503, 26.566372701596634, 26.704643535301226, 26.64825681739731, 26.72973206817985, 26.422494592646, 26.63550053386431, 26.577939100625127, 26.715092816787735, 26.686267727429957, 26.690504339802185, 26.594613239817182, 26.79365079365079, 26.722278153315116, 26.51115910727142, 26.466182739946998, 26.639367898956113, 26.563444326128877, 26.67204332046777, 26.672814247017463, 26.661685680623005, 26.657832574753705]\n",
      "epoch_loss=21.423406263529245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141750000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_fsoce=[0, 30.0, 29.629629629629626, 36.80297397769517, 0.0, 9.30232558139535, 0.0, 28.57142857142857, 0.0, 3.508771929824561, 19.736842105263158, 8.955223880597014, 0.0, 22.270742358078603, 18.181818181818183, 32.77777777777778, 19.48717948717949, 17.52988047808765, 24.817518248175183, 1.7241379310344827, 2.1621621621621623, 9.821428571428571, 10.0, 14.545454545454545, 18.543046357615893, 0.0, 9.836065573770492, 11.428571428571429, 0.0, 16.374269005847953, 7.100591715976331, 14.054054054054054, 9.30232558139535, 5.673758865248227, 4.0, 23.121387283236995, 8.60215053763441, 10.152284263959391, 2.380952380952381, 19.327731092436977, 9.375, 5.88235294117647, 14.473684210526317, 8.633093525179856, 7.536231884057972, 8.633093525179856, 10.138248847926267, 9.12280701754386, 5.181347150259067, 10.084033613445378, 16.25, 1.3333333333333335, 8.0, 5.813953488372093]\n",
      "label_num=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n",
      "Epoch: [61][   8/7542]\tLoss 7.41e-01 (8.34e-01)\tAccuracy@Bitmap 93.75 (92.91)\tPrecision@Bitmap 19.05 (12.29)\tRecall@Bitmap 28.57 (17.07)\taccuracy: 92.9102713824936, precision: 12.285012285012286, recall: 17.06827309236948, F_score: 14.28691486679553\n",
      "[2.3420558045395405, 9.1557911908646, 10.648836057454185, 11.374111397547066, 12.005068102629078, 13.760588141281765, 14.038256300796323, 13.594396688952562, 14.226009997541588, 13.681795838112404, 14.207377866400797, 14.109347442680775, 14.154982789018556, 14.025056756075003, 14.177852348993289, 14.106425702811245, 14.343366403228519, 14.283302380550397, 14.227848101265822, 14.277325727707407, 14.229513685444045, 14.388125158134436, 14.209950332519572, 14.226717235566793, 14.118636937315946, 14.435252405875401, 14.207373660676623, 14.20986093552465, 14.0625, 14.312142616885302, 14.374163319946454, 14.377104377104377, 14.061973728528123, 14.438188083032188, 14.051048774323982, 14.428655511645506, 13.986839885270793, 14.244870501177262, 14.316884860691506, 14.17309627641731, 14.177470954706179, 14.069081718618365, 14.338296804416931, 14.315718726371504, 14.193331653649114, 14.10460918478717, 14.152292806058057, 14.134631525935873, 14.182368775235531, 14.213454729387962, 14.082611255993942, 14.218566392479437, 14.178790682028424, 14.158399192870355, 14.241173000758407, 14.301356017855637, 14.094468300075777, 14.196908602150538, 14.119029631495007, 14.33860652978795, 14.38511191214687, 14.28691486679553]\n",
      "epoch_loss=26.454340350060235\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import copy\n",
    "import numpy as np\n",
    "# import torchmetrics\n",
    "import logging\n",
    "import util.misc as utils\n",
    "\n",
    "num_classes=54\n",
    "num_epochs = 100\n",
    "device = 'cuda:0'\n",
    "# model_rcnn = model_rcnn.to(device)\n",
    "model=PipelineModel().to(device)\n",
    "\n",
    "# model = models.vgg16(pretrained=True).to(device)\n",
    "# num_ftrs = model.classifier[6].in_features\n",
    "# model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# model = models.resnet50(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
    "# mainmodel  = mainNetwork(model_rcnn,model)\n",
    "\n",
    "# outputs_metric = []\n",
    "# targets_metric = []\n",
    "# result_metric = {}\n",
    "# def epoch_reset():\n",
    "#   outputs_metric = []\n",
    "#   targets_metric = []\n",
    "#   result_metric = {}\n",
    "#   for metric in epoch_metrics:\n",
    "#       metric.reset()\n",
    "# info = {}\n",
    "# def batch_reset():\n",
    "#   info = {}\n",
    "#   for metric in batch_metrics:\n",
    "#       metric.reset()\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# def cross_entropy_one_hot(input, target):\n",
    "#   _, one_hot_labels = target.max(dim=1)\n",
    "#   # _, one_hot_input = input.max(dim=0)\n",
    "#   # tmp=torch.greater(target, 0.6)\n",
    "#   # one_hot_labels=F.one_hot(tmp)\n",
    "#   # print(one_hot_labels)\n",
    "#   print(input)\n",
    "#   # _, one_hot_input = input.max(dim=1)\n",
    "\n",
    "#   return nn.CrossEntropyLoss()(input, one_hot_labels)\n",
    "\n",
    "weight=[1, 4.814957594448728, 5.156734693877551, 5.057831325301205, 4.679216867469879, 5.558260869565218, 4.653673163418291, 6.329446064139941, 4.873831775700935, 8.963011889035666, 8.976190476190476, 11.144927536231885, 8.807542262678803, 12.372340425531915, 12.07105719237435, 11.164516129032258, 10.839874411302983, 12.762773722627736, 15.948314606741572, 14.423312883435583, 16.14090909090909, 15.289416846652268, 15.254310344827585, 17.761194029850746, 18.239795918367346, 15.467248908296943, 21.446428571428573, 19.89196675900277, 18.388174807197945, 17.086330935251798, 22.642633228840126, 22.71698113207547, 23.566775244299674, 23.173076923076923, 18.239795918367346, 22.422360248447205, 24.308724832214764, 24.74061433447099, 22.06422018348624, 26.727941176470587, 24.393939393939394, 25.096885813148788, 23.973509933774835, 25.278745644599304, 28.00769230769231, 28.8102766798419, 26.626373626373628, 28.11969111969112, 32.22466960352423, 26.32608695652174, 30.165289256198346, 29.658536585365855, 30.165289256198346, 35.43478260869565]\n",
    "weight=torch.as_tensor(weight)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weight.to(device))\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     params=model.parameters(),\n",
    "#     lr=0.001,\n",
    "#     betas=(0.9, 0.999),\n",
    "#     eps=1e-08,\n",
    "#     weight_decay=0, #  weight_decay=args.weight_decay\n",
    "#     amsgrad=False,\n",
    "# )\n",
    "# # optimizer = torch.optim.AdamW(\n",
    "# #     params=model.parameters(),\n",
    "# #     lr=args.lr,\n",
    "# #     weight_decay=args.weight_decay)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.lr_drop)\n",
    "\n",
    "# best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "best_fscore=0\n",
    "f_score_train=[]\n",
    "f_score_test=[]\n",
    "\n",
    "# batch_metrics=[AccuracyThresh(thresh=0.5)]\n",
    "# epoch_metrics=[AUC(task_type='binary', average='micro'), F1Score(task_type='binary', average='micro')]\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "  # train_acc = 0.0\n",
    "\n",
    "  for phase in ['train', 'val']:\n",
    "\n",
    "    # outputs_metric = []\n",
    "    # targets_metric = []\n",
    "    # result_metric = {}\n",
    "    # for metric in epoch_metrics:\n",
    "    #     metric.reset()\n",
    "\n",
    "    # model_rcnn.eval()\n",
    "    if phase == 'train':\n",
    "      model.train()\n",
    "    else:\n",
    "      model.eval()\n",
    "    \n",
    "    all_batchs_loss=0\n",
    "    all_batchs_corrects=0\n",
    "    all_batchs_acc=0\n",
    "    all_batchs_prec = 0\n",
    "    all_batchs_recall=0\n",
    "    all_batchs_fscore=0\n",
    "    counter=0\n",
    "\n",
    "\n",
    "    losses = AverageMeter('Loss', ':.2e')\n",
    "    bitmap_accuracy = AverageMeter('Accuracy@Bitmap', ':4.2f')\n",
    "    bitmap_precision = AverageMeter('Precision@Bitmap', ':4.2f')\n",
    "    bitmap_recall = AverageMeter('Recall@Bitmap', ':4.2f')\n",
    "\n",
    "    short_answer_precision_bitmap_class = bitmap_precision_recall_class(num_classes=54, average=True)\n",
    "\n",
    "\n",
    "    progress = ProgressMeter(\n",
    "        len(train_dataset),\n",
    "        [\n",
    "            losses,\n",
    "            bitmap_accuracy, bitmap_precision, bitmap_recall, short_answer_precision_bitmap_class#\n",
    "        ],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "\n",
    "\n",
    "    i=0\n",
    "    \n",
    "    for data_batch in dataloader[phase]:\n",
    "      # print('*******************')\n",
    "\n",
    "      \n",
    "      questionID, questions, gt_scene_graphs, gt_scene_graphs_concept, programs, full_answers, short_answer_label, types, short_answer_bitmap, image_id, img = data_batch\n",
    "      \n",
    "      imgs= torch.stack(img)\n",
    "      \n",
    "\n",
    "      del questionID\n",
    "      del img\n",
    "      questions, gt_scene_graphs, gt_scene_graphs_concept, programs, full_answers, short_answer_label, short_answer_bitmap, imgs = [\n",
    "          datum.to(device=cuda, non_blocking=True) for datum in [\n",
    "              questions, gt_scene_graphs, gt_scene_graphs_concept, programs, full_answers, short_answer_label, short_answer_bitmap, imgs\n",
    "          ]\n",
    "      ]\n",
    "      \n",
    "      \n",
    "      this_batch_size = questions.size(1)\n",
    "      i+=1\n",
    "\n",
    "      # info = {}\n",
    "      # for metric in batch_metrics:\n",
    "      #     metric.reset()\n",
    "      \n",
    "\n",
    "      # labels_unique = set(labels)\n",
    "      # keys = {key: value for key, value in zip(labels_unique, range(len(labels_unique)))}\n",
    "      # labels_onehot = torch.zeros(size=(len(labels), len(keys)))\n",
    "      # for idx, label in enumerate(labels_onehot):\n",
    "      #   labels_onehot[idx][keys[label]] = 1\n",
    "\n",
    "      # inputs = inputs.to(device)\n",
    "      # labels = labels.to(device)\n",
    "      # one_hot=torch.nn.functional.one_hot(labels)\n",
    "  \n",
    "      # objects=torch.Tensor(objects).to(device)\n",
    "      programs_input = programs[:-1]\n",
    "      full_answers_input = full_answers[:-1]\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      with torch.set_grad_enabled(phase == 'train'):\n",
    "        # outputs = model(imgs.cuda())\n",
    "        outputs = model(questions.cuda(), gt_scene_graphs.cuda(), gt_scene_graphs_concept.cuda(), programs_input.cuda(), full_answers_input.cuda(), imgs.cuda(), image_id, phase)\n",
    "        # labels=labels.float()\n",
    "        # print(f'**********{objects.shape}')\n",
    "        # print(outputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # _, preds = outputs.max(dim=1)\n",
    "        # print(f'**********{outputs}')\n",
    "        # print(f'**********{preds}')\n",
    "        # print(f'**********{labels}')\n",
    "        # loss = criterion(outputs, labels.float())\n",
    "        loss = criterion(outputs, short_answer_bitmap.float().cuda())\n",
    "        # print(loss)\n",
    "        # loss = cross_entropy_one_hot(labels, outputs)\n",
    "        \n",
    "        if phase == 'train':\n",
    "          loss.backward()\n",
    "          # loss.backward(retain_graph=True)\n",
    "          optimizer.step()\n",
    "\n",
    "\n",
    "          \n",
    "      all_batchs_loss += loss.item() * imgs.size(0)\n",
    "      # all_batchs_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "      accuracy, accuracy_div, precision, precision_div, recall, recall_div = bitmap_precision_recall(outputs, short_answer_bitmap.cuda(), threshold=0.5)\n",
    "      losses.update(loss.item(), this_batch_size)\n",
    "      bitmap_accuracy.update(accuracy, accuracy_div)\n",
    "      bitmap_precision.update(precision, precision_div)\n",
    "      bitmap_recall.update(recall, recall_div)\n",
    "      short_answer_precision_bitmap_class.update(image_id, outputs, short_answer_bitmap.cuda(), threshold=0.5)\n",
    "      \n",
    "      # progress.display(i)\n",
    "\n",
    "\n",
    "      # print(f'loss={loss.item() * objects.size(0)}')\n",
    "      # print(labels.data.shape)\n",
    "      all_batchs_acc+=accuracy\n",
    "\n",
    "      my_out_dict=short_answer_precision_bitmap_class.calculate_result\n",
    "      # my_out='accuracy: {accuracy}, precision: {precision}, recall: {recall}, F_score: {F_score}, distb: {distb}'\n",
    "\n",
    "      all_batchs_fscore+=my_out_dict['F_score']\n",
    "      # all_batchs_corrects += accuracy(outputs,labels)\n",
    "      # print(f'batch_accuracy={all_batchs_corrects}')\n",
    "      # accuracy=torchmetrics.Accuracy()\n",
    "      # train_acc += (outputs.argmax(1) == labels).cpu().numpy().mean()\n",
    "      # acc_score=accuracy(preds.cpu().detach(), labels.cpu().detach())\n",
    "      # print('acc: {}'.format(acc_score))\n",
    "      # all_batchs_acc += acc_score\n",
    "      # all_batchs_acc += train_acc\n",
    "      # print(f'epoch_acc={train_acc}')\n",
    "      \n",
    "      # f1=torchmetrics.F1(num_classes=num_classes)\n",
    "      # fscore=f1(preds.cpu().detach(), labels.cpu().detach())\n",
    "      # print('F1: {}'.format(f1(preds.cpu().detach(), labels.cpu().detach())))\n",
    "\n",
    "      # all_batchs_fscore+=fscore\n",
    "      # print('Precision: {}'.format(precision_score(labels, preds, average=\"samples\")))\n",
    "      # print('Recall: {}'.format(recall_score(labels, preds, average=\"samples\")))\n",
    "\n",
    "      # prec,recall,fscore=precision_recall(outputs,labels)\n",
    "      # all_batchs_prec += prec\n",
    "      # all_batchs_recall+=recall\n",
    "      # all_batchs_fscore+=fscore\n",
    "      # print(f'batch_precision, recall, fscore={precision_recall(outputs,labels)}')\n",
    "      counter+=1\n",
    "\n",
    "      # if batch_metrics:\n",
    "      #   for metric in batch_metrics:\n",
    "      #     metric(logits = outputs,target = labels)\n",
    "      #     info[metric.name()] = metric.value()\n",
    "      #     print(f'batch_metric_name={metric.name()}, info_metric_name={info[metric.name()]}')\n",
    "\n",
    "      # outputs_metric.append(outputs.cpu().detach())\n",
    "      # targets_metric.append(labels.cpu().detach())\n",
    "      # if epoch_metrics:\n",
    "      #   for metric in epoch_metrics:\n",
    "      #     metric(logits=torch.cat(outputs_metric, dim =0).cpu().detach(), target=torch.cat(targets_metric, dim =0).cpu().detach())\n",
    "      #     value = metric.value()\n",
    "      #     if value:\n",
    "      #       result_metric[f'valid_{metric.name()}'] = value\n",
    "      #       print(f'bbbbbbbepoch_metric_name={metric.name()}, info_metric_name={result_metric[f\"valid_{metric.name()}\"]}')\n",
    "      # print(f'acc={accuracy(outputs,labels)}')\n",
    "\n",
    "      # with torch.set_grad_enabled(phase == 'train'):\n",
    "      #   # img_embed=image_embed(inputs).to(device)\n",
    "      #   outputs = model(objects)\n",
    "      #   # outputs = mainmodel(inputs)\n",
    "      #   # img_embed=image_embed(inputs).to(device)\n",
    "      #   # print(outputs)\n",
    "      #   # outputs=np.argmax(outputs)\n",
    "      #   pred_labels=torch.argmax(outputs, dim=1)\n",
    "      #   pred_labels=torch.reshape(pred_labels,(batchsize,1))\n",
    "\n",
    "      #   # _, preds = torch.max(outputs, 1)\n",
    "      #   print(f'outputs{outputs}')\n",
    "      #   print(f'outputs{pred_labels}')\n",
    "      #   print(f'labels{labels}')\n",
    "      #   loss = criterion(pred_labes, labels)\n",
    "      #   if phase == 'train':\n",
    "      #     loss.backward()\n",
    "      #     optimizer.step()\n",
    "      # all_batchs_loss += loss.item() * inputs.size(0)\n",
    "      # all_batchs_corrects += torch.sum(pred_labes == labels.data)\n",
    "\n",
    "    if phase == 'train':\n",
    "      scheduler.step()\n",
    "\n",
    "    progress.display(this_batch_size)\n",
    "    my_out_dict=short_answer_precision_bitmap_class.calculate_result\n",
    "    if phase=='train':\n",
    "      # my_out='accuracy: {accuracy}, precision: {precision}, recall: {recall}, F_score: {F_score}, distb: {distb}'\n",
    "      f_score_train.append(my_out_dict['F_score'])\n",
    "      print(f_score_train)\n",
    "    else:\n",
    "      # my_out='accuracy: {accuracy}, precision: {precision}, recall: {recall}, F_score: {F_score}, distb: {distb}'\n",
    "      f_score_test.append(my_out_dict['F_score'])\n",
    "      print(f_score_test)\n",
    "\n",
    "    epoch_loss = all_batchs_loss / counter\n",
    "    # print(f\"Testing accuracy: {train_acc/nb_batches}\")\n",
    "    print(f'epoch_loss={epoch_loss}')\n",
    "    # epoch_corrects = all_batchs_corrects.double()/ counter\n",
    "    # print(f'epoch_corrects={epoch_corrects}')\n",
    "    epoch_acc = all_batchs_acc / counter\n",
    "    epoch_fscore=all_batchs_fscore /counter\n",
    "    # print(f'epoch_acc={epoch_acc}')\n",
    "    # epoch_prec=all_batchs_prec / counter\n",
    "    # print(f'epoch_precision={epoch_prec}')\n",
    "    # epoch_recall=all_batchs_recall/ counter\n",
    "    # print(f'epoch_recall={epoch_recall}')\n",
    "    # epoch_fscore=all_batchs_fscore/ counter\n",
    "    # print(f'epoch_fscore={epoch_fscore}')\n",
    "    # epoch_prec=all_batchs_prec / counter\n",
    "    # print(f'epoch_precision={epoch_prec}')\n",
    "    # epoch_recall=all_batchs_recall/ counter\n",
    "    # print(f'epoch_recall={epoch_recall}')\n",
    "    # epoch_fscore=all_batchs_fscore/ counter\n",
    "    # print(f'epoch_fscore={epoch_fscore}')\n",
    "\n",
    "    # # epoch metric\n",
    "    # outputs_metric = torch.cat(outputs_metric, dim =0).cpu().detach()\n",
    "    # targets_metric = torch.cat(targets_metric, dim =0).cpu().detach()\n",
    "\n",
    "    # if epoch_metrics:\n",
    "    #   for metric in epoch_metrics:\n",
    "    #     metric(logits=outputs_metric, target=targets_metric)\n",
    "    #     value = metric.value()\n",
    "    #     if value:\n",
    "    #       result_metric[f'valid_{metric.name()}'] = value\n",
    "    #       print(f'********************epoch_metric_name={metric.name()}, info_metric_name={result_metric[f\"valid_{metric.name()}\"]}')\n",
    "    #       # print(result_metric[f'valid_{metric.name()}'])\n",
    "\n",
    "\n",
    "    if phase == 'val' and epoch_fscore > best_fscore:\n",
    "      best_acc = epoch_acc\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      torch.save(best_model_wts , 'best_model_weight.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKpUYyRLdqJ6"
   },
   "outputs": [],
   "source": [
    "!pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xpUMc0edOHw"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHrYv5ouejnU"
   },
   "outputs": [],
   "source": [
    "def get_total_parameters(model):\n",
    "  def helper_count_weight(shape):\n",
    "    total_product=1\n",
    "    for i in shape:\n",
    "      total_product*=i\n",
    "    return total_product\n",
    "  total_sum=0\n",
    "  for key, weights in model.state_dict().items():\n",
    "    total_sum+=helper_count_weight(weights.shape)\n",
    "  return total_sum\n",
    "\n",
    "get_total_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsH7snsff3w0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "label_number=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
    "labels=[\"unknown\",\"fashion\", \"family\", \"strength\", \"fun\", \"sex\", \"natural\", \"comfort\", \"delicious\", \"violence\", \"health\", \"speed\", \"energy\", \"love\", \"entertainment\", \"adventure\", \"vacation\", \"art\", \"travel\", \"beauty\", \"danger\", \"nature\", \"power\", \"sports\", \"happy\", \"freedom\", \"variety\", \"environment\", \"technology\", \"protection\", \"sexy\", \"happiness\", \"party\", \"youth\", \"fitness\", \"safety\", \"death\", \"clean\", \"animal cruelty\", \"relaxation\", \"hot\", \"excitement\", \"healthy\", \"class\", \"christmas\", \"alcohol\", \"strong\", \"injury\", \"hunger\", \"desire\", \"food\", \"humor\", \"refreshing\", \"smoking\"]\n",
    "SKG-Sym=[0, 28.834355828220858, 31.346578366445915, 36.462093862815884, 0.0, 9.049773755656108, 0.0, 26.353790613718413, 0.0, 0.0, 21.451104100946374, 8.294930875576037, 0.0, 19.53290870488323, 14.960629921259844, 34.13333333333333, 20.792079207920793, 16.447368421052634, 22.69503546099291, 8.849557522123893, 0.0, 9.523809523809524, 13.471502590673575, 11.416490486257928, 15.65217391304348, 0.0, 12.738853503184714, 10.476190476190476, 0.0, 14.207650273224044, 7.894736842105263, 16.49484536082474, 13.513513513513514, 7.633587786259542, 0.0, 22.439024390243905, 3.389830508474576, 7.792207792207792, 2.73972602739726, 17.00404858299595, 10.526315789473683, 7.361963190184049, 16.56804733727811, 3.508771929824561, 7.194244604316546, 8.333333333333332, 13.270142180094787, 8.148148148148149, 4.761904761904762, 11.678832116788321, 20.64516129032258, 1.7937219730941705, 2.9197080291970803, 5.691056910569105]\n",
    "# attention_based_fusion=[0, 32.57328990228013, 32.743362831858406, 35.16483516483517, 0.5025125628140703, 10.81081081081081, 0.0, 28.782287822878228, 0.0, 4.545454545454546, 22.591362126245848, 8.372093023255815, 2.0, 23.17596566523605, 14.345991561181433, 29.05027932960894, 20.0, 15.22491349480969, 22.064056939501782, 5.0, 4.444444444444445, 9.433962264150944, 11.282051282051283, 13.333333333333334, 17.445482866043612, 0.0, 9.94475138121547, 12.745098039215685, 0.0, 12.941176470588237, 8.235294117647058, 16.129032258064516, 13.008130081300814, 9.022556390977442, 10.714285714285714, 25.0, 5.9880239520958085, 8.968609865470851, 2.5, 20.425531914893615, 10.294117647058822, 6.382978723404255, 19.875776397515526, 6.015037593984962, 6.956521739130435, 8.275862068965518, 10.204081632653061, 6.545454545454546, 6.25, 9.75609756097561, 15.950920245398773, 5.333333333333334, 5.555555555555555, 3.6036036036036037]\n",
    "# attention_based_GCN=[0, 31.736526946107784, 30.76923076923077, 36.077057793345006, 0.0, 7.547169811320755, 0.0, 25.795053003533567, 0.0, 3.571428571428571, 23.78048780487805, 10.909090909090908, 0.0, 21.367521367521366, 15.062761506276152, 31.57894736842105, 21.67487684729064, 16.216216216216218, 25.874125874125873, 10.869565217391305, 0.0, 7.6923076923076925, 13.333333333333334, 11.45374449339207, 16.091954022988507, 0.0, 9.89010989010989, 11.224489795918368, 0.0, 18.6046511627907, 5.031446540880504, 16.113744075829384, 9.022556390977442, 4.958677685950414, 4.3478260869565215, 23.036649214659686, 5.347593582887701, 7.659574468085106, 0.0, 18.39080459770115, 8.695652173913043, 7.954545454545454, 14.857142857142858, 0.0, 6.787330316742081, 8.450704225352112, 12.962962962962962, 6.177606177606178, 5.714285714285714, 10.526315789473683, 15.204678362573098, 2.209944751381215, 2.898550724637681, 3.8095238095238098]\n",
    "ASKG-Sym=[0, 28.57142857142857, 31.308411214953267, 38.02559414990859, 1.0025062656641603, 12.612612612612612, 0.0, 28.735632183908045, 0.0, 2.380952380952381, 22.145328719723185, 9.852216748768473, 1.9607843137254901, 22.90748898678414, 15.454545454545453, 36.118598382749326, 19.35483870967742, 16.541353383458645, 20.618556701030926, 8.547008547008547, 4.597701149425287, 11.11111111111111, 16.75977653631285, 16.75392670157068, 18.666666666666668, 0.0, 8.235294117647058, 12.5, 0.0, 16.216216216216218, 10.38961038961039, 14.084507042253522, 6.0606060606060606, 9.45945945945946, 3.7735849056603774, 22.988505747126435, 1.3071895424836601, 9.950248756218906, 0.0, 16.736401673640167, 9.523809523809524, 3.6809815950920246, 15.286624203821656, 3.8095238095238098, 7.242339832869081, 9.395973154362416, 12.444444444444445, 5.303030303030303, 4.5662100456621, 9.79020979020979, 20.253164556962027, 4.878048780487805, 13.071895424836603, 4.145077720207254]\n",
    "VGG=[0, 30.519480519480517, 38.47780126849894, 35.08771929824561, 3.3653846153846154, 21.92691029900332, 0.0, 29.268292682926827, 0.0, 8.835341365461847, 19.662921348314608, 8.832807570977918, 9.230769230769232, 24.03628117913832, 16.666666666666664, 27.906976744186046, 25.0, 17.61006289308176, 24.46043165467626, 9.75609756097561, 2.1739130434782608, 7.659574468085106, 9.950248756218906, 13.092550790067719, 13.707165109034266, 18.181818181818183, 11.353711790393014, 15.0, 0.0, 14.285714285714285, 11.926605504587156, 15.52511415525114, 10.975609756097562, 8.695652173913043, 3.278688524590164, 25.49019607843137, 11.483253588516746, 8.88888888888889, 8.333333333333332, 14.166666666666666, 9.523809523809524, 4.524886877828054, 18.681318681318682, 8.780487804878048, 9.00900900900901, 9.278350515463918, 16.08040201005025, 4.651162790697675, 4.444444444444445, 14.193548387096774, 19.54022988505747, 6.2015503875969, 1.4705882352941175, 8.835341365461847]\n",
    "Resnet=[0, 27.312775330396477, 34.146341463414636, 16.292134831460675, 0.0, 10.92896174863388, 0.0, 25.0, 0.0, 0.0, 21.01694915254237, 8.588957055214724, 0.0, 24.083769633507853, 12.345679012345679, 9.486166007905137, 23.076923076923077, 15.444015444015443, 27.43362831858407, 10.526315789473683, 0.0, 2.083333333333333, 4.724409448818897, 11.76470588235294, 14.5748987854251, 4.3478260869565215, 2.5, 20.8, 0.0, 3.389830508474576, 16.49484536082474, 16.184971098265898, 7.5, 7.4074074074074066, 0.0, 32.55813953488372, 4.938271604938271, 8.98876404494382, 0.0, 15.53398058252427, 8.98876404494382, 4.0, 15.748031496062993, 2.7027027027027026, 10.32258064516129, 8.19672131147541, 17.5, 6.015037593984962, 0.0, 21.875, 28.235294117647058, 3.571428571428571, 0.0, 7.4074074074074066]\n",
    "micro_fscore_dict={'labels':labels, 'label_number': label_number,'SKG-Sym':SKG-Sym, 'ASKG-Sym':ASKG-Sym, 'VGG':VGG, 'Resnet':Resnet}\n",
    "df=pd.DataFrame(data=micro_fscore_dict)\n",
    "# df['label number'].sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tm_EXZnkjgwk"
   },
   "outputs": [],
   "source": [
    "VGG=[5.4631466503891355, 11.088830960497292, 13.071191309812372, 13.372933055065019, 13.636704963580385, 14.32979604124332, 14.551708666716518, 14.631943399066687, 14.529787550141139, 14.602614955193184, 14.682685929092651, 14.646390078251882, 14.838235294117647, 14.740393077148724, 14.577817005001469, 14.78753958317991, 14.812629094128061, 14.561467889908258, 14.741474147414742, 14.657071522984285, 14.670504021843406, 14.62767916329086, 14.866553929858098, 14.911312283800692, 14.698124267291911, 14.653523613358836, 14.624098867147271, 14.7968910397419, 14.817539729252504, 14.72913616398243, 14.561751524502242, 14.692675745307325, 14.873720639128194, 14.826800029418255, 14.849222148492222, 14.707397865292602, 14.8583174276905, 14.689265536723163, 14.655299132735559, 14.837144327622969, 14.829512051734275, 14.670394349617421, 14.828449418347814, 14.58547322083639, 14.640253332351426, 14.623056614843064]\n",
    "# ResNet=[0.04008819402685909, 1.9528371407516583, 6.992592592592592, 10.10704505850137, 11.618163288415808, 12.025460331893612, 12.347090431004917, 12.502862376917792, 12.771219786396854, 12.623097582811102, 12.467995101859067, 12.523676880222842, 12.855404358889258, 12.801402893467777, 12.738575635292834, 12.77292576419214, 12.663755458515283, 12.784684783804598, 12.421677476091018, 12.524106636415203, 12.632508833922262, 12.567366127737644, 12.346226310539732, 12.942477876106196, 12.725274725274724, 12.690355329949238, 13.021923543020822, 12.785588752196835, 12.493102306588677, 12.494451841988461]\n",
    "ResNet=[0.040096230954290296, 2.101313320825516, 7.0289518501316, 9.961880559085133, 11.768699784994908, 11.819342853825612, 11.779621945597048, 12.101109458995769, 12.03922894825837, 12.242152466367713, 12.183312690012386, 12.10012347064766, 12.239874692324905, 12.171016102165463, 12.283567461613853, 12.355721666483456, 12.121212121212121, 12.29372023479898, 12.424142116297032, 12.235398426244043, 12.361400812383357, 12.090118224403302, 12.23792160437557, 12.022104432164205, 12.36266785040506, 12.185197404596943, 12.153088630259624, 12.00796107916851, 12.366178719685383, 12.387436854820997, 12.189110463813577, 12.087171422152325, 12.307013674459638, 12.440295267042988, 12.238219895287958, 12.240263426819576, 12.476578860354898, 12.409875464277912, 12.371362177713843, 11.915673693858846, 12.315601251676352, 12.353998203054807, 12.13337794134047, 12.129173508483854]\n",
    "attention_based_fusion=[2.689941336385749, 10.103482808501168, 11.417850442240686, 12.592369175086715, 12.62135922330097, 13.851544039762079, 14.438459683254282, 14.175806187592077, 14.162512857029826, 14.387211367673181, 14.510219037537661, 14.311328443357782, 14.468924695823743, 14.386367360314601, 14.263413030975268, 14.324302201849882, 14.391083428946075, 14.592204389125452, 14.45290121941239, 14.424569141550272, 14.22710863144076, 14.235400114669506, 14.364097944476292, 14.503942181340342, 14.42299794661191, 14.15001637733377, 14.428594851615017, 14.365274365274367, 14.479934479934482, 14.451718494271686, 14.38496117695137, 14.517576054155452, 14.48179501931454, 14.316204235757676, 14.436040776060507, 14.3571252970581, 14.36870959823255, 14.389784726201196, 14.510575504181014, 14.418832761157429, 14.443988510463685]\n",
    "attention_graph=[1.1309264897781643, 8.40502978160159, 11.350902676903923, 12.110972790325448, 11.750862880451836, 13.410788381742739, 14.149298347587811, 13.663903061224488, 13.90131011218326, 13.726575472444058, 13.836175834734565, 13.962776579599009, 14.042926673581743, 14.01263696712789, 13.98166600239139, 14.089894803952822, 14.088110658031502, 13.966123362096516, 13.971291866028709, 13.863600063887557, 14.082707967427751, 13.94939141575913, 13.926776740847094, 14.003676764447286, 14.045167983401166, 13.792552341377656, 14.12722483837497, 14.093959731543624, 13.982102908277405, 14.092617771734783, 14.070753961901714, 13.9116593712694, 14.032014016086643]\n",
    "ASKG-Sym=[2.5279054497701905, 10.766778820612714, 11.8916505432356, 13.601208996355233, 13.224608428871306, 14.269823613538854, 14.326321773735076, 14.077514413837283, 14.586922635162852, 14.05925802971201, 14.601585314977056, 14.412915037030874, 14.224964562661551, 14.456421826690063, 14.389328887036266, 14.4258995219324, 14.688887027887112, 14.47214321566003, 14.597931264597932, 14.488874017065417, 14.809249519993323, 14.711297071129707, 14.540880503144654, 14.474123539232053, 14.71521630198764, 14.633737965676016, 14.531132154529455, 14.621059691482227, 14.485981308411214, 14.570090331214452, 14.407487882333278, 14.645155897350163, 14.657328664332168, 14.438324152896008, 14.622326203208555, 14.42387860596965, 14.597931264597932, 14.566994827298515, 14.610878661087867, 14.869144857476247, 14.508891474156558, 14.645118293902032, 14.532122323139737, 14.69557964970809]\n",
    "SKG-Sym=[2.092569604539812, 6.7872878972532105, 10.16358050319688, 11.852528945764778, 12.03296263701096, 13.179678623600067, 13.526030022357075, 13.404782852115494, 13.827639124464906, 13.69753922115155, 13.889111128890312, 13.687061822817082, 13.821333975439442, 13.81957773512476, 13.759566326530612, 13.894434240996567, 13.77326835503715, 13.809637976504435, 13.717836373775194, 13.924151696606787, 13.730818414322252, 13.819334389857369, 13.913459239780062, 13.682284623339433, 13.995845981786228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFsyks9pNs-D"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# plotting the line points\n",
    "plt.plot(range(len(VGG)), VGG, label = \"VGG\")\n",
    "plt.plot(range(len(ResNet)), ResNet, label = \"ResNet\")\n",
    " \n",
    "plt.plot(range(len(attention_based_fusion)), attention_based_fusion, label = \"attention-based fusion\")\n",
    "plt.plot(range(len(attention_graph)), attention_graph, label = \"attention-based GCN\")\n",
    "plt.plot(range(len(ASKG-Sym)), ASKG-Sym, label = \"ASKG-Sym\")\n",
    "plt.plot(range(len(SKG-Sym)), SKG-Sym, label = \"SKG-Sym\")\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('Epoch')\n",
    "# naming the y axis\n",
    "plt.ylabel('F-Score')\n",
    "# giving a title to my graph\n",
    "plt.title('F-Score')\n",
    " \n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNee2XSPqekF"
   },
   "outputs": [],
   "source": [
    "#relations_to_keep = ['antithesis', 'background', 'circumstance', 'concession', 'condition', 'elaboration', 'enablement', 'evaluation', 'interpretation', 'justify', 'motivation', 'cause', 'result', 'purpose', 'restatement', ''summary', 'solutionhood', 'joint', 'list', 'sequence' ]\n",
    "labels=['unknown', 'natural', 'sex', 'nature', 'danger', 'fun', 'violence', 'beauty', 'death', 'health', 'adventure', 'power', 'love', 'sexy', 'sports', 'environment', 'speed', 'fashion', 'food', 'energy', 'injury', 'strength', 'safety', 'youth', 'travel', 'hot', 'entertainment', 'technology', 'smoking', 'family', 'excitement', 'healthy', 'relaxation', 'art', 'christmas', 'refreshing', 'happiness', 'fitness', 'protection', 'delicious', 'clean', 'freedom', 'vacation', 'comfort', 'desire', 'variety', 'hunger', 'strong', 'humor', 'party', 'alcohol', 'happy', 'animal cruelty', 'class']\n",
    "labels_to_keep=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYLN9OBMqieQ"
   },
   "outputs": [],
   "source": [
    "# distb=[0.0000, 0.0275, 0.0332, 0.0354, 0.0291, 0.0343, 0.0162, 0.0346, 0.0187,\n",
    "#         0.0373, 0.0253, 0.0242, 0.0189, 0.0362, 0.0214, 0.0255, 0.0195, 0.0272,\n",
    "#         0.0236, 0.0192, 0.0178, 0.0220, 0.0242, 0.0181, 0.0184, 0.0115, 0.0209,\n",
    "#         0.0107, 0.0135, 0.0129, 0.0157, 0.0143, 0.0102, 0.0162, 0.0071, 0.0126,\n",
    "#         0.0165, 0.0121, 0.0165, 0.0187, 0.0124, 0.0159, 0.0110, 0.0118, 0.0178,\n",
    "#         0.0140, 0.0135, 0.0148, 0.0121, 0.0137, 0.0121, 0.0124, 0.0085, 0.0129]#multi\n",
    "# distb=[0.0000, 0.0161, 0.0100, 0.0141, 0.0120, 0.0100, 0.0070, 0.0110, 0.0030,\n",
    "#         0.0030, 0.0040, 0.0000, 0.0100, 0.0030, 0.0060, 0.0010, 0.0080, 0.0020,\n",
    "#         0.0010, 0.0010, 0.0000, 0.0000, 0.0000, 0.0020, 0.0000, 0.0000, 0.0000,\n",
    "#         0.0020, 0.0000, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0010,\n",
    "#         0.0000, 0.0000, 0.0010, 0.0020, 0.0000, 0.0000, 0.0010, 0.0000, 0.0000,\n",
    "#         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000, 0.0020, 0.0000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfXWbLh7WPmn"
   },
   "outputs": [],
   "source": [
    "train=[0, 612, 579, 633, 496, 736, 164, 592, 234, 446, 467, 384, 325, 351, 368, 222, 307, 339, 314, 303, 144, 293, 233, 241, 253, 171, 249, 252, 54, 212, 236, 222, 178, 196, 131, 185, 185, 186, 164, 192, 172, 177, 168, 177, 179, 181, 180, 186, 164, 160, 137, 169, 17, 140]\n",
    "test=[0, 164, 168, 260, 397, 163, 366, 129, 387, 148, 87, 102, 98, 86, 51, 229, 65, 67, 73, 50, 166, 54, 101, 66, 60, 43, 51, 35, 190, 50, 42, 43, 34, 40, 37, 50, 44, 31, 72, 39, 45, 48, 38, 40, 42, 20, 44, 42, 46, 33, 45, 30, 135, 34]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbbvyFtqqkL8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# mask = [True if rel in labels_to_keep else False for rel in labels] \n",
    "train=np.array(train)\n",
    "# print(distb[mask])\n",
    "relations = np.array(labels)\n",
    "\n",
    "ind = np.arange(0,len(train),1)\n",
    "width = 0.35 \n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "# f_bar=plt.barh(ind, distb[mask], width, label='multilabel')\n",
    "# t_bar=plt.barh(ind + width, center_truth[mask], width, label='truth')\n",
    "f_bar=plt.barh(ind, train, width, label='train')\n",
    "t_bar=plt.barh(ind + width, test, width, label='test')\n",
    "# autolabel(f_bar)\n",
    "# autolabel(t_bar)\n",
    "\n",
    "plt.xlabel('distribution')\n",
    "plt.ylabel('labels')\n",
    "\n",
    "plt.yticks(ind + width / 2, labels)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb0nZAQmcvme"
   },
   "outputs": [],
   "source": [
    "# with open(SCENEGRAPHS / 'train_sceneGraphs.json') as f:\n",
    "\n",
    "def to_molecule(data, imageid, sg_json_data):\n",
    "    # ATOM_MAP = ['C', 'O', 'Cl', 'H', 'N', 'F',\n",
    "    #             'Br', 'S', 'P', 'I', 'Na', 'K', 'Li', 'Ca']\n",
    "    sg_this = sg_json_data[imageid]\n",
    "    objIDs = sorted(sg_this['objects'].keys()) # str list(sorted)\n",
    "\n",
    "    g = to_networkx(data, node_attrs=['x'])\n",
    "    for u, d in g.nodes(data=True):\n",
    "        d['name'] = sg_this['objects'][objIDs[u]]['name']+ '_' + objIDs[u]\n",
    "        d['nid'] = objIDs[u]\n",
    "        del d['x']\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hu0ECw_mkUcr"
   },
   "outputs": [],
   "source": [
    "!pip install -q captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHi8gl877POv"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "\n",
    "def draw_molecule(g, sg_data, sg_json_data, imageid, edge_mask=None, draw_edge_labels=True):\n",
    "  \n",
    "    thresh=0.1\n",
    "    g = g.copy().to_undirected()\n",
    "    node_labels = {}\n",
    "    for u, data in g.nodes(data=True):\n",
    "        node_labels[u] = data['name']\n",
    "    pos = nx.circular_layout(g)\n",
    "    # pos = nx.spring_layout(g, pos=pos)\n",
    "    # pos = nx.spring_layout(g)\n",
    "    if edge_mask is None:\n",
    "        edge_color = 'black'\n",
    "        widths = None\n",
    "    else:\n",
    "        edge_color = ['black' if edge_mask[(u, v)]>thresh else 'white' for u, v in g.edges()]\n",
    "        widths = [1 for x in edge_color]\n",
    "        # print(f'with={widths}')\n",
    "        # print(f'edgecolor={edge_color}')\n",
    "    nx.draw(g, pos=pos,labels=node_labels, width=widths,\n",
    "            edge_color=edge_color, edge_cmap=plt.cm.Blues,\n",
    "            node_color='azure')\n",
    "    \n",
    "    if draw_edge_labels and edge_mask is not None:\n",
    "        edge_labels = {k: ('%.2f' % v) for k, v in edge_mask.items()}  \n",
    "        sg_this=sg_json_data[imageid]\n",
    "        objIDs = sorted(sg_this['objects'].keys())\n",
    "        # objIDs=sg_this['objects'].keys() \n",
    "\n",
    "        # root='/content/drive/My Drive/Symbolic_image/SKG-Sym/data'\n",
    "        # if os.path.exists(os.path.join(root,'train_images/'+imageid)):\n",
    "        #   img = cv2.imread(os.path.join(root,'train_images/'+imageid))\n",
    "        # elif os.path.exists(os.path.join(root,'test_images/'+imageid)):\n",
    "        #   img = cv2.imread(os.path.join(root,'test_images/'+imageid))\n",
    "\n",
    "        # img_result = img.copy()\n",
    "\n",
    "\n",
    "        for edgkey, edgval in edge_mask.items():\n",
    "          if edgval<=thresh:\n",
    "            del edge_labels[edgkey]\n",
    "            continue\n",
    "          obj=sg_this['objects'][objIDs[edgkey[0]]]\n",
    "\n",
    "          # print(obj)        \n",
    "          # print('key0',objIDs[edgkey[0]])\n",
    "\n",
    "          # relations=[]\n",
    "          # color=[0]*len( dist_label )\n",
    "          # dist_label = set(sg_this['objects'][obj]['name'] for obj in sg_this['objects'])\n",
    "          # for i, l in enumerate(dist_label):\n",
    "          #     if l in color:\n",
    "          #         continue\n",
    "          #     color[l] = (random() * 255., random() * 255, random() * 255)\n",
    "        \n",
    "\n",
    "          for rel in obj['relations']:\n",
    "            if rel['object']==objIDs[edgkey[1]]:\n",
    "              print(obj)        \n",
    "              print(\"key0\",objIDs[edgkey[0]]+sg_this['objects'][objIDs[edgkey[0]]]['name'])            \n",
    "              edge_labels[edgkey]=edge_labels[edgkey]+' '+rel['name']\n",
    "              print(rel['name']+edge_labels[edgkey])\n",
    "              print(\"key1\",objIDs[edgkey[1]]+sg_this['objects'][objIDs[edgkey[1]]]['name'])\n",
    "\n",
    "              # _,obj_key_s=sg_this['objects'][obj].items()\n",
    "              # print(obj_key_s['x'])\n",
    "\n",
    "              # x_crd_s=int(sg_this['objects'][obj]['x'])\n",
    "              # y_crd_s=int(sg_this['objects'][obj]['y'])\n",
    "              # h_crd_s=int(sg_this['objects'][obj]['h'])\n",
    "              # w_crd_s=int(sg_this['objects'][obj]['w'])\n",
    "              # x_crd_o=int(sg_this['objects'][sg_this['objects'][objIDs[edgkey[1]]]]['x'])\n",
    "              # y_crd_o=int(sg_this['objects'][sg_this['objects'][objIDs[edgkey[1]]]]['y'])\n",
    "              # h_crd_o=int(sg_this['objects'][sg_this['objects'][objIDs[edgkey[1]]]]['h'])\n",
    "              # w_crd_o=int(sg_this['objects'][sg_this['objects'][objIDs[edgkey[1]]]]['w'])\n",
    "              # cv2.rectangle(img_result, (int(sg_this['objects'][obj]['x']), int(sg_this['objects'][obj]['y'])), (int(sg_this['objects'][obj]['w']), int(sg_this['objects'][obj]['h'])), (0, 0, 255), 2)\n",
    "              # subj_center=[(x_crd_s+w_crd_s)/2, (y_crd_s+h_crd_s)/2]\n",
    "              # obj_center = [(x_crd_o+w_crd_o)/2, (y_crd_o+h_crd_o)/2]\n",
    "              # cv2.line(img_result, (int(subj_center[0]), int(subj_center[1])), (int(obj_center[0]), int(obj_center[1])), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "          obj=sg_this['objects'][objIDs[edgkey[1]]]\n",
    "\n",
    "          for rel in obj['relations']:\n",
    "            if rel['object']==objIDs[edgkey[0]]:\n",
    "              print(obj)\n",
    "              print(\"key0\",objIDs[edgkey[0]]+sg_this['objects'][objIDs[edgkey[0]]]['name'])\n",
    "              edge_labels[edgkey]=edge_labels[edgkey]+' '+rel['name']\n",
    "              print(rel['name']+edge_labels[edgkey])\n",
    "              print(\"key1\",objIDs[edgkey[1]]+sg_this['objects'][objIDs[edgkey[1]]]['name'])\n",
    "\n",
    "          for rel in obj['relations']:\n",
    "            if rel['object']!=objIDs[edgkey[0]] and rel['object']!=objIDs[edgkey[0]]:\n",
    "              print(\"????????????????????????\",obj)        \n",
    "              print(\"????????????????????????key0\",objIDs[edgkey[0]]+sg_this['objects'][objIDs[edgkey[0]]]['name'])\n",
    "              print(\"????????????????????????key1\",objIDs[edgkey[1]]+sg_this['objects'][objIDs[edgkey[1]]]['name'])\n",
    "\n",
    "        # print(f'edgelabel={edge_labels}') \n",
    "        nx.draw_networkx_edge_labels(g, pos, edge_labels=edge_labels,\n",
    "                                    font_color='red')\n",
    "        \n",
    "    plt.show()\n",
    "    # # cv2.imwrite('two_blobs_result.jpg',result)      \n",
    "\n",
    "    # # show thresh and result    \n",
    "    # cv2.imshow(\"bounding_box\", img_result)\n",
    "    # cv2.waitKey(0)\n",
    "    # # cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adB-09dvEtUD"
   },
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_mul \n",
    "def explain(data, graph_type):\n",
    "# questionID, questions, gt_scene_graphs, gt_scene_graphs_concept, programs, full_answers, short_answer_label, types, short_answer_bitmap, image_id, img = train_dataset[0]\n",
    "# data=gt_scene_graphs_concept\n",
    "# batch = torch.zeros(data.x.shape[0], dtype=int).to(device)\n",
    "# x_encoded,_,_=model.scene_graph_encoder(data)\n",
    "# x_encoded,_,_=model.scene_graph_encoder_concept(data)\n",
    "  if graph_type=='concept':\n",
    "    # from gqa_dataset_entry import GQA_gt_sg_feature_lookup_concept\n",
    "    # sg_vocab = GQA_gt_sg_feature_lookup_concept.SG_ENCODING_TEXT.vocab   \n",
    "    # sg_TEXT = GQA_gt_sg_feature_lookup_concept.SG_ENCODING_TEXT\n",
    "    model_weight=model.scene_graph_encoder_concept.scene_graph_encoding_layer.edge_model.edge_mlp[0].weight\n",
    "    # model_weight=model.scene_graph_encoder.scene_graph_encoding_layer.node_model.edge_mlp_1[0].weight\n",
    "  else:\n",
    "    # from gqa_dataset_entry import GQA_gt_sg_feature_lookup\n",
    "    # sg_vocab = GQA_gt_sg_feature_lookup.SG_ENCODING_TEXT.vocab\n",
    "    # sg_TEXT = GQA_gt_sg_feature_lookup.SG_ENCODING_TEXT\n",
    "    model_weight=model.scene_graph_encoder.scene_graph_encoding_layer.edge_model.edge_mlp[0].weight\n",
    "    # model_weight=model.scene_graph_encoder.scene_graph_encoding_layer.node_model.edge_mlp_1[0].weight\n",
    "\n",
    "  # sg_emb_dim = 300 # 300d glove\n",
    "  # sg_pad_idx = sg_vocab.stoi[sg_TEXT.pad_token]\n",
    "  # sg_vocab_embedding=torch.nn.Embedding(len(sg_vocab), sg_emb_dim, padding_idx=sg_pad_idx)\n",
    "  # model.scene_graph_encoder.sg_vocab_embedding.weight()\n",
    "\n",
    "  x_embed     = model.scene_graph_encoder.sg_vocab_embedding.weight[data.x]\n",
    "  # print(x_embed)\n",
    "\n",
    "  x_embed_sum = torch.sum(input=x_embed.detach().cpu(), dim=-2, keepdim=False)\n",
    "\n",
    "  edge_attr_embed = model.scene_graph_encoder.sg_vocab_embedding.weight[data.edge_attr]\n",
    "\n",
    "  edge_attr_embed[data.added_sym_edge, :, :] *= -1\n",
    "\n",
    "  edge_attr_embed_sum   = torch.sum(input=edge_attr_embed.detach().cpu(), dim=-2, keepdim=False)\n",
    "  row, col= data.edge_index\n",
    "  # print(row[0])\n",
    "  print(\"<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\",data.edge_index.shape)\n",
    "  # print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>\", data.x.shape)\n",
    "  # print(edge_attr_embed_sum.shape)\n",
    "  # print(data.edge_index.shape)\n",
    "  row, col= data.edge_index\n",
    "  tmp=torch.cat([x_embed_sum[row], x_embed_sum[col], edge_attr_embed_sum], 1)\n",
    "  # print(tmp)\n",
    "  # tmp=torch.ones(tmp.shape)\n",
    "  # tmp=torch.ones(data.edge_index.shape[1],900)\n",
    "  # print(tmp.shape)\n",
    "  # print(model.scene_graph_encoder_concept.scene_graph_encoding_layer.edge_model.edge_mlp[0].weight.shape)\n",
    "  # tmp_weight=model.scene_graph_encoder_concept.scene_graph_encoding_layer.edge_model.edge_mlp[0].weight\n",
    "  # tmp_weight=tmp_weight.permute(1,0)\n",
    "  tmp_weight=torch.transpose(model_weight.detach().cpu(),0,1)\n",
    "  # print(tmp_weight.shape)\n",
    "  # tmp_weight=tmp_weight.t\n",
    "  # torch.transpose(tmp_weight,0,1)\n",
    "  # print(tmp_weight.shape)\n",
    "  tmp_mul=torch.matmul(tmp,tmp_weight)\n",
    "  # print(tmp_mul.shape)\n",
    "  output=torch.sum(tmp_mul, dim=-1)\n",
    "  # print(output)\n",
    "  # print(output.shape)\n",
    "  # scatter_mul(tmp,[1:900], out=model.scene_graph_encoder_concept.scene_graph_encoding_layer.edge_model.edge_mlp[0].weight)\n",
    "\n",
    "  vals, idx=output.topk(10, 0, True, True)\n",
    "\n",
    "  topk = torch.zeros(output.shape[0])\n",
    "  # print(topk.shape)\n",
    "  topk[idx.cpu()] = vals.cpu()\n",
    "  topkout=np.abs(topk.detach().numpy())\n",
    "  # print(topkout)\n",
    "  # topkout=np.abs(output.detach().numpy())\n",
    "  return topkout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXa0soBmpI9v"
   },
   "outputs": [],
   "source": [
    "import Constants\n",
    "ROOT_DIR = Constants.ROOT_DIR\n",
    "SCENEGRAPHS = ROOT_DIR.joinpath('sceneGraphs')\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# root='data/train_images/'\n",
    "\n",
    "label_dict={\"unknown\":0, \"fashion\": 17, \"family\": 29, \"strength\": 21, \"fun\": 5, \"sex\": 2, \"natural\": 1, \"comfort\": 43, \"delicious\": 39, \"violence\": 6, \"health\": 9, \"speed\": 16, \"energy\": 19, \"love\": 12, \"entertainment\": 26, \"adventure\": 10, \"vacation\": 42, \"art\": 33, \"travel\": 24, \"beauty\": 7, \"danger\": 4, \"nature\": 3, \"power\": 11, \"sports\": 14, \"happy\": 51, \"freedom\": 41, \"variety\": 45, \"environment\": 15, \"technology\": 27, \"protection\": 38, \"sexy\": 13, \"happiness\": 36, \"party\": 49, \"youth\": 23, \"fitness\": 37, \"safety\": 22, \"death\": 8, \"clean\": 40, \"animal cruelty\": 52, \"relaxation\": 32, \"hot\": 25, \"excitement\": 30, \"healthy\": 31, \"class\": 53, \"christmas\": 34, \"alcohol\": 50, \"strong\": 47, \"injury\": 20, \"hunger\": 46, \"desire\": 44, \"food\": 18, \"humor\": 48, \"refreshing\": 35, \"smoking\": 28}\n",
    "labels=[0]*(len(label_dict))\n",
    "for label in label_dict:\n",
    "  labels[label_dict[label]]=label\n",
    "# print(labels)\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def aggregate_edge_directions(edge_mask, data):\n",
    "    edge_mask_dict = defaultdict(float)\n",
    "    \n",
    "\n",
    "    for val, u, v in list(zip(edge_mask, *data.edge_index)):\n",
    "        u, v = u.item(), v.item()\n",
    "        if u > v:\n",
    "            u, v = v, u\n",
    "        edge_mask_dict[(u, v)] += val\n",
    "    return edge_mask_dict\n",
    "    \n",
    "\n",
    "# data = random.choice([t for t in test_dataset if not t.y.item()])\n",
    "with open(SCENEGRAPHS / 'val_sceneGraphs_concept.json') as f:\n",
    "  concept_json = dict(json.load(f))\n",
    "with open(SCENEGRAPHS / 'val_sceneGraphs.json') as f:\n",
    "  sg_json = dict(json.load(f))\n",
    "\n",
    "visited=[False]*len(val_dataset)\n",
    "for i, valdata in enumerate(val_dataset):\n",
    "  questionID, questions, gt_scene_graphs, gt_scene_graphs_concept, programs, full_answers, short_answer_label, types, short_answer_bitmap, image_id, img = valdata\n",
    "  label_true=[[], ['5/58825.jpg', '10/173173.png', '10/173139.png', '10/172571.png', '9/137779.jpg', '8/80808.jpg', '0/54450.jpg', '10/177249.png', '2/30082.jpg', '10/171140.png', '10/173460.png', '2/120202.jpg', '7/86527.jpg', '10/174037.png', '1/65311.jpg', '10/170299.png', '4/49524.jpg', '5/149005.jpg', '10/173379.png', '10/175756.png', '2/54442.jpg', '10/172374.png', '10/173461.png', '10/174576.png', '10/172570.png', '10/172270.png', '0/52490.jpg', '10/176131.png', '10/172151.png', '10/173862.png', '10/177370.png', '5/54655.jpg', '4/42234.jpg', '10/172520.png', '1/165201.jpg', '10/173268.png', '3/47503.jpg', '2/65392.jpg', '0/78390.jpg'], ['1/116201.jpg', '10/174440.png', '1/116301.jpg', '10/172119.png', '1/165241.jpg', '10/176262.png', '6/116456.jpg', '1/31641.jpg', '10/173199.png', '10/173071.png', '2/62072.jpg', '2/116472.jpg', '1/136311.jpg', '0/116550.jpg', '0/18670.jpg', '0/98560.jpg', '3/20843.jpg', '5/10845.jpg', '0/155920.jpg', '10/173145.png', '3/66253.jpg', '10/172255.png', '10/175330.png', '10/174699.png', '2/32852.jpg', '3/116483.jpg', '10/170191.png', '0/10510.jpg', '0/30030.jpg', '0/32670.jpg', '0/73170.jpg', '0/57500.jpg', '3/134043.jpg', '10/176058.png', '7/158737.jpg', '1/93051.jpg', '10/175803.png', '10/174680.png', '9/45989.jpg', '3/158853.jpg', '8/116548.jpg', '7/22777.jpg', '10/173500.png', '4/45934.jpg', '10/175121.png', '4/41384.jpg', '1/119481.jpg', '10/177955.png', '10/170037.png', '10/175877.png', '10/171043.png', '8/46188.jpg'], ['5/58825.jpg', '4/13184.jpg', '5/82575.jpg', '10/177391.png', '10/176487.png', '1/158991.jpg', '9/85739.jpg', '6/52506.jpg', '8/38428.jpg', '10/173687.png', '8/80808.jpg', '10/173244.png', '10/177627.png', '9/102919.jpg', '10/173621.png', '10/170857.png', '4/54134.jpg', '10/175743.png', '6/103376.jpg', '5/103085.jpg', '10/177145.png', '5/77865.jpg', '4/52414.jpg', '0/11270.jpg', '2/30082.jpg', '10/174734.png', '10/173601.png', '10/173503.png', '0/52830.jpg', '5/140425.jpg', '1/52501.jpg', '5/85745.jpg', '10/171956.png', '7/11057.jpg', '6/52486.jpg', '10/171942.png', '6/52476.jpg', '9/52399.jpg', '9/45879.jpg', '10/174163.png', '10/173960.png', '9/103389.jpg', '10/177327.png', '10/172468.png', '10/173623.png', '10/175084.png', '10/170299.png', '8/21628.jpg', '10/173634.png', '10/170274.png', '1/103021.jpg', '4/52604.jpg', '4/49524.jpg', '9/67549.jpg', '10/174793.png', '10/177968.png', '10/174416.png', '10/170706.png', '10/172374.png', '10/176772.png', '10/174136.png', '2/54492.jpg', '8/102878.jpg', '8/72298.jpg', '0/52620.jpg', '10/173744.png', '10/172117.png', '10/172018.png', '6/146156.jpg', '10/176490.png', '10/175809.png', '10/176808.png', '10/175303.png', '10/172270.png', '2/52652.jpg', '8/31538.jpg', '0/40450.jpg', '7/102907.jpg', '7/46007.jpg', '8/102978.jpg', '7/103127.jpg', '10/171479.png', '0/52440.jpg', '7/52477.jpg', '1/108211.jpg', '1/103191.jpg', '10/176541.png', '9/62899.jpg', '5/67305.jpg', '0/13220.jpg', '10/173038.png', '10/177294.png', '0/102870.jpg', '10/176050.png'], [], [], [], ['10/173522.png', '10/175043.png', '10/174220.png', '10/171936.png', '2/79032.jpg', '10/172119.png', '10/172043.png', '1/165241.jpg', '10/172921.png', '1/12011.jpg', '10/170842.png', '10/173890.png', '2/107982.jpg', '0/130290.jpg', '10/170407.png', '1/109311.jpg', '3/94853.jpg', '10/171832.png', '0/155920.jpg', '10/173291.png', '10/172560.png', '3/125853.jpg', '3/66253.jpg', '3/116253.jpg', '10/175330.png', '10/174699.png', '2/32852.jpg', '10/171924.png', '10/170670.png', '10/171326.png', '10/170119.png', '10/173020.png', '10/172581.png', '10/170004.png', '0/86120.jpg', '10/171330.png', '10/170584.png', '10/173435.png', '0/130330.jpg', '0/130270.jpg', '10/175432.png', '10/172229.png', '10/173186.png', '10/175803.png', '10/173184.png', '10/172640.png', '10/172427.png', '10/175924.png', '3/45883.jpg', '10/176388.png', '10/172686.png', '10/172497.png', '10/170112.png', '10/172097.png', '3/135043.jpg', '10/172174.png', '8/116548.jpg', '10/172920.png', '10/171456.png', '8/86558.jpg', '1/131611.jpg'], [], [], ['4/13184.jpg', '4/103064.jpg', '6/135796.jpg', '10/173703.png', '4/33754.jpg', '10/175215.png', '10/175148.png', '1/106801.jpg', '10/176714.png', '1/85751.jpg', '10/174623.png', '9/86039.jpg', '10/177853.png', '10/173816.png', '9/123499.jpg', '4/109194.jpg', '8/21628.jpg', '0/155150.jpg', '10/174172.png', '8/53638.jpg', '4/32694.jpg', '10/177532.png', '10/173437.png', '10/176791.png', '1/125221.jpg', '3/76853.jpg', '6/133736.jpg', '7/129067.jpg', '0/99730.jpg', '10/175724.png', '0/102870.jpg'], ['10/174437.png', '10/173816.png', '10/174892.png', '4/95744.jpg'], [], ['10/172660.png', '1/116201.jpg', '10/170073.png', '10/177618.png', '10/172119.png', '10/176733.png', '3/116223.jpg', '10/172921.png', '0/116440.jpg', '6/162606.jpg', '10/176302.png', '2/62072.jpg', '2/116472.jpg', '0/130290.jpg', '0/116550.jpg', '0/97420.jpg', '3/94853.jpg', '6/46076.jpg', '3/66253.jpg', '3/116253.jpg', '2/32852.jpg', '6/133906.jpg', '10/171326.png', '5/116475.jpg', '0/10510.jpg', '0/30030.jpg', '5/46845.jpg', '2/134832.jpg', '1/8991.jpg', '3/157223.jpg', '0/39600.jpg', '9/116329.jpg', '10/172272.png', '10/172229.png', '10/172449.png', '1/116231.jpg', '1/116241.jpg', '9/45989.jpg', '4/86204.jpg', '10/172920.png', '4/140334.jpg', '10/173500.png', '4/45934.jpg', '4/71924.jpg', '4/157444.jpg'], ['0/7420.jpg', '10/172473.png', '1/118051.jpg', '3/57213.jpg', '3/136483.jpg', '1/163451.jpg', '4/92294.jpg', '10/177406.png', '10/173850.png', '10/175994.png', '2/105752.jpg', '1/126691.jpg', '9/62759.jpg', '10/172310.png', '2/7032.jpg', '0/136350.jpg', '0/138450.jpg'], ['6/46216.jpg', '10/177391.png', '6/52506.jpg', '9/102889.jpg', '9/137779.jpg', '10/170857.png', '4/52514.jpg', '10/174734.png', '10/177897.png', '0/52830.jpg', '10/174163.png', '10/173960.png', '9/103389.jpg', '10/177327.png', '10/174240.png', '1/103021.jpg', '10/171600.png', '10/170107.png', '10/174793.png', '10/172363.png', '10/174416.png', '10/172015.png', '10/174136.png', '2/45852.jpg', '1/102931.jpg', '10/173744.png', '10/176421.png', '10/172018.png', '10/176808.png', '10/175303.png', '2/52652.jpg', '2/52612.jpg', '10/176645.png', '8/102978.jpg', '10/176662.png', '10/177325.png', '7/103127.jpg', '0/52440.jpg', '7/52477.jpg', '10/174720.png', '1/103191.jpg', '1/103281.jpg', '10/177701.png', '10/176390.png', '10/177918.png', '10/173524.png'], ['10/172590.png', '0/57780.jpg', '10/173044.png', '10/174437.png', '6/4156.jpg', '0/133700.jpg', '10/174892.png', '6/13366.jpg', '3/87403.jpg', '10/176132.png', '2/106282.jpg', '5/1105.jpg', '10/177699.png', '10/170192.png', '7/158967.jpg', '1/150151.jpg', '10/173178.png', '10/173590.png', '10/175724.png', '5/119145.jpg'], ['10/177217.png', '2/79032.jpg', '10/176691.png', '4/46574.jpg', '1/165241.jpg', '2/62072.jpg', '1/126861.jpg', '10/173156.png', '10/173046.png', '0/155920.jpg', '9/132089.jpg', '9/12419.jpg', '4/4774.jpg', '0/73170.jpg', '1/93051.jpg', '1/63541.jpg', '10/170038.png', '10/177947.png', '5/143915.jpg', '1/87861.jpg', '10/170037.png'], ['7/18957.jpg', '10/173371.png', '10/171994.png', '10/177529.png', '10/177595.png', '1/102001.jpg', '10/172752.png', '2/150402.jpg', '10/171195.png', '10/171443.png', '10/171323.png', '0/104490.jpg', '1/61061.jpg', '10/174625.png', '1/60881.jpg', '2/120202.jpg', '1/79021.jpg', '10/176539.png', '10/170565.png', '0/22610.jpg', '10/173930.png', '7/42477.jpg', '10/177830.png', '10/170644.png', '8/148948.jpg', '9/96249.jpg', '10/171299.png', '0/135240.jpg', '7/157977.jpg', '10/176253.png', '10/170218.png', '10/173928.png', '0/52540.jpg', '6/52426.jpg'], ['1/106691.jpg', '10/171526.png'], [], ['1/32161.jpg', '10/175994.png', '0/36990.jpg'], ['6/72486.jpg', '10/177380.png', '10/173671.png', '0/127560.jpg', '1/127521.jpg', '10/177306.png'], ['10/172660.png', '10/170073.png', '4/96214.jpg', '10/172575.png', '10/172043.png', '1/103971.jpg', '10/174905.png', '10/177934.png', '8/135238.jpg', '6/130136.jpg', '10/171628.png', '4/53644.jpg', '10/173046.png', '10/172560.png', '10/170376.png', '1/101101.jpg', '8/53958.jpg', '10/173231.png', '10/172581.png', '0/136620.jpg', '4/53724.jpg', '0/130330.jpg', '10/175432.png', '10/173184.png', '3/8413.jpg', '10/172497.png', '10/177024.png', '10/176384.png', '10/170488.png'], ['10/174536.png', '1/158991.jpg', '10/173244.png', '1/69411.jpg', '0/81770.jpg', '6/150016.jpg', '10/170395.png', '1/58201.jpg', '10/171942.png', '0/5690.jpg', '10/172490.png', '8/1538.jpg', '1/36391.jpg', '0/95790.jpg', '10/171045.png', '8/13658.jpg', '0/144700.jpg', '1/106061.jpg', '10/170572.png'], [], ['0/53180.jpg', '6/116316.jpg', '2/38672.jpg', '8/82888.jpg', '0/139220.jpg', '4/47234.jpg', '10/170973.png'], ['6/52936.jpg', '1/159251.jpg', '0/112230.jpg', '6/35376.jpg', '3/1633.jpg', '10/173951.png', '1/201.jpg', '10/172530.png', '10/173712.png', '6/1066.jpg'], [], ['10/173846.png', '10/173393.png', '0/104310.jpg', '1/135041.jpg', '10/175211.png', '10/173034.png'], ['10/172900.png', '10/175767.png', '10/174172.png', '10/173899.png'], ['8/80808.jpg', '5/20325.jpg', '10/171892.png', '10/171545.png', '10/170382.png', '10/173912.png', '10/170918.png', '6/54386.jpg', '10/172570.png', '10/172270.png', '10/172151.png', '10/173947.png', '10/172520.png', '10/173268.png', '5/47205.jpg', '4/52734.jpg', '0/78390.jpg'], ['1/149381.jpg', '4/44744.jpg'], ['0/155500.jpg', '4/41354.jpg'], [], ['6/116176.jpg', '1/158571.jpg', '8/9998.jpg', '10/176475.png', '4/29344.jpg', '10/175162.png', '10/174619.png'], ['10/170407.png', '5/14075.jpg', '10/172565.png', '3/71943.jpg'], ['5/121175.jpg', '7/92687.jpg', '8/106718.jpg', '10/174929.png', '1/142241.jpg', '10/174640.png', '2/92592.jpg', '8/105888.jpg'], [], ['4/67534.jpg', '10/171923.png', '10/172122.png', '10/170923.png', '10/172434.png', '5/149005.jpg', '10/170228.png', '10/173930.png', '10/172024.png', '10/173090.png', '10/177394.png', '2/22852.jpg', '10/172373.png', '10/172569.png', '10/173840.png', '9/6929.jpg', '10/176779.png', '1/165201.jpg', '9/26499.jpg'], ['2/145802.jpg', '4/29344.jpg', '7/105447.jpg', '5/105365.jpg'], ['1/58201.jpg'], ['10/172490.png', '3/149103.jpg', '10/172487.png', '9/155159.jpg', '1/52521.jpg'], [], ['6/116456.jpg', '3/94853.jpg', '0/97760.jpg', '10/172255.png', '10/176370.png', '0/32670.jpg', '3/103933.jpg', '10/172272.png', '5/86635.jpg', '10/173237.png', '7/22777.jpg', '10/172613.png', '10/170037.png', '10/171043.png'], ['10/173389.png', '10/173851.png', '9/131279.jpg', '9/156039.jpg'], ['10/173139.png', '1/102001.jpg', '10/171323.png', '10/173851.png', '1/60881.jpg', '0/22890.jpg', '10/173843.png', '10/173758.png', '6/110976.jpg', '10/173857.png', '10/174522.png', '9/96249.jpg'], ['4/85914.jpg', '0/97750.jpg', '4/93774.jpg'], ['2/16462.jpg'], ['10/174619.png'], ['10/176810.png', '6/116176.jpg', '9/12069.jpg', '5/11035.jpg', '2/10802.jpg', '1/13911.jpg', '4/11704.jpg'], ['4/96214.jpg', '5/14075.jpg'], [], ['10/172748.png']]\n",
    "\n",
    "  for l in range(len(label_true)):\n",
    "\n",
    "    for idx in label_true[l]:\n",
    "      if image_id==idx:\n",
    "        if visited[i]==False:\n",
    "          visited[i]=True\n",
    "          print(f'image={image_id},    label={labels[l]};')\n",
    "          # path=os.path.join(root,idx)\n",
    "          root='/content/drive/My Drive/Symbolic_image/SKG-Sym/data'\n",
    "          if os.path.exists(os.path.join(root,'train_images/'+image_id)):\n",
    "          # if os.path.isfile(path):\n",
    "            image=mpimg.imread(os.path.join(root,'train_images/'+image_id))\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "          elif os.path.exists(os.path.join(root,'test_images/'+image_id)):\n",
    "            image=mpimg.imread(os.path.join(root,'test_images/'+image_id))\n",
    "            # image=plt.imread(path)\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "          print('imageid: ', image_id)\n",
    "          print('i=',i)\n",
    "          for graph_type in ['sg']:\n",
    "            print(graph_type)\n",
    "            if graph_type=='concept':\n",
    "              data=gt_scene_graphs_concept\n",
    "\n",
    "              # with open(SCENEGRAPHS / 'val_sceneGraphs_concept.json') as f:\n",
    "              sg_json_data = concept_json\n",
    "            else:\n",
    "              data=gt_scene_graphs\n",
    "              # with open(SCENEGRAPHS / 'val_sceneGraphs.json') as f:\n",
    "              sg_json_data = sg_json\n",
    "            # print(sg_json_data[image_id])\n",
    "            mol = to_molecule(data, image_id, sg_json_data)\n",
    "            \n",
    "\n",
    "            # for title, method in [('Integrated Gradients', 'ig'), ('Saliency', 'saliency')]:\n",
    "                # edge_mask = explain(method, data.cuda(), target=short_answer_label)\n",
    "            edge_mask = explain(data,graph_type)\n",
    "            # print(edge_mask)\n",
    "            edge_mask_dict = aggregate_edge_directions(edge_mask, data)\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            # plt.title(title)\n",
    "            draw_molecule(mol, data, sg_json_data, image_id, edge_mask_dict)\n",
    "        else:\n",
    "          print(f'image={image_id},    label={labels[l]};')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNe8JER2W5IU"
   },
   "outputs": [],
   "source": [
    "import Constants\n",
    "ROOT_DIR = Constants.ROOT_DIR\n",
    "SCENEGRAPHS = ROOT_DIR.joinpath('sceneGraphs')\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# root='data/train_images/'\n",
    "\n",
    "label_dict={\"unknown\":0, \"fashion\": 17, \"family\": 29, \"strength\": 21, \"fun\": 5, \"sex\": 2, \"natural\": 1, \"comfort\": 43, \"delicious\": 39, \"violence\": 6, \"health\": 9, \"speed\": 16, \"energy\": 19, \"love\": 12, \"entertainment\": 26, \"adventure\": 10, \"vacation\": 42, \"art\": 33, \"travel\": 24, \"beauty\": 7, \"danger\": 4, \"nature\": 3, \"power\": 11, \"sports\": 14, \"happy\": 51, \"freedom\": 41, \"variety\": 45, \"environment\": 15, \"technology\": 27, \"protection\": 38, \"sexy\": 13, \"happiness\": 36, \"party\": 49, \"youth\": 23, \"fitness\": 37, \"safety\": 22, \"death\": 8, \"clean\": 40, \"animal cruelty\": 52, \"relaxation\": 32, \"hot\": 25, \"excitement\": 30, \"healthy\": 31, \"class\": 53, \"christmas\": 34, \"alcohol\": 50, \"strong\": 47, \"injury\": 20, \"hunger\": 46, \"desire\": 44, \"food\": 18, \"humor\": 48, \"refreshing\": 35, \"smoking\": 28}\n",
    "labels=[0]*(len(label_dict))\n",
    "for label in label_dict:\n",
    "  labels[label_dict[label]]=label\n",
    "# print(labels)\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def aggregate_edge_directions(edge_mask, data):\n",
    "    edge_mask_dict = defaultdict(float)\n",
    "    \n",
    "\n",
    "    for val, u, v in list(zip(edge_mask, *data.edge_index)):\n",
    "        u, v = u.item(), v.item()\n",
    "        if u > v:\n",
    "            u, v = v, u\n",
    "        edge_mask_dict[(u, v)] += val\n",
    "    return edge_mask_dict\n",
    "    \n",
    "\n",
    "# data = random.choice([t for t in test_dataset if not t.y.item()])\n",
    "with open(SCENEGRAPHS / 'val_sceneGraphs_concept.json') as f:\n",
    "  concept_json = dict(json.load(f))\n",
    "with open(SCENEGRAPHS / 'val_sceneGraphs.json') as f:\n",
    "  sg_json = dict(json.load(f))\n",
    "\n",
    "visited=[False]*len(val_dataset)\n",
    "for i, valdata in enumerate(val_dataset):\n",
    "  questionID, questions, gt_scene_graphs, gt_scene_graphs_concept, programs, full_answers, short_answer_label, types, short_answer_bitmap, image_id, img = valdata\n",
    "  label_true=label_true=[[], ['5/58825.jpg', '10/173173.png', '10/173139.png', '10/172571.png', '9/137779.jpg', '8/80808.jpg', '0/54450.jpg', '10/177249.png', '2/30082.jpg', '10/171140.png', '10/173460.png', '2/120202.jpg', '7/86527.jpg', '10/174037.png', '1/65311.jpg', '10/170299.png', '4/49524.jpg', '5/149005.jpg', '10/173379.png', '10/175756.png', '2/54442.jpg', '10/172374.png', '10/173461.png', '10/174576.png', '10/172570.png', '10/172270.png', '0/52490.jpg', '10/176131.png', '10/172151.png', '10/173862.png', '10/177370.png', '5/54655.jpg', '4/42234.jpg', '10/172520.png', '1/165201.jpg', '10/173268.png', '3/47503.jpg', '2/65392.jpg', '0/78390.jpg'], ['1/116201.jpg', '10/174440.png', '1/116301.jpg', '10/172119.png', '1/165241.jpg', '10/176262.png', '6/116456.jpg', '1/31641.jpg', '10/173199.png', '10/173071.png', '2/62072.jpg', '2/116472.jpg', '1/136311.jpg', '0/116550.jpg', '0/18670.jpg', '0/98560.jpg', '3/20843.jpg', '5/10845.jpg', '0/155920.jpg', '10/173145.png', '3/66253.jpg', '10/172255.png', '10/175330.png', '10/174699.png', '2/32852.jpg', '3/116483.jpg', '10/170191.png', '0/10510.jpg', '0/30030.jpg', '0/32670.jpg', '0/73170.jpg', '0/57500.jpg', '3/134043.jpg', '10/176058.png', '7/158737.jpg', '1/93051.jpg', '10/175803.png', '10/174680.png', '9/45989.jpg', '3/158853.jpg', '8/116548.jpg', '7/22777.jpg', '10/173500.png', '4/45934.jpg', '10/175121.png', '4/41384.jpg', '1/119481.jpg', '10/177955.png', '10/170037.png', '10/175877.png', '10/171043.png', '8/46188.jpg'], ['5/58825.jpg', '4/13184.jpg', '5/82575.jpg', '10/177391.png', '10/176487.png', '1/158991.jpg', '9/85739.jpg', '6/52506.jpg', '8/38428.jpg', '10/173687.png', '8/80808.jpg', '10/173244.png', '10/177627.png', '9/102919.jpg', '10/173621.png', '10/170857.png', '4/54134.jpg', '10/175743.png', '6/103376.jpg', '5/103085.jpg', '10/177145.png', '5/77865.jpg', '4/52414.jpg', '0/11270.jpg', '2/30082.jpg', '10/174734.png', '10/173601.png', '10/173503.png', '0/52830.jpg', '5/140425.jpg', '1/52501.jpg', '5/85745.jpg', '10/171956.png', '7/11057.jpg', '6/52486.jpg', '10/171942.png', '6/52476.jpg', '9/52399.jpg', '9/45879.jpg', '10/174163.png', '10/173960.png', '9/103389.jpg', '10/177327.png', '10/172468.png', '10/173623.png', '10/175084.png', '10/170299.png', '8/21628.jpg', '10/173634.png', '10/170274.png', '1/103021.jpg', '4/52604.jpg', '4/49524.jpg', '9/67549.jpg', '10/174793.png', '10/177968.png', '10/174416.png', '10/170706.png', '10/172374.png', '10/176772.png', '10/174136.png', '2/54492.jpg', '8/102878.jpg', '8/72298.jpg', '0/52620.jpg', '10/173744.png', '10/172117.png', '10/172018.png', '6/146156.jpg', '10/176490.png', '10/175809.png', '10/176808.png', '10/175303.png', '10/172270.png', '2/52652.jpg', '8/31538.jpg', '0/40450.jpg', '7/102907.jpg', '7/46007.jpg', '8/102978.jpg', '7/103127.jpg', '10/171479.png', '0/52440.jpg', '7/52477.jpg', '1/108211.jpg', '1/103191.jpg', '10/176541.png', '9/62899.jpg', '5/67305.jpg', '0/13220.jpg', '10/173038.png', '10/177294.png', '0/102870.jpg', '10/176050.png'], [], [], [], ['10/173522.png', '10/175043.png', '10/174220.png', '10/171936.png', '2/79032.jpg', '10/172119.png', '10/172043.png', '1/165241.jpg', '10/172921.png', '1/12011.jpg', '10/170842.png', '10/173890.png', '2/107982.jpg', '0/130290.jpg', '10/170407.png', '1/109311.jpg', '3/94853.jpg', '10/171832.png', '0/155920.jpg', '10/173291.png', '10/172560.png', '3/125853.jpg', '3/66253.jpg', '3/116253.jpg', '10/175330.png', '10/174699.png', '2/32852.jpg', '10/171924.png', '10/170670.png', '10/171326.png', '10/170119.png', '10/173020.png', '10/172581.png', '10/170004.png', '0/86120.jpg', '10/171330.png', '10/170584.png', '10/173435.png', '0/130330.jpg', '0/130270.jpg', '10/175432.png', '10/172229.png', '10/173186.png', '10/175803.png', '10/173184.png', '10/172640.png', '10/172427.png', '10/175924.png', '3/45883.jpg', '10/176388.png', '10/172686.png', '10/172497.png', '10/170112.png', '10/172097.png', '3/135043.jpg', '10/172174.png', '8/116548.jpg', '10/172920.png', '10/171456.png', '8/86558.jpg', '1/131611.jpg'], [], [], ['4/13184.jpg', '4/103064.jpg', '6/135796.jpg', '10/173703.png', '4/33754.jpg', '10/175215.png', '10/175148.png', '1/106801.jpg', '10/176714.png', '1/85751.jpg', '10/174623.png', '9/86039.jpg', '10/177853.png', '10/173816.png', '9/123499.jpg', '4/109194.jpg', '8/21628.jpg', '0/155150.jpg', '10/174172.png', '8/53638.jpg', '4/32694.jpg', '10/177532.png', '10/173437.png', '10/176791.png', '1/125221.jpg', '3/76853.jpg', '6/133736.jpg', '7/129067.jpg', '0/99730.jpg', '10/175724.png', '0/102870.jpg'], ['10/174437.png', '10/173816.png', '10/174892.png', '4/95744.jpg'], [], ['10/172660.png', '1/116201.jpg', '10/170073.png', '10/177618.png', '10/172119.png', '10/176733.png', '3/116223.jpg', '10/172921.png', '0/116440.jpg', '6/162606.jpg', '10/176302.png', '2/62072.jpg', '2/116472.jpg', '0/130290.jpg', '0/116550.jpg', '0/97420.jpg', '3/94853.jpg', '6/46076.jpg', '3/66253.jpg', '3/116253.jpg', '2/32852.jpg', '6/133906.jpg', '10/171326.png', '5/116475.jpg', '0/10510.jpg', '0/30030.jpg', '5/46845.jpg', '2/134832.jpg', '1/8991.jpg', '3/157223.jpg', '0/39600.jpg', '9/116329.jpg', '10/172272.png', '10/172229.png', '10/172449.png', '1/116231.jpg', '1/116241.jpg', '9/45989.jpg', '4/86204.jpg', '10/172920.png', '4/140334.jpg', '10/173500.png', '4/45934.jpg', '4/71924.jpg', '4/157444.jpg'], ['0/7420.jpg', '10/172473.png', '1/118051.jpg', '3/57213.jpg', '3/136483.jpg', '1/163451.jpg', '4/92294.jpg', '10/177406.png', '10/173850.png', '10/175994.png', '2/105752.jpg', '1/126691.jpg', '9/62759.jpg', '10/172310.png', '2/7032.jpg', '0/136350.jpg', '0/138450.jpg'], ['6/46216.jpg', '10/177391.png', '6/52506.jpg', '9/102889.jpg', '9/137779.jpg', '10/170857.png', '4/52514.jpg', '10/174734.png', '10/177897.png', '0/52830.jpg', '10/174163.png', '10/173960.png', '9/103389.jpg', '10/177327.png', '10/174240.png', '1/103021.jpg', '10/171600.png', '10/170107.png', '10/174793.png', '10/172363.png', '10/174416.png', '10/172015.png', '10/174136.png', '2/45852.jpg', '1/102931.jpg', '10/173744.png', '10/176421.png', '10/172018.png', '10/176808.png', '10/175303.png', '2/52652.jpg', '2/52612.jpg', '10/176645.png', '8/102978.jpg', '10/176662.png', '10/177325.png', '7/103127.jpg', '0/52440.jpg', '7/52477.jpg', '10/174720.png', '1/103191.jpg', '1/103281.jpg', '10/177701.png', '10/176390.png', '10/177918.png', '10/173524.png'], ['10/172590.png', '0/57780.jpg', '10/173044.png', '10/174437.png', '6/4156.jpg', '0/133700.jpg', '10/174892.png', '6/13366.jpg', '3/87403.jpg', '10/176132.png', '2/106282.jpg', '5/1105.jpg', '10/177699.png', '10/170192.png', '7/158967.jpg', '1/150151.jpg', '10/173178.png', '10/173590.png', '10/175724.png', '5/119145.jpg'], ['10/177217.png', '2/79032.jpg', '10/176691.png', '4/46574.jpg', '1/165241.jpg', '2/62072.jpg', '1/126861.jpg', '10/173156.png', '10/173046.png', '0/155920.jpg', '9/132089.jpg', '9/12419.jpg', '4/4774.jpg', '0/73170.jpg', '1/93051.jpg', '1/63541.jpg', '10/170038.png', '10/177947.png', '5/143915.jpg', '1/87861.jpg', '10/170037.png'], ['7/18957.jpg', '10/173371.png', '10/171994.png', '10/177529.png', '10/177595.png', '1/102001.jpg', '10/172752.png', '2/150402.jpg', '10/171195.png', '10/171443.png', '10/171323.png', '0/104490.jpg', '1/61061.jpg', '10/174625.png', '1/60881.jpg', '2/120202.jpg', '1/79021.jpg', '10/176539.png', '10/170565.png', '0/22610.jpg', '10/173930.png', '7/42477.jpg', '10/177830.png', '10/170644.png', '8/148948.jpg', '9/96249.jpg', '10/171299.png', '0/135240.jpg', '7/157977.jpg', '10/176253.png', '10/170218.png', '10/173928.png', '0/52540.jpg', '6/52426.jpg'], ['1/106691.jpg', '10/171526.png'], [], ['1/32161.jpg', '10/175994.png', '0/36990.jpg'], ['6/72486.jpg', '10/177380.png', '10/173671.png', '0/127560.jpg', '1/127521.jpg', '10/177306.png'], ['10/172660.png', '10/170073.png', '4/96214.jpg', '10/172575.png', '10/172043.png', '1/103971.jpg', '10/174905.png', '10/177934.png', '8/135238.jpg', '6/130136.jpg', '10/171628.png', '4/53644.jpg', '10/173046.png', '10/172560.png', '10/170376.png', '1/101101.jpg', '8/53958.jpg', '10/173231.png', '10/172581.png', '0/136620.jpg', '4/53724.jpg', '0/130330.jpg', '10/175432.png', '10/173184.png', '3/8413.jpg', '10/172497.png', '10/177024.png', '10/176384.png', '10/170488.png'], ['10/174536.png', '1/158991.jpg', '10/173244.png', '1/69411.jpg', '0/81770.jpg', '6/150016.jpg', '10/170395.png', '1/58201.jpg', '10/171942.png', '0/5690.jpg', '10/172490.png', '8/1538.jpg', '1/36391.jpg', '0/95790.jpg', '10/171045.png', '8/13658.jpg', '0/144700.jpg', '1/106061.jpg', '10/170572.png'], [], ['0/53180.jpg', '6/116316.jpg', '2/38672.jpg', '8/82888.jpg', '0/139220.jpg', '4/47234.jpg', '10/170973.png'], ['6/52936.jpg', '1/159251.jpg', '0/112230.jpg', '6/35376.jpg', '3/1633.jpg', '10/173951.png', '1/201.jpg', '10/172530.png', '10/173712.png', '6/1066.jpg'], [], ['10/173846.png', '10/173393.png', '0/104310.jpg', '1/135041.jpg', '10/175211.png', '10/173034.png'], ['10/172900.png', '10/175767.png', '10/174172.png', '10/173899.png'], ['8/80808.jpg', '5/20325.jpg', '10/171892.png', '10/171545.png', '10/170382.png', '10/173912.png', '10/170918.png', '6/54386.jpg', '10/172570.png', '10/172270.png', '10/172151.png', '10/173947.png', '10/172520.png', '10/173268.png', '5/47205.jpg', '4/52734.jpg', '0/78390.jpg'], ['1/149381.jpg', '4/44744.jpg'], ['0/155500.jpg', '4/41354.jpg'], [], ['6/116176.jpg', '1/158571.jpg', '8/9998.jpg', '10/176475.png', '4/29344.jpg', '10/175162.png', '10/174619.png'], ['10/170407.png', '5/14075.jpg', '10/172565.png', '3/71943.jpg'], ['5/121175.jpg', '7/92687.jpg', '8/106718.jpg', '10/174929.png', '1/142241.jpg', '10/174640.png', '2/92592.jpg', '8/105888.jpg'], [], ['4/67534.jpg', '10/171923.png', '10/172122.png', '10/170923.png', '10/172434.png', '5/149005.jpg', '10/170228.png', '10/173930.png', '10/172024.png', '10/173090.png', '10/177394.png', '2/22852.jpg', '10/172373.png', '10/172569.png', '10/173840.png', '9/6929.jpg', '10/176779.png', '1/165201.jpg', '9/26499.jpg'], ['2/145802.jpg', '4/29344.jpg', '7/105447.jpg', '5/105365.jpg'], ['1/58201.jpg'], ['10/172490.png', '3/149103.jpg', '10/172487.png', '9/155159.jpg', '1/52521.jpg'], [], ['6/116456.jpg', '3/94853.jpg', '0/97760.jpg', '10/172255.png', '10/176370.png', '0/32670.jpg', '3/103933.jpg', '10/172272.png', '5/86635.jpg', '10/173237.png', '7/22777.jpg', '10/172613.png', '10/170037.png', '10/171043.png'], ['10/173389.png', '10/173851.png', '9/131279.jpg', '9/156039.jpg'], ['10/173139.png', '1/102001.jpg', '10/171323.png', '10/173851.png', '1/60881.jpg', '0/22890.jpg', '10/173843.png', '10/173758.png', '6/110976.jpg', '10/173857.png', '10/174522.png', '9/96249.jpg'], ['4/85914.jpg', '0/97750.jpg', '4/93774.jpg'], ['2/16462.jpg'], ['10/174619.png'], ['10/176810.png', '6/116176.jpg', '9/12069.jpg', '5/11035.jpg', '2/10802.jpg', '1/13911.jpg', '4/11704.jpg'], ['4/96214.jpg', '5/14075.jpg'], [], ['10/172748.png']]\n",
    "  for l in range(len(label_true)):\n",
    "\n",
    "    for idx in label_true[l]:\n",
    "      if image_id==idx:\n",
    "        if visited[i]==False:\n",
    "          visited[i]=True\n",
    "          print(f'image={idx},    label={labels[l]};')\n",
    "          # path=os.path.join(root,idx)\n",
    "          root='/content/drive/My Drive/Symbolic_image/SKG-Sym/data'\n",
    "          if os.path.exists(os.path.join(root,'train_images/'+idx)):\n",
    "          # if os.path.isfile(path):\n",
    "            image=mpimg.imread(os.path.join(root,'train_images/'+idx))\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "          elif os.path.exists(os.path.join(root,'test_images/'+idx)):\n",
    "            image=mpimg.imread(os.path.join(root,'test_images/'+idx))\n",
    "            # image=plt.imread(path)\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "          print('imageid: ', image_id)\n",
    "          print('i=',i)\n",
    "          for graph_type in ['concept']:\n",
    "            print(graph_type)\n",
    "            if graph_type=='concept':\n",
    "              data=gt_scene_graphs_concept\n",
    "\n",
    "              # with open(SCENEGRAPHS / 'val_sceneGraphs_concept.json') as f:\n",
    "              sg_json_data = concept_json\n",
    "            else:\n",
    "              data=gt_scene_graphs\n",
    "              # with open(SCENEGRAPHS / 'val_sceneGraphs.json') as f:\n",
    "              sg_json_data = sg_json\n",
    "            # print(sg_json_data[image_id])\n",
    "            mol = to_molecule(data, image_id, sg_json_data)\n",
    "            \n",
    "\n",
    "            # for title, method in [('Integrated Gradients', 'ig'), ('Saliency', 'saliency')]:\n",
    "                # edge_mask = explain(method, data.cuda(), target=short_answer_label)\n",
    "            edge_mask = explain(data,graph_type)\n",
    "            # print(edge_mask)\n",
    "            edge_mask_dict = aggregate_edge_directions(edge_mask, data)\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            # plt.title(title)\n",
    "            draw_molecule(mol, data, sg_json_data, image_id, edge_mask_dict)\n",
    "        else:\n",
    "          print(f'image={idx},    label={labels[l]};')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [],
   "authorship_tag": "ABX9TyMOaBOpau9CRkMnzuUcTDhz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}